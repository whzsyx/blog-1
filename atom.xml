<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Dunwu</title>
  
  <subtitle>大道至简，知易行难</subtitle>
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="https://dunwu.github.io/blog/"/>
  <updated>2022-04-14T08:45:53.602Z</updated>
  <id>https://dunwu.github.io/blog/</id>
  
  <author>
    <name>Zhang Peng</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>读写分离基本原理</title>
    <link href="https://dunwu.github.io/blog/2022/04/14/%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/"/>
    <id>https://dunwu.github.io/blog/2022/04/14/%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/</id>
    <published>2022-04-14T03:36:23.000Z</published>
    <updated>2022-04-14T08:45:53.602Z</updated>
    
    <content type="html"><![CDATA[<h1 id="读写分离基本原理"><a class="markdownIt-Anchor" href="#读写分离基本原理"></a> 读写分离基本原理</h1><p><strong>读写分离的基本原理是：主服务器用来处理写操作以及实时性要求比较高的读操作，而从服务器用来处理读操作</strong>。</p><h2 id="1-为何要读写分离"><a class="markdownIt-Anchor" href="#1-为何要读写分离"></a> 1. 为何要读写分离</h2><ul><li><strong>有效减少锁竞争</strong> - 主服务器只负责写，从服务器只负责读，能够有效的避免由数据更新导致的行锁竞争，使得整个系统的查询性能得到极大的改善。</li><li><strong>提高查询吞吐量</strong> - 通过一主多从的配置方式，可以将查询请求均匀的分散到多个数据副本，能够进一步的提升系统的处理能力。</li><li><strong>提升数据库可用性</strong> - 使用多主多从的方式，不但能够提升系统的吞吐量，还能够提升数据库的可用性，可以达到在任何一个数据库宕机，甚至磁盘物理损坏的情况下仍然不影响系统的正常运行。</li></ul><h2 id="2-读写分离的原理"><a class="markdownIt-Anchor" href="#2-读写分离的原理"></a> 2. 读写分离的原理</h2><p>读写分离的实现是根据 SQL 语义分析，将读操作和写操作分别路由至主库与从库。</p><p><img src="https://shardingsphere.apache.org/document/current/img/read-write-split/read-write-split.png" alt="读写分离" /></p><p>读写分离的基本实现是：</p><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/cs/database/mysql/master-slave-proxy.png" alt="img" /></p><ul><li>数据库服务器搭建主从集群，一主一从、一主多从都可以。</li><li>数据库主机负责读写操作，从机只负责读操作。</li><li>数据库主机通过复制将数据同步到从机，每台数据库服务器都存储了全量数据。</li><li>业务服务器将写操作发给数据库主机，将读操作发给数据库从机。</li><li>主机会记录请求的二进制日志，然后推送给从库，从库解析并执行日志中的请求，完成主从复制。这意味着：复制过程存在时延，这段时间内，主从数据可能不一致。</li></ul><h2 id="3-读写分离的问题"><a class="markdownIt-Anchor" href="#3-读写分离的问题"></a> 3. 读写分离的问题</h2><p>读写分离存在两个问题：<strong>数据一致性</strong>和<strong>分发机制</strong>。</p><h3 id="31-数据一致性"><a class="markdownIt-Anchor" href="#31-数据一致性"></a> 3.1. 数据一致性</h3><p>读写分离产生了主库与从库之间的数据一致性的问题。</p><p><img src="https://shardingsphere.apache.org/document/current/img/read-write-split/sharding-read-write-split.png" alt="数据分片 + 读写分离" /></p><h3 id="32-分发机制"><a class="markdownIt-Anchor" href="#32-分发机制"></a> 3.2. 分发机制</h3><p>数据库读写分离后，一个 SQL 请求具体分发到哪个数据库节点？一般有两种分发方式：客户端分发和中间件代理分发。</p><p>客户端分发，是基于程序代码，自行控制数据分发到哪个数据库节点。更细一点来说，一般程序中建立多个数据库的连接，根据一定的算法，选择合适的连接去发起 SQL 请求。这种方式也被称为客户端中间件，代表有：jdbc-sharding。</p><p>中间件代理分发，指的是独立一套系统出来，实现读写操作分离和数据库服务器连接的管理。中间件对业务服务器提供 SQL 兼容的协议，业务服务器无须自己进行读写分离。对于业务服务器来说，访问中间件和访问数据库没有区别，事实上在业务服务器看来，中间件就是一个数据库服务器。代表有：Mycat。</p><h2 id="4-参考资料"><a class="markdownIt-Anchor" href="#4-参考资料"></a> 4. 参考资料</h2><ul><li><a href="https://time.geekbang.org/column/intro/100046801" target="_blank" rel="noopener">后端存储实战课</a></li><li><a href="https://shardingsphere.apache.org/document/current/cn/overview/" target="_blank" rel="noopener">ShardingSphere 官方文档</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;读写分离基本原理&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#读写分离基本原理&quot;&gt;&lt;/a&gt; 读写分离基本原理&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;读写分离的基本原理是：主服务器用来处理写操作以及实时性要求比较高的读操作，而从服务器用来处理
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="分布式关键技术" scheme="https://dunwu.github.io/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/"/>
    
      <category term="数据调度" scheme="https://dunwu.github.io/blog/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/%E6%95%B0%E6%8D%AE%E8%B0%83%E5%BA%A6/"/>
    
    
      <category term="分布式" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="分布式关键技术" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF/"/>
    
      <category term="数据调度" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E8%B0%83%E5%BA%A6/"/>
    
      <category term="读写分离" scheme="https://dunwu.github.io/blog/tags/%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/"/>
    
  </entry>
  
  <entry>
    <title>数据库综合</title>
    <link href="https://dunwu.github.io/blog/2022/04/11/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%BC%E5%90%88/"/>
    <id>https://dunwu.github.io/blog/2022/04/11/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%BC%E5%90%88/</id>
    <published>2022-04-11T08:52:35.000Z</published>
    <updated>2022-04-14T08:45:53.606Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据库综合"><a class="markdownIt-Anchor" href="#数据库综合"></a> 数据库综合</h1><h2 id="内容"><a class="markdownIt-Anchor" href="#内容"></a> 📖 内容</h2><h3 id="分布式存储原理"><a class="markdownIt-Anchor" href="#分布式存储原理"></a> 分布式存储原理</h3><ul><li><a href="https://dunwu.github.io/design/distributed/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%80%E4%BB%8B.html">分布式简介</a></li><li><a href="https://dunwu.github.io/design/distributed/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA.html">分布式基础理论</a> - 关键词：<code>拜占庭将军</code>、<code>CAP</code>、<code>BASE</code></li><li><a href="https://dunwu.github.io/design/distributed/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95Paxos.html">分布式算法 Paxos</a> - 关键词：<code>共识性算法</code></li><li><a href="https://dunwu.github.io/design/distributed/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95Raft.html">分布式算法 Raft</a> - 关键词：<code>共识性算法</code></li><li><a href="https://dunwu.github.io/design/distributed/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.html">负载均衡</a> - 关键词：<code>轮询</code>、<code>随机</code>、<code>最少连接</code>、<code>源地址哈希</code>、<code>一致性哈希</code>、<code>虚拟 hash 槽</code></li><li><a href="https://dunwu.github.io/design/distributed/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97.html">消息队列</a> - 关键词：<code>重复消费</code>、<code>消息丢失</code>、<code>消息顺序性</code>、<code>消息积压</code></li><li><a href="https://dunwu.github.io/design/distributed/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8.html">分布式存储</a> - 关键词：<code>读写分离</code>、<code>分库分表</code>、<code>迁移</code>、<code>扩容</code></li><li><a href="https://dunwu.github.io/design/distributed/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98.html">分布式缓存</a> - 关键词：<code>进程内缓存</code>、<code>分布式缓存</code>、<code>缓存雪崩</code>、<code>缓存穿透</code>、<code>缓存击穿</code>、<code>缓存更新</code>、<code>缓存预热</code>、<code>缓存降级</code></li><li><a href="https://dunwu.github.io/design/distributed/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.html">分布式锁</a> - 关键词：<code>数据库</code>、<code>Redis</code>、<code>ZooKeeper</code>、<code>互斥</code>、<code>可重入</code>、<code>死锁</code>、<code>容错</code>、<code>自旋尝试</code></li><li><a href="https://dunwu.github.io/design/distributed/%E5%88%86%E5%B8%83%E5%BC%8FID.html">分布式 ID</a> - 关键词：<code>UUID</code>、<code>自增序列</code>、<code>雪花算法</code>、<code>Leaf</code></li><li><a href="https://dunwu.github.io/design/distributed/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1.html">分布式事务</a> - 关键词：<code>2PC</code>、<code>3PC</code>、<code>TCC</code>、<code>本地消息表</code>、<code>MQ 消息</code>、<code>SAGA</code></li><li><a href="https://dunwu.github.io/design/distributed/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BC%9A%E8%AF%9D.html">分布式会话</a> - 关键词：<code>粘性 Session</code>、<code>Session 复制共享</code>、<code>基于缓存的 session 共享</code></li><li><a href="https://dunwu.github.io/design/distributed/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6.html">流量控制</a> - 关键词：<code>计数器法</code>、<code>时间窗口法</code>、<code>令牌桶法</code>、<code>漏桶法</code></li></ul><h3 id="其他"><a class="markdownIt-Anchor" href="#其他"></a> 其他</h3><ul><li><a href="01.Nosql%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B.md">Nosql 技术选型</a></li><li><a href="02.%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95.md">数据结构与数据库索引</a></li></ul><h2 id="资料"><a class="markdownIt-Anchor" href="#资料"></a> 📚 资料</h2><h2 id="传送"><a class="markdownIt-Anchor" href="#传送"></a> 🚪 传送</h2><p>◾ 🏠 <a href="https://github.com/dunwu/db-tutorial" target="_blank" rel="noopener">DB-TUTORIAL 首页</a> ◾ 🎯 <a href="https://github.com/dunwu/blog" target="_blank" rel="noopener">我的博客</a> ◾</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;数据库综合&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#数据库综合&quot;&gt;&lt;/a&gt; 数据库综合&lt;/h1&gt;
&lt;h2 id=&quot;内容&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#内容&quot;&gt;&lt;/a&gt; 📖 内容&lt;/h2
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="数据库综合" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%BC%E5%90%88/"/>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="综合" scheme="https://dunwu.github.io/blog/tags/%E7%BB%BC%E5%90%88/"/>
    
  </entry>
  
  <entry>
    <title>数据库中间件和代理</title>
    <link href="https://dunwu.github.io/blog/2022/04/11/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E9%97%B4%E4%BB%B6%E5%92%8C%E4%BB%A3%E7%90%86/"/>
    <id>https://dunwu.github.io/blog/2022/04/11/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E9%97%B4%E4%BB%B6%E5%92%8C%E4%BB%A3%E7%90%86/</id>
    <published>2022-04-11T08:52:35.000Z</published>
    <updated>2022-04-14T08:45:53.606Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据库中间件和代理"><a class="markdownIt-Anchor" href="#数据库中间件和代理"></a> 数据库中间件和代理</h1><h2 id="内容"><a class="markdownIt-Anchor" href="#内容"></a> 📖 内容</h2><ul><li><a href="01.Shardingsphere/01.ShardingSphere%E7%AE%80%E4%BB%8B.md">ShardingSphere 简介</a></li><li><a href="01.Shardingsphere/02.ShardingSphereJdbc.md">ShardingSphere Jdbc</a></li><li><a href="02.Flyway.md">版本管理中间件 Flyway</a></li></ul><h2 id="资料"><a class="markdownIt-Anchor" href="#资料"></a> 📚 资料</h2><ul><li><a href="https://github.com/seata/seata" target="_blank" rel="noopener"><strong>Seata</strong></a> - 分布式事务中间件。</li><li><a href="https://github.com/apache/shardingsphere" target="_blank" rel="noopener"><strong>ShardingSphere</strong></a> - 关系型数据库读写分离、分库分表中间件。</li><li><a href="https://github.com/flyway/flyway" target="_blank" rel="noopener"><strong>Flyway</strong></a> - 关系型数据库版本管理中间件。</li><li><a href="https://github.com/alibaba/canal" target="_blank" rel="noopener"><strong>Canal</strong></a> - 基于 MySQL 的 binlog，提供增量数据订阅和消费。</li><li><a href="https://github.com/twitter/twemproxy" target="_blank" rel="noopener"><strong>Twemproxy</strong></a> - Twitter 开源的一个 Redis 和 Memcache 的中间代理服务。</li><li><a href="https://github.com/CodisLabs/codis" target="_blank" rel="noopener"><strong>Codis</strong></a> - Redis 分布式集群方案。</li></ul><h2 id="传送"><a class="markdownIt-Anchor" href="#传送"></a> 🚪 传送</h2><p>◾ 🏠 <a href="https://github.com/dunwu/db-tutorial" target="_blank" rel="noopener">DB-TUTORIAL 首页</a> ◾ 🎯 <a href="https://github.com/dunwu/blog" target="_blank" rel="noopener">我的博客</a> ◾</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;数据库中间件和代理&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#数据库中间件和代理&quot;&gt;&lt;/a&gt; 数据库中间件和代理&lt;/h1&gt;
&lt;h2 id=&quot;内容&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#内容&quot;&gt;&lt;/
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="数据库中间件" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="中间件" scheme="https://dunwu.github.io/blog/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>关系型数据库</title>
    <link href="https://dunwu.github.io/blog/2022/04/11/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    <id>https://dunwu.github.io/blog/2022/04/11/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/</id>
    <published>2022-04-11T08:52:35.000Z</published>
    <updated>2022-04-14T08:45:53.606Z</updated>
    
    <content type="html"><![CDATA[<h1 id="关系型数据库"><a class="markdownIt-Anchor" href="#关系型数据库"></a> 关系型数据库</h1><h2 id="内容"><a class="markdownIt-Anchor" href="#内容"></a> 📖 内容</h2><h3 id="公共知识"><a class="markdownIt-Anchor" href="#公共知识"></a> 公共知识</h3><ul><li><a href="01.%E7%BB%BC%E5%90%88/01.%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9D%A2%E8%AF%95.md">关系型数据库面试总结</a> 💯</li><li><a href="01.%E7%BB%BC%E5%90%88/02.SqlCheatSheet.md">SQL Cheat Sheet</a> 是一个 SQL 入门教程。</li><li><a href="01.%E7%BB%BC%E5%90%88/03.%E6%89%A9%E5%B1%95SQL.md">扩展 SQL</a> 是一个 SQL 入门教程。</li></ul><h3 id="mysql"><a class="markdownIt-Anchor" href="#mysql"></a> Mysql</h3><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20200716103611.png" alt="img" /></p><ul><li><a href="02.Mysql/01.Mysql%E5%BA%94%E7%94%A8%E6%8C%87%E5%8D%97.md">Mysql 应用指南</a> ⚡</li><li><a href="02.Mysql/02.MySQL%E5%B7%A5%E4%BD%9C%E6%B5%81.md">Mysql 工作流</a> - 关键词：<code>连接</code>、<code>缓存</code>、<code>语法分析</code>、<code>优化</code>、<code>执行引擎</code>、<code>redo log</code>、<code>bin log</code>、<code>两阶段提交</code></li><li><a href="02.Mysql/03.Mysql%E4%BA%8B%E5%8A%A1.md">Mysql 事务</a> - 关键词：<code>ACID</code>、<code>AUTOCOMMIT</code>、<code>事务隔离级别</code>、<code>死锁</code>、<code>分布式事务</code></li><li><a href="02.Mysql/04.Mysql%E9%94%81.md">Mysql 锁</a> - 关键词：<code>乐观锁</code>、<code>表级锁</code>、<code>行级锁</code>、<code>意向锁</code>、<code>MVCC</code>、<code>Next-key 锁</code></li><li><a href="02.Mysql/05.Mysql%E7%B4%A2%E5%BC%95.md">Mysql 索引</a> - 关键词：<code>Hash</code>、<code>B 树</code>、<code>聚簇索引</code>、<code>回表</code></li><li><a href="02.Mysql/06.Mysql%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.md">Mysql 性能优化</a></li><li><a href="02.Mysql/20.Mysql%E8%BF%90%E7%BB%B4.md">Mysql 运维</a> 🔨</li><li><a href="02.Mysql/21.Mysql%E9%85%8D%E7%BD%AE.md">Mysql 配置</a> 🔨</li><li><a href="02.Mysql/99.Mysql%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98.md">Mysql 问题</a></li></ul><h3 id="其他"><a class="markdownIt-Anchor" href="#其他"></a> 其他</h3><ul><li><a href="99.%E5%85%B6%E4%BB%96/01.PostgreSQL.md">PostgreSQL 应用指南</a></li><li><a href="99.%E5%85%B6%E4%BB%96/02.H2.md">H2 应用指南</a></li><li><a href="99.%E5%85%B6%E4%BB%96/03.Sqlite.md">SqLite 应用指南</a></li></ul><h2 id="资料"><a class="markdownIt-Anchor" href="#资料"></a> 📚 资料</h2><h3 id="综合"><a class="markdownIt-Anchor" href="#综合"></a> 综合</h3><ul><li><a href="https://book.douban.com/subject/26419771/" target="_blank" rel="noopener">《数据库的索引设计与优化》</a></li><li><a href="https://book.douban.com/subject/35167240/" target="_blank" rel="noopener">《SQL 必知必会》</a> - SQL 的基本概念和语法【入门】</li></ul><h3 id="mysql-2"><a class="markdownIt-Anchor" href="#mysql-2"></a> Mysql</h3><ul><li><strong>官方</strong><ul><li><a href="https://www.mysql.com/" target="_blank" rel="noopener">Mysql 官网</a></li><li><a href="https://dev.mysql.com/doc/" target="_blank" rel="noopener">Mysql 官方文档</a></li><li><a href="https://dev.mysql.com/doc/refman/8.0/en/mysql.html" target="_blank" rel="noopener">Mysql 官方文档之命令行客户端</a></li></ul></li><li><strong>书籍</strong><ul><li><a href="https://book.douban.com/subject/23008813/" target="_blank" rel="noopener">《高性能 MySQL》</a> - 经典，适合 DBA 或作为开发者的参考手册</li><li><a href="https://book.douban.com/subject/3354490/" target="_blank" rel="noopener">《MySQL 必知必会》</a> - 适合入门者</li></ul></li><li><strong>教程</strong><ul><li><a href="https://time.geekbang.org/column/intro/139" target="_blank" rel="noopener">MySQL 实战 45 讲</a></li><li><a href="http://www.runoob.com/mysql/mysql-tutorial.html" target="_blank" rel="noopener">runoob.com MySQL 教程</a></li><li><a href="https://github.com/jaywcjlove/mysql-tutorial" target="_blank" rel="noopener">mysql-tutorial</a></li></ul></li><li><strong>更多资源</strong><ul><li><a href="https://github.com/jobbole/awesome-mysql-cn" target="_blank" rel="noopener">awesome-mysql</a></li></ul></li></ul><h3 id="其他-2"><a class="markdownIt-Anchor" href="#其他-2"></a> 其他</h3><ul><li><a href="https://book.douban.com/subject/5402711/" target="_blank" rel="noopener">《Oracle Database 9i/10g/11g 编程艺术》</a></li></ul><h2 id="传送"><a class="markdownIt-Anchor" href="#传送"></a> 🚪 传送</h2><p>◾ 🏠 <a href="https://github.com/dunwu/db-tutorial" target="_blank" rel="noopener">DB-TUTORIAL 首页</a> ◾ 🎯 <a href="https://github.com/dunwu/blog" target="_blank" rel="noopener">我的博客</a> ◾</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;关系型数据库&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#关系型数据库&quot;&gt;&lt;/a&gt; 关系型数据库&lt;/h1&gt;
&lt;h2 id=&quot;内容&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#内容&quot;&gt;&lt;/a&gt; 📖 内容&lt;
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="关系型数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="关系型数据库" scheme="https://dunwu.github.io/blog/tags/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>关系型数据库其他知识</title>
    <link href="https://dunwu.github.io/blog/2022/04/11/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%B6%E4%BB%96%E7%9F%A5%E8%AF%86/"/>
    <id>https://dunwu.github.io/blog/2022/04/11/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%B6%E4%BB%96%E7%9F%A5%E8%AF%86/</id>
    <published>2022-04-11T08:52:35.000Z</published>
    <updated>2022-04-14T08:45:53.606Z</updated>
    
    <content type="html"><![CDATA[<h1 id="关系型数据库其他知识"><a class="markdownIt-Anchor" href="#关系型数据库其他知识"></a> 关系型数据库其他知识</h1><h2 id="内容"><a class="markdownIt-Anchor" href="#内容"></a> 📖 内容</h2><ul><li><a href="01.PostgreSQL.md">PostgreSQL 应用指南</a></li><li><a href="02.H2.md">H2 应用指南</a></li><li><a href="03.Sqlite.md">SqLite 应用指南</a></li></ul><h2 id="资料"><a class="markdownIt-Anchor" href="#资料"></a> 📚 资料</h2><h2 id="传送"><a class="markdownIt-Anchor" href="#传送"></a> 🚪 传送</h2><p>◾ 🏠 <a href="https://github.com/dunwu/db-tutorial" target="_blank" rel="noopener">DB-TUTORIAL 首页</a> ◾ 🎯 <a href="https://github.com/dunwu/blog" target="_blank" rel="noopener">我的博客</a> ◾</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;关系型数据库其他知识&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#关系型数据库其他知识&quot;&gt;&lt;/a&gt; 关系型数据库其他知识&lt;/h1&gt;
&lt;h2 id=&quot;内容&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#内容&quot;
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="关系型数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="关系型数据库" scheme="https://dunwu.github.io/blog/tags/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch 教程</title>
    <link href="https://dunwu.github.io/blog/2022/04/11/elasticsearch-%E6%95%99%E7%A8%8B/"/>
    <id>https://dunwu.github.io/blog/2022/04/11/elasticsearch-%E6%95%99%E7%A8%8B/</id>
    <published>2022-04-11T08:52:35.000Z</published>
    <updated>2022-04-14T08:45:53.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="elasticsearch-教程"><a class="markdownIt-Anchor" href="#elasticsearch-教程"></a> Elasticsearch 教程</h1><blockquote><p>Elasticsearch 是一个基于 Lucene 的搜索和数据分析工具，它提供了一个分布式服务。Elasticsearch 是遵从 Apache 开源条款的一款开源产品，是当前主流的企业级搜索引擎。</p></blockquote><h2 id="内容"><a class="markdownIt-Anchor" href="#内容"></a> 📖 内容</h2><h3 id="elasticsearch-面试总结"><a class="markdownIt-Anchor" href="#elasticsearch-面试总结"></a> <a href="01.Elasticsearch%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93.md">Elasticsearch 面试总结</a> 💯</h3><h3 id="elasticsearch-快速入门"><a class="markdownIt-Anchor" href="#elasticsearch-快速入门"></a> <a href="02.Elasticsearch%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8.md">Elasticsearch 快速入门</a></h3><h3 id="elasticsearch-简介"><a class="markdownIt-Anchor" href="#elasticsearch-简介"></a> <a href="03.Elasticsearch%E7%AE%80%E4%BB%8B.md">Elasticsearch 简介</a></h3><h3 id="elasticsearch-rest-api"><a class="markdownIt-Anchor" href="#elasticsearch-rest-api"></a> <a href="11.ElasticsearchRestApi.md">Elasticsearch Rest API</a></h3><h3 id="elasticsearch-java-api-之-high-level-rest-client"><a class="markdownIt-Anchor" href="#elasticsearch-java-api-之-high-level-rest-client"></a> <a href="12.ElasticsearchHighLevelRestJavaApi.md">ElasticSearch Java API 之 High Level REST Client</a></h3><h3 id="elasticsearch-索引管理"><a class="markdownIt-Anchor" href="#elasticsearch-索引管理"></a> <a href="04.Elasticsearch%E7%B4%A2%E5%BC%95.md">Elasticsearch 索引管理</a></h3><h3 id="elasticsearch-查询"><a class="markdownIt-Anchor" href="#elasticsearch-查询"></a> <a href="05.Elasticsearch%E6%9F%A5%E8%AF%A2.md">Elasticsearch 查询</a></h3><h3 id="elasticsearch-高亮"><a class="markdownIt-Anchor" href="#elasticsearch-高亮"></a> <a href="06.Elasticsearch%E9%AB%98%E4%BA%AE.md">Elasticsearch 高亮</a></h3><h3 id="elasticsearch-排序"><a class="markdownIt-Anchor" href="#elasticsearch-排序"></a> <a href="07.Elasticsearch%E6%8E%92%E5%BA%8F.md">Elasticsearch 排序</a></h3><h3 id="elasticsearch-聚合"><a class="markdownIt-Anchor" href="#elasticsearch-聚合"></a> <a href="08.Elasticsearch%E8%81%9A%E5%90%88.md">Elasticsearch 聚合</a></h3><h3 id="elasticsearch-分析器"><a class="markdownIt-Anchor" href="#elasticsearch-分析器"></a> <a href="09.Elasticsearch%E5%88%86%E6%9E%90%E5%99%A8.md">Elasticsearch 分析器</a></h3><h3 id="elasticsearch-集群和分片"><a class="markdownIt-Anchor" href="#elasticsearch-集群和分片"></a> <a href="13.Elasticsearch%E9%9B%86%E7%BE%A4%E5%92%8C%E5%88%86%E7%89%87.md">Elasticsearch 集群和分片</a></h3><h3 id="elasticsearch-运维"><a class="markdownIt-Anchor" href="#elasticsearch-运维"></a> <a href="20.Elasticsearch%E8%BF%90%E7%BB%B4.md">Elasticsearch 运维</a></h3><h3 id="elasticsearch-性能优化"><a class="markdownIt-Anchor" href="#elasticsearch-性能优化"></a> <a href="10.Elasticsearch%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.md">Elasticsearch 性能优化</a></h3><h2 id="资料"><a class="markdownIt-Anchor" href="#资料"></a> 📚 资料</h2><ul><li><strong>官方</strong><ul><li><a href="https://www.elastic.co/cn/products/elasticsearch" target="_blank" rel="noopener">Elasticsearch 官网</a></li><li><a href="https://github.com/elastic/elasticsearch" target="_blank" rel="noopener">Elasticsearch Github</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html" target="_blank" rel="noopener">Elasticsearch 官方文档</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/guide/master/index.html" target="_blank" rel="noopener">Elasticsearch: The Definitive Guide</a> - ElasticSearch 官方学习资料</li></ul></li><li><strong>书籍</strong><ul><li><a href="https://book.douban.com/subject/30380439/" target="_blank" rel="noopener">《Elasticsearch 实战》</a></li></ul></li><li><strong>教程</strong><ul><li><a href="https://github.com/chenryn/logstash-best-practice-cn" target="_blank" rel="noopener">ELK Stack 权威指南</a></li><li><a href="https://www.knowledgedict.com/tutorial/elasticsearch-intro.html" target="_blank" rel="noopener">Elasticsearch 教程</a></li></ul></li><li><strong>文章</strong><ul><li><a href="https://www.cnblogs.com/xing901022/p/4704319.html" target="_blank" rel="noopener">Elasticsearch+Logstash+Kibana 教程</a></li><li><a href="https://github.com/judasn/Linux-Tutorial/blob/master/ELK-Install-And-Settings.md" target="_blank" rel="noopener">ELK（Elasticsearch、Logstash、Kibana）安装和配置</a></li><li><strong>性能调优相关</strong>的工程实践<ul><li><a href="https://www.ebayinc.com/stories/blogs/tech/elasticsearch-performance-tuning-practice-at-ebay/" target="_blank" rel="noopener">Elasticsearch Performance Tuning Practice at eBay</a></li><li><a href="https://kickstarter.engineering/elasticsearch-at-kickstarter-db3c487887fc" target="_blank" rel="noopener">Elasticsearch at Kickstarter</a></li><li><a href="https://www.loggly.com/blog/nine-tips-configuring-elasticsearch-for-high-performance/" target="_blank" rel="noopener">9 tips on ElasticSearch configuration for high performance</a></li><li><a href="https://medium.com/@abhidrona/elasticsearch-deployment-best-practices-d6c1323b25d7" target="_blank" rel="noopener">Elasticsearch In Production - Deployment Best Practices</a></li></ul></li></ul></li><li><strong>更多资源</strong><ul><li><a href="https://github.com/dzharii/awesome-elasticsearch" target="_blank" rel="noopener">GitHub: Awesome ElasticSearch</a></li></ul></li></ul><h2 id="传送"><a class="markdownIt-Anchor" href="#传送"></a> 🚪 传送</h2><p>◾ 🏠 <a href="https://github.com/dunwu/db-tutorial" target="_blank" rel="noopener">DB-TUTORIAL 首页</a> ◾ 🎯 <a href="https://github.com/dunwu/blog" target="_blank" rel="noopener">我的博客</a> ◾</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;elasticsearch-教程&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#elasticsearch-教程&quot;&gt;&lt;/a&gt; Elasticsearch 教程&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;Elasticsearch 是一个
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/Elasticsearch/"/>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Elastic 技术栈</title>
    <link href="https://dunwu.github.io/blog/2022/04/11/elastic-%E6%8A%80%E6%9C%AF%E6%A0%88/"/>
    <id>https://dunwu.github.io/blog/2022/04/11/elastic-%E6%8A%80%E6%9C%AF%E6%A0%88/</id>
    <published>2022-04-11T08:52:35.000Z</published>
    <updated>2022-04-14T08:45:53.614Z</updated>
    
    <content type="html"><![CDATA[<h1 id="elastic-技术栈"><a class="markdownIt-Anchor" href="#elastic-技术栈"></a> Elastic 技术栈</h1><blockquote><p><strong>Elastic 技术栈通常被用来作为日志采集、检索、可视化的解决方案。</strong></p><p>ELK 是 elastic 公司旗下三款产品 <a href="https://www.elastic.co/products/elasticsearch" target="_blank" rel="noopener">Elasticsearch</a> 、<a href="https://www.elastic.co/products/logstash" target="_blank" rel="noopener">Logstash</a> 、<a href="https://www.elastic.co/products/kibana" target="_blank" rel="noopener">Kibana</a> 的首字母组合。</p><p><a href="https://www.elastic.co/products/logstash" target="_blank" rel="noopener">Logstash</a> 传输和处理你的日志、事务或其他数据。</p><p><a href="https://www.elastic.co/products/kibana" target="_blank" rel="noopener">Kibana</a> 将 Elasticsearch 的数据分析并渲染为可视化的报表。</p><p>Elastic 技术栈，在 ELK 的基础上扩展了一些新的产品，如：<a href="https://www.elastic.co/products/beats" target="_blank" rel="noopener">Beats</a> 、<a href="https://www.elastic.co/products/x-pack" target="_blank" rel="noopener">X-Pack</a> 。</p></blockquote><h2 id="内容"><a class="markdownIt-Anchor" href="#内容"></a> 📖 内容</h2><ul><li><a href="01.Elastic%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8.md">Elastic 快速入门</a></li><li><a href="02.Elastic%E6%8A%80%E6%9C%AF%E6%A0%88%E4%B9%8BFilebeat.md">Elastic 技术栈之 Filebeat</a></li><li><a href="03.Filebeat%E8%BF%90%E7%BB%B4.md">Filebeat 运维</a></li><li><a href="04.Elastic%E6%8A%80%E6%9C%AF%E6%A0%88%E4%B9%8BKibana.md">Elastic 技术栈之 Kibana</a></li><li><a href="05.Kibana%E8%BF%90%E7%BB%B4.md">Kibana 运维</a></li><li><a href="06.Elastic%E6%8A%80%E6%9C%AF%E6%A0%88%E4%B9%8BLogstash.md">Elastic 技术栈之 Logstash</a></li><li><a href="07.Logstash%E8%BF%90%E7%BB%B4.md">Logstash 运维</a></li></ul><h2 id="资料"><a class="markdownIt-Anchor" href="#资料"></a> 📚 资料</h2><ul><li><strong>官方</strong><ul><li><a href="https://www.elastic.co/cn/products/logstash" target="_blank" rel="noopener">Logstash 官网</a></li><li><a href="https://github.com/elastic/logstash" target="_blank" rel="noopener">Logstash Github</a></li><li><a href="https://www.elastic.co/guide/en/logstash/current/index.html" target="_blank" rel="noopener">Logstash 官方文档</a></li><li><a href="https://www.elastic.co/cn/products/kibana" target="_blank" rel="noopener">Kibana 官网</a></li><li><a href="https://github.com/elastic/kibana" target="_blank" rel="noopener">Kibana Github</a></li><li><a href="https://www.elastic.co/guide/en/kibana/current/index.html" target="_blank" rel="noopener">Kibana 官方文档</a></li><li><a href="https://www.elastic.co/cn/products/beats" target="_blank" rel="noopener">Beats 官网</a></li><li><a href="https://github.com/elastic/beats" target="_blank" rel="noopener">Beats Github</a></li><li><a href="https://www.elastic.co/guide/en/beats/libbeat/current/index.html" target="_blank" rel="noopener">Beats 官方文档</a></li></ul></li><li><strong>第三方工具</strong><ul><li><a href="https://github.com/logstash/logstash-logback-encoder" target="_blank" rel="noopener">logstash-logback-encoder</a></li></ul></li><li><strong>文章</strong><ul><li><a href="https://www.cnblogs.com/xing901022/p/4704319.html" target="_blank" rel="noopener">Elasticsearch+Logstash+Kibana 教程</a></li><li><a href="https://github.com/judasn/Linux-Tutorial/blob/master/ELK-Install-And-Settings.md" target="_blank" rel="noopener">ELK（Elasticsearch、Logstash、Kibana）安装和配置</a></li></ul></li></ul><h2 id="传送"><a class="markdownIt-Anchor" href="#传送"></a> 🚪 传送</h2><p>◾ 🏠 <a href="https://github.com/dunwu/db-tutorial" target="_blank" rel="noopener">DB-TUTORIAL 首页</a> ◾ 🎯 <a href="https://github.com/dunwu/blog" target="_blank" rel="noopener">我的博客</a> ◾</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;elastic-技术栈&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#elastic-技术栈&quot;&gt;&lt;/a&gt; Elastic 技术栈&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Elastic 技术栈通常被用来作为日志采集、检
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elastic" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/Elastic/"/>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elastic" scheme="https://dunwu.github.io/blog/tags/Elastic/"/>
    
  </entry>
  
  <entry>
    <title>后端存储实战课笔记</title>
    <link href="https://dunwu.github.io/blog/2022/04/08/%E5%90%8E%E7%AB%AF%E5%AD%98%E5%82%A8%E5%AE%9E%E6%88%98%E8%AF%BE%E7%AC%94%E8%AE%B0/"/>
    <id>https://dunwu.github.io/blog/2022/04/08/%E5%90%8E%E7%AB%AF%E5%AD%98%E5%82%A8%E5%AE%9E%E6%88%98%E8%AF%BE%E7%AC%94%E8%AE%B0/</id>
    <published>2022-04-08T09:00:00.000Z</published>
    <updated>2022-04-14T08:45:53.614Z</updated>
    
    <content type="html"><![CDATA[<h1 id="后端存储实战课笔记"><a class="markdownIt-Anchor" href="#后端存储实战课笔记"></a> 后端存储实战课笔记</h1><h2 id="1-课前加餐丨电商系统是如何设计的"><a class="markdownIt-Anchor" href="#1-课前加餐丨电商系统是如何设计的"></a> 1. 课前加餐丨电商系统是如何设计的？</h2><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20220407152237.png" alt="" /></p><h2 id="2-创建和更新订单时如何保证数据准确无误"><a class="markdownIt-Anchor" href="#2-创建和更新订单时如何保证数据准确无误"></a> 2. 创建和更新订单时，如何保证数据准确无误？</h2><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20220407162459.png" alt="" /></p><h2 id="3-流量大-数据多的商品详情页系统该如何设计"><a class="markdownIt-Anchor" href="#3-流量大-数据多的商品详情页系统该如何设计"></a> 3. 流量大、数据多的商品详情页系统该如何设计？</h2><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20220407164745.png" alt="" /></p><h2 id="4-复杂而又重要的购物车系统应该如何设计"><a class="markdownIt-Anchor" href="#4-复杂而又重要的购物车系统应该如何设计"></a> 4. 复杂而又重要的购物车系统，应该如何设计？</h2><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20220408142059.png" alt="" /></p><h2 id="5-事务账户余额总是对不上账怎么办"><a class="markdownIt-Anchor" href="#5-事务账户余额总是对不上账怎么办"></a> 5. 事务：账户余额总是对不上账，怎么办？</h2><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20220408152524.png" alt="" /></p><h2 id="6-分布式事务如何保证多个系统间的数据是一致的"><a class="markdownIt-Anchor" href="#6-分布式事务如何保证多个系统间的数据是一致的"></a> 6. 分布式事务：如何保证多个系统间的数据是一致的？</h2><p>分布式事务常见解决方案：</p><ul><li>2PC</li><li>3PC</li><li>TCC</li><li>Saga</li><li>本地消息表</li></ul><blockquote><p>个人以前总结：<a href="https://dunwu.github.io/design/distributed/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1.html">分布式事务</a></p></blockquote><h2 id="7-如何用-elasticsearch-构建商品搜索系统"><a class="markdownIt-Anchor" href="#7-如何用-elasticsearch-构建商品搜索系统"></a> 7. 如何用 Elasticsearch 构建商品搜索系统？</h2><p>搜索领域的核心问题是进行全文匹配。一般的关系型数据库，如 Mysql 的索引（InnoDB 为 B 树索引）不适用于全文检索，导致查询时只能全表扫描，性能很差。</p><p>搜索引擎（典型代表：Elasticsearch）通过倒排索引技术，很好的支持了全文检索。但是，倒排索引的写入和更新性能相较于 B 树索引较差，因此不适用于更新频繁的数据。</p><h2 id="8-mysql-ha如何将删库跑路的损失降到最低"><a class="markdownIt-Anchor" href="#8-mysql-ha如何将删库跑路的损失降到最低"></a> 8. MySQL HA：如何将“删库跑路”的损失降到最低？</h2><p>Mysql 复制（略）</p><h2 id="9-一个几乎每个系统必踩的坑儿访问数据库超时"><a class="markdownIt-Anchor" href="#9-一个几乎每个系统必踩的坑儿访问数据库超时"></a> 9. 一个几乎每个系统必踩的坑儿：访问数据库超时</h2><p>数据库超时分析经验：</p><ul><li>根据故障时段在系统忙时，推断出故障是跟支持用户访问的功能有关。</li><li>根据系统能在流量峰值过后自动恢复这一现象，排除后台服务被大量请求打死的可能性。</li><li>根据 CPU 利用率的变化曲线，如果满足一定的周期性波动，可推断出大概率和定时任务有关。这些定时任务负责刷新数据缓存。如果确实是因为刷新缓存定时任务导致的，需要针对性优化。</li><li>如果 Mysql CPU 过高，大概率是慢 SQL 导致的，优先排查慢 SQL 日志，找出查询特别慢的表。看看该表是不是需要加缓存。</li></ul><p>避免访问数据库超时的注意点：</p><ul><li>开发时，考虑 SQL 相关表的数据规模，查询性能，是否匹配索引等等，避免出现慢 SQL</li><li>设计上，考虑减少查询次数，如使用缓存</li><li>系统支持自动杀慢 SQL</li><li>支持熔断、降级，减少故障影响范围</li></ul><h2 id="10-怎么能避免写出慢-sql"><a class="markdownIt-Anchor" href="#10-怎么能避免写出慢-sql"></a> 10. 怎么能避免写出慢 SQL？</h2><p>数据表不宜过大，一般不要超过千万条数据。</p><p>根据实际情况，尽量设计好索引，以提高查询、排序效率。</p><p>如果出现慢 SQL，需要改造索引时，可以通过执行计划进行分析。</p><blockquote><p>个人过往总结：<a href="https://dunwu.github.io/db-tutorial/sql/mysql/mysql-optimization.html">Mysql 性能优化</a></p></blockquote><h2 id="11-走进黑盒sql-是如何在数据库中执行的"><a class="markdownIt-Anchor" href="#11-走进黑盒sql-是如何在数据库中执行的"></a> 11. 走进黑盒：SQL 是如何在数据库中执行的？</h2><blockquote><p>个人过往总结：<a href="https://github.com/dunwu/db-tutorial/blob/master/docs/sql/mysql/mysql-workflow.md" target="_blank" rel="noopener">Mysql 工作流</a></p></blockquote><h2 id="12-mysql-如何应对高并发一使用缓存保护-mysql"><a class="markdownIt-Anchor" href="#12-mysql-如何应对高并发一使用缓存保护-mysql"></a> 12. MySQL 如何应对高并发（一）：使用缓存保护 MySQL</h2><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20220413101029.png" alt="" /></p><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20220413101039.png" alt="" /></p><h2 id="13-mysql-如何应对高并发二读写分离"><a class="markdownIt-Anchor" href="#13-mysql-如何应对高并发二读写分离"></a> 13. MySQL 如何应对高并发（二）：读写分离</h2><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20220413160150.png" alt="" /></p><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/cs/database/mysql/master-slave-proxy.png" alt="img" /></p><h2 id="14-mysql-主从数据库同步是如何实现的"><a class="markdownIt-Anchor" href="#14-mysql-主从数据库同步是如何实现的"></a> 14. MySQL 主从数据库同步是如何实现的？</h2><p>基于 binlog 进行数据同步</p><h2 id="15-订单数据越来越多数据库越来越慢该怎么办"><a class="markdownIt-Anchor" href="#15-订单数据越来越多数据库越来越慢该怎么办"></a> 15. 订单数据越来越多，数据库越来越慢该怎么办？</h2><p>针对大表，为了优化其查询性能，可以将历史数据归档。一般可以考虑归档到列式数据库，如：Hive</p><h2 id="16-mysql存储海量数据的最后一招分库分表"><a class="markdownIt-Anchor" href="#16-mysql存储海量数据的最后一招分库分表"></a> 16. MySQL存储海量数据的最后一招：分库分表</h2><p>分库分表</p><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20220413174922.png" alt="" /></p><h2 id="17-用-redis-构建缓存集群的最佳实践有哪些"><a class="markdownIt-Anchor" href="#17-用-redis-构建缓存集群的最佳实践有哪些"></a> 17. 用 Redis 构建缓存集群的最佳实践有哪些</h2><p>Redis 3.0 后，官方提供 Redis Cluster 来解决数据量大、高可用和高并发问题。</p><blockquote><p>相关文章：<a href="https://dunwu.github.io/blog/%E6%95%B0%E6%8D%AE%E5%BA%93/05.KV%E6%95%B0%E6%8D%AE%E5%BA%93/01.Redis/07.Redis%E9%9B%86%E7%BE%A4/">Redis 集群</a></p></blockquote><h2 id="18-大厂都是怎么做-mysql-to-redis-同步的"><a class="markdownIt-Anchor" href="#18-大厂都是怎么做-mysql-to-redis-同步的"></a> 18. 大厂都是怎么做 MySQL to Redis 同步的?</h2><p>缓存穿透：把全量数据都放在 Redis 集群，服务通过接受 MQ 消息，去触发更新缓存数据。</p><p>使用 Binlog 实时更新 Redis 缓存，如 <a href="https://github.com/alibaba/canal" target="_blank" rel="noopener">Canal</a></p><h2 id="19-分布式存储你知道对象存储是如何保存图片文件的吗"><a class="markdownIt-Anchor" href="#19-分布式存储你知道对象存储是如何保存图片文件的吗"></a> 19. 分布式存储：你知道对象存储是如何保存图片文件的吗？</h2><p>保存图片、音频、视频这种相对较大的文件，一般使用对象存储。如：HDFS 等。</p><p>元数据管理：ZooKeeper、etcd、Nacos</p><p>对象如何拆分和保存：将大文件分块（block），提升 IO效率并方便维护。</p><h2 id="20-跨系统实时同步数据分布式事务是唯一的解决方案吗"><a class="markdownIt-Anchor" href="#20-跨系统实时同步数据分布式事务是唯一的解决方案吗"></a> 20. 跨系统实时同步数据，分布式事务是唯一的解决方案吗？</h2><p>跨系统实时同步数据：</p><ul><li>早期方案：使用 ETL 定时同步数据，在 T+1 时刻去同步上一周期的数据，然后进行计算和分析。</li><li>使用 Binlog 和 MQ 构建实时数据同步系统</li></ul><p>如何保证数据同步的实时性</p><ul><li>为了能够支撑众多下游数据库实时同步的需求，可以通过 MQ 解耦上下游，Binlog 先发送到 MQ 中，下游各业务方可以消费 MQ 中的消息再写入各自的数据库。</li><li>如果下游处理能力不能满足要求，可以增加 MQ 中的分区数量实现并发同步，但需要结合同步的业务数据特点，把具有因果关系的数据哈希到相同分区上，才能避免因为并发乱序而出现数据同步错误的问题。</li></ul><h2 id="21-如何在不停机的情况下安全地更换数据库"><a class="markdownIt-Anchor" href="#21-如何在不停机的情况下安全地更换数据库"></a> 21. 如何在不停机的情况下，安全地更换数据库？</h2><ul><li><strong>停机迁移/扩容</strong><ul><li>优点：简单粗暴；没有数据一致性问题</li><li>缺点：需要停机</li></ul></li><li><strong>双写迁移</strong><ul><li>优点：不需要停机</li><li>缺点：方案较复杂</li></ul></li><li><strong>主从升级</strong><ul><li>优点：不需要停机；无需数据迁移</li><li>缺点：需要冗余的从库</li></ul></li></ul><h2 id="22-类似点击流这样的海量数据应该如何存储"><a class="markdownIt-Anchor" href="#22-类似点击流这样的海量数据应该如何存储"></a> 22. 类似“点击流”这样的海量数据应该如何存储？</h2><p>使用 Kafka 暂存海量原始数据，然后再使用大数据计算框架（Spark、Flink）进行计算。</p><p>其他方案：</p><p>分布式流数据存储，如：Pravega、Pulsar 的存储引擎 BookKeeper</p><p>时序数据库，如：InfluxDB、OpenTSDB 等。</p><h2 id="23-面对海量数据如何才能查得更快"><a class="markdownIt-Anchor" href="#23-面对海量数据如何才能查得更快"></a> 23. 面对海量数据，如何才能查得更快</h2><p>实时计算：Flink、Storm</p><p>批处理计算：Map-Reduce、Spark</p><p>海量数据存储：</p><ul><li>列式数据库（在正确使用的前提下，10GB 量级的数据查询基本上可以做到秒级返回）：HBase、Cassandra</li><li>搜索引擎（对于 TB 量级以下的数据，如果可以接受相对比较贵的硬件成本）：Elasticsearch</li></ul><h2 id="24-mysql-经常遇到的高可用-分片问题newsql-是如何解决的"><a class="markdownIt-Anchor" href="#24-mysql-经常遇到的高可用-分片问题newsql-是如何解决的"></a> 24. MySQL 经常遇到的高可用、分片问题，NewSQL 是如何解决的？</h2><p>安利 CockroachDB、RocksDB、OceanBase</p><h2 id="25-rocksdb不丢数据的高性能-kv-存储"><a class="markdownIt-Anchor" href="#25-rocksdb不丢数据的高性能-kv-存储"></a> 25. RocksDB：不丢数据的高性能 KV 存储、</h2><p>越来越多的新生代数据库，都选择 RocksDB 作为它们的存储引擎。</p><p>Redis 是一个内存数据库，所以它很快。</p><p>RocksDB 是一个持久化的 KV 存储，它需要保证每条数据都要安全地写到磁盘上。磁盘的读写性能和内<br />存读写性能差着一两个数量级，读写磁盘的 RocksDB，能和读写内存的 Redis 做到相近的性能，这就是 RocksDB 的价值所在了。</p><p>RocksDB 性能好，是由于使用了 LSM 树结构。</p><p>LSM-Tree 的全称是：The Log-Structured Merge-Tree，是一种非常复杂的复合数据结构，它包含了 WAL（Write Ahead Log）、跳表（SkipList）和一个分层的有序表（SSTable，Sorted String Table）。</p><h2 id="26-参考资料"><a class="markdownIt-Anchor" href="#26-参考资料"></a> 26. 参考资料</h2><ul><li><a href="https://time.geekbang.org/column/intro/100046801" target="_blank" rel="noopener">后端存储实战课</a> - 极客教程【入门】：讲解存储在电商领域的种种应用和一些基本特性</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;后端存储实战课笔记&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#后端存储实战课笔记&quot;&gt;&lt;/a&gt; 后端存储实战课笔记&lt;/h1&gt;
&lt;h2 id=&quot;1-课前加餐丨电商系统是如何设计的&quot;&gt;&lt;a class=&quot;markdownIt-Anchor
      
    
    </summary>
    
    
      <category term="笔记" scheme="https://dunwu.github.io/blog/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="架构" scheme="https://dunwu.github.io/blog/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>数据结构与数据库索引</title>
    <link href="https://dunwu.github.io/blog/2022/03/27/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95/"/>
    <id>https://dunwu.github.io/blog/2022/03/27/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95/</id>
    <published>2022-03-27T15:39:10.000Z</published>
    <updated>2022-04-14T08:45:53.606Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据结构与数据库索引"><a class="markdownIt-Anchor" href="#数据结构与数据库索引"></a> 数据结构与数据库索引</h1><blockquote><p>关键词：链表、数组、散列表、红黑树、B+ 树、LSM 树、跳表</p></blockquote><h2 id="引言"><a class="markdownIt-Anchor" href="#引言"></a> 引言</h2><p><strong>数据库</strong>是“按照 <strong>数据结构</strong> 来组织、存储和管理数据的仓库”。是一个长期存储在计算机内的、有组织的、可共享的、统一管理的大量数据的集合。</p><p>——上面这句定义对数据库的定义来自百度百科。通过这个定义，我们也能明显看出数据结构是实现数据库的基石。</p><p>从本质来看，数据库只负责两件事：读数据、写数据；而数据结构研究的是如何合理组织数据，尽可能提升读、写数据的效率，这恰好是数据库的核心问题。因此，数据结构与数据库这两个领域有非常多的交集。其中，数据库索引最能体现二者的紧密关联。</p><p><strong>索引是数据库为了提高查找效率的一种数据结构</strong>。索引基于原始数据衍生而来，它的主要作用是缩小检索的数据范围，提升查询性能。通俗来说，索引在数据库中的作用就像是一本书的目录索引。索引对于良好的性能非常关键，在数据量小且负载较低时，不恰当的索引对于性能的影响可能还不明显；但随着数据量逐渐增大，性能则会急剧下降。因此，<strong>索引优化应该是查询性能优化的最有效手段</strong>。</p><p>很多数据库允许单独添加和删除索引，而不影响数据库的内容，它只会影响查询性能。维护额外的结构势必会引入开销，特别是在新数据写入时。对于写入，它很难超过简单地追加文件方式的性能，因为那已经是最简单的写操作了。由于每次写数据时，需要更新索引，因此任何类型的索引通常都会降低写的速度。</p><p>本文以一些常见的数据库为例，分析它们的索引采用了什么样的数据结构，有什么利弊，为何如此设计。</p><h2 id="数组和链表"><a class="markdownIt-Anchor" href="#数组和链表"></a> 数组和链表</h2><p>数组和链表分别代表了连续空间和不连续空间的存储方式，它们是线性表（Linear List）的典型代表。其他所有的数据结构，比如栈、队列、二叉树、B+ 树等，实际上都是这两者的结合和变化。</p><p><strong>数组用连续的内存空间来存储数据</strong>。数组<strong>支持随机访问，根据下标随机访问的时间复杂度为 <code>O(1)</code></strong>。但这并不代表数组的查找时间复杂度也是 <code>O(1)</code>。</p><ul><li><strong>对于无序数组，只能顺序查找，其时间复杂度为 <code>O(n)</code></strong>。</li><li><strong>对于有序数组，可以应用二分查找法，其时间复杂度为 <code>O(log n)</code></strong>。</li></ul><p>在有序数组上应用二分查找法如此高效，为什么几乎没有数据库直接使用数组作为索引？这是因为它的限制条件：<strong>数据有序</strong>——为了保证数据有序，每次添加、删除数组数据时，都必须要进行数据调整，来保证其有序，而 <strong>数组的插入/删除操作，时间复杂度为 <code>O(n)</code></strong>。此外，由于数组空间大小固定，每次扩容只能采用复制数组的方式。数组的这些特性，决定了它不适合用于数据频繁变化的应用场景。</p><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20220320115836.png" alt="img" /></p><p><strong>链表用不连续的内存空间来存储数据；并通过一个指针按顺序将这些空间串起来，形成一条链</strong>。</p><p>区别于数组，链表中的元素不是存储在内存中连续的一片区域，链表中的数据存储在每一个称之为「结点」复合区域里，在每一个结点除了存储数据以外，还保存了到下一个节点的指针（Pointer）。由于不必按顺序存储，<strong>链表的插入/删除操作，时间复杂度为 <code>O(1)</code></strong>，但是，链表只支持顺序访问，其 <strong>查找时间复杂度为 <code>O(n)</code></strong>。其低效的查找方式，决定了链表不适合作为索引。</p><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20220320174829.png" alt="img" /></p><h2 id="哈希索引"><a class="markdownIt-Anchor" href="#哈希索引"></a> 哈希索引</h2><p>哈希表是一种以键 - 值（key-value）对形式存储数据的结构，我们只要输入待查找的值即 key，就可以找到其对应的值即 Value。</p><p><strong>哈希表</strong> 使用 <strong>哈希函数</strong> 组织数据，以支持快速插入和搜索的数据结构。哈希表的本质是一个数组，其思路是：使用 Hash 函数将 Key 转换为数组下标，利用数组的随机访问特性，使得我们能在 <code>O(1)</code> 的时间代价内完成检索。</p><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20220320201844.png" alt="img" /></p><p>有两种不同类型的哈希表：<strong>哈希集合</strong> 和 <strong>哈希映射</strong>。</p><ul><li><strong>哈希集合</strong> 是集合数据结构的实现之一，用于存储非重复值。</li><li><strong>哈希映射</strong> 是映射 数据结构的实现之一，用于存储键值对。</li></ul><p>哈希索引基于哈希表实现，<strong>只适用于等值查询</strong>。对于每一行数据，哈希索引都会将所有的索引列计算一个哈希码（<code>hashcode</code>），哈希码是一个较小的值。哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存指向每个数据行的指针。</p><p>✔ 哈希索引的<strong>优点</strong>：</p><ul><li>因为索引数据结构紧凑，所以<strong>查询速度非常快</strong>。</li></ul><p>❌ 哈希索引的<strong>缺点</strong>：</p><ul><li>哈希索引值包含哈希值和行指针，而不存储字段值，所以不能使用索引中的值来避免读取行。不过，访问内存中的行的速度很快，所以大部分情况下这一点对性能影响不大。</li><li><strong>哈希索引数据不是按照索引值顺序存储的</strong>，所以<strong>无法用于排序</strong>。</li><li>哈希索引<strong>不支持部分索引匹配查找</strong>，因为哈希索引时使用索引列的全部内容来进行哈希计算的。如，在数据列 (A,B) 上建立哈希索引，如果查询只有数据列 A，无法使用该索引。</li><li>哈希索引<strong>只支持等值比较查询</strong>，包括 <code>=</code>、<code>IN()</code>、<code>&lt;=&gt;</code>；不支持任何范围查询，如 <code>WHERE price &gt; 100</code>。</li><li>哈希索引有<strong>可能出现哈希冲突</strong><ul><li>出现哈希冲突时，必须遍历链表中所有的行指针，逐行比较，直到找到符合条件的行。</li><li>如果哈希冲突多的话，维护索引的代价会很高。</li></ul></li></ul><blockquote><p>因为种种限制，所以哈希索引只适用于特定的场合。而一旦使用哈希索引，则它带来的性能提升会非常显著。例如，Mysql 中的 Memory 存储引擎就显示的支持哈希索引。</p></blockquote><h2 id="b-tree-索引"><a class="markdownIt-Anchor" href="#b-tree-索引"></a> B-Tree 索引</h2><p>通常我们所说的 B 树索引是指 <code>B-Tree</code> 索引，它是目前关系型数据库中查找数据最为常用和有效的索引，大多数存储引擎都支持这种索引。使用 <code>B-Tree</code> 这个术语，是因为 MySQL 在 <code>CREATE TABLE</code> 或其它语句中使用了这个关键字，但实际上不同的存储引擎可能使用不同的数据结构，比如 InnoDB 使用的是 <code>B+Tree</code>索引；而 MyISAM 使用的是 <code>B-Tree</code>索引。</p><p><code>B-Tree</code> 索引中的 B 是指 <code>balance</code>，意为平衡。需要注意的是，<code>B-Tree</code> 索引并不能找到一个给定键值的具体行，它找到的只是被查找数据行所在的页，接着数据库会把页读入到内存，再在内存中进行查找，最后得到要查找的数据。</p><h3 id="二叉搜索树"><a class="markdownIt-Anchor" href="#二叉搜索树"></a> 二叉搜索树</h3><p>二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。其查询时间复杂度是 <code>O(log n)</code>。</p><p>当然为了维持 <code>O(log n)</code> 的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 <code>O(log n)</code>。</p><p>随着数据库中数据的增加，索引本身大小随之增加，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘 I/O 消耗，相对于内存存取，I/O 存取的消耗要高几个数量级。可以想象一下一棵几百万节点的二叉树的深度是多少？如果将这么大深度的一颗二叉树放磁盘上，每读取一个节点，需要一次磁盘的 I/O 读取，整个查找的耗时显然是不能够接受的。那么如何减少查找过程中的 I/O 存取次数？</p><p>一种行之有效的解决方法是减少树的深度，将<strong>二叉树变为 N 叉树</strong>（多路搜索树），而 <strong>B+ 树就是一种多路搜索树</strong>。</p><h3 id="btree-索引"><a class="markdownIt-Anchor" href="#btree-索引"></a> <code>B+Tree</code> 索引</h3><p>B+ 树索引适用于<strong>全键值查找</strong>、<strong>键值范围查找</strong>和<strong>键前缀查找</strong>，其中键前缀查找只适用于最左前缀查找。</p><p>理解 <code>B+Tree</code>，只需要理解其最重要的两个特征即可：</p><ul><li>第一，所有的关键字（可以理解为数据）都存储在叶子节点，非叶子节点并不存储真正的数据，所有记录节点都是按键值大小顺序存放在同一层叶子节点上。</li><li>其次，所有的叶子节点由指针连接。如下图为简化了的<code>B+Tree</code>。</li></ul><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20200304235424.jpg" alt="img" /></p><p>根据叶子节点的内容，索引类型分为主键索引和非主键索引。</p><ul><li><strong>聚簇索引（clustered）</strong>：又称为主键索引，其叶子节点存的是整行数据。因为无法同时把数据行存放在两个不同的地方，所以<strong>一个表只能有一个聚簇索引</strong>。<strong>InnoDB 的聚簇索引实际是在同一个结构中保存了 B 树的索引和数据行</strong>。</li><li>非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为<strong>二级索引（secondary）</strong>。数据存储在一个位置，索引存储在另一个位置，索引中包含指向数据存储位置的指针。可以有多个，小于 249 个。</li></ul><p><strong>聚簇表示数据行和相邻的键值紧凑地存储在一起，因为数据紧凑，所以访问快</strong>。因为无法同时把数据行存放在两个不同的地方，所以<strong>一个表只能有一个聚簇索引</strong>。</p><p><strong>聚簇索引和非聚簇索引的查询有什么区别</strong></p><ul><li>如果语句是 <code>select * from T where ID=500</code>，即聚簇索引查询方式，则只需要搜索 ID 这棵 B+ 树；</li><li>如果语句是 <code>select * from T where k=5</code>，即非聚簇索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为<strong>回表</strong>。</li></ul><p>也就是说，<strong>基于非聚簇索引的查询需要多扫描一棵索引树</strong>。因此，我们在应用中应该尽量使用主键查询。</p><p><strong>显然，主键长度越小，非聚簇索引的叶子节点就越小，非聚簇索引占用的空间也就越小。</strong></p><p>自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT。从性能和存储空间方面考量，自增主键往往是更合理的选择。有没有什么场景适合用业务字段直接做主键的呢？还是有的。比如，有些业务的场景需求是这样的：</p><ul><li>只有一个索引；</li><li>该索引必须是唯一索引。</li></ul><p>由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。</p><hr /><p>内存是半导体元件。对于内存而言，只要给出了内存地址，我们就可以直接访问该地址取出数据。这个过程具有高效的随机访问特性，因此内存也叫随机访问存储器（Random Access Memory，即 RAM）。内存的访问速度很快，但是价格相对较昂贵，因此一般的计算机内存空间都相对较小。</p><p>而磁盘是机械器件。磁盘访问数据时，需要等磁盘盘片旋转到磁头下，才能读取相应的数据。尽管磁盘的旋转速度很快，但是和内存的随机访问相比，性能差距非常大。一般来说，如果是随机读写，会有 10 万到 100 万倍左右的差距。但如果是顺序访问大批量数据的话，磁盘的性能和内存就是一个数量级的。</p><p>磁盘的最小读写单位是扇区，较早期的磁盘一个扇区是 <strong><code>512</code></strong> 字节。随着磁盘技术的发展，目前常见的磁盘扇区是 <strong><code>4K</code></strong> 个字节。操作系统一次会读写多个扇区，所以操作系统的最小读写单位是块（Block），也叫作簇（Cluster）。当我们要从磁盘中读取一个数据时，操作系统会一次性将整个块都读出来。因此，对于大批量的顺序读写来说，磁盘的效率会比随机读写高许多。</p><p>假设有一个有序数组存储在硬盘中，如果它足够大，那么它会存储在多个块中。当我们要对这个数组使用二分查找时，需要先找到中间元素所在的块，将这个块从磁盘中读到内存里，然后在内存中进行二分查找。如果下一步要读的元素在其他块中，则需要再将相应块从磁盘中读入内存。直到查询结束，这个过程可能会多次访问磁盘。我们可以看到，这样的检索性能非常低。</p><p>由于磁盘相对于内存而言访问速度实在太慢，因此，对于磁盘上数据的高效检索，我们有一个极其重要的原则：对磁盘的访问次数要尽可能的少！</p><p>将索引和数据分离就是一种常见的设计思路。在数据频繁变化的场景中，有序数组并不是一个最好的选择，二叉检索树或者哈希表往往更有普适性。但是，哈希表由于缺乏范围检索的能力，在一些场合也不适用。因此，二叉检索树这种树形结构是许多常见检索系统的实施方案。</p><p>随着索引数据越来越大，直到无法完全加载到内存中，这是需要将索引数据也存入磁盘中。B+ 树给出了将树形索引的所有节点都存在磁盘上的高效检索方案。操作系统对磁盘数据的访问是以块为单位的。因此，如果我们想将树型索引的一个节点从磁盘中读出，即使该节点的数据量很小（比如说只有几个字节），但磁盘依然会将整个块的数据全部读出来，而不是只读这一小部分数据，这会让有效读取效率很低。B+ 树的一个关键设计，就是让一个节点的大小等于一个块的大小。节点内存储的数据，不是一个元素，而是一个可以装 m 个元素的有序数组。这样一来，我们就可以将磁盘一次读取的数据全部利用起来，使得读取效率最大化。</p><p>B+ 树还有另一个设计，就是将所有的节点分为内部节点和叶子节点。内部节点仅存储 key 和维持树形结构的指针，并不存储 key 对应的数据（无论是具体数据还是文件位置信息）。这样内部节点就能存储更多的索引数据，我们也就可以使用最少的内部节点，将所有数据组织起来了。而叶子节点仅存储 key 和对应数据，不存储维持树形结构的指针。通过这样的设计，B+ 树就能做到节点的空间利用率最大化。此外，B+ 树还将同一层的所有节点串成了有序的双向链表，这样一来，B+ 树就同时具备了良好的范围查询能力和灵活调整的能力了。</p><p>因此，B+ 树是一棵完全平衡的 m 阶多叉树。所谓的 m 阶，指的是每个节点最多有 m 个子节点，并且每个节点里都存了一个紧凑的可包含 m 个元素的数组。</p><p>即使是复杂的 B+ 树，我们将它拆解开来，其实也是由简单的数组、链表和树组成的，而且 B+ 树的检索过程其实也是二分查找。因此，如果 B+ 树完全加载在内存中的话，它的检索效率其实并不会比有序数组或者二叉检索树更<br />高，也还是二分查找的 log(n) 的效率。并且，它还比数组和二叉检索树更加复杂，还会带来额外的开销。</p><p>另外，这一节还有一个很重要的设计思想需要你掌握，那就是将索引和数据分离。通过这样的方式，我们能将索引的数组大小保持在一个较小的范围内，让它能加载在内存中。在许多大规模系统中，都是使用这个设计思想来精简索引的。而且，B+ 树的内部节点和叶子节点的区分，其实也是索引和数据分离的一次实践。</p><p>MySQL 中的 B+ 树实现其实有两种，一种是 MyISAM 引擎，另一种是 InnoDB 引擎。它们的核心区别就在于，数据和索引是否是分离的。</p><p>在 MyISAM 引擎中，B+ 树的叶子节点仅存储了数据的位置指针，这是一种索引和数据分离的设计方案，叫作非聚集索引。如果要保证 MyISAM 的数据一致性，那我们需要在表级别上进行加锁处理。</p><p>在 InnoDB 中，B+ 树的叶子节点直接存储了具体数据，这是一种索引和数据一体的方案。叫作聚集索引。由于数据直接就存在索引的叶子节点中，因此 InnoDB 不需要给全表加锁来保证一致性，它只需要支持行级的锁就可以了。</p><h2 id="lsm-树"><a class="markdownIt-Anchor" href="#lsm-树"></a> LSM 树</h2><p>B+ 树的数据都存储在叶子节点中，而叶子节点一般都存储在磁盘中。因此，每次插入的新数据都需要随机写入磁盘，而随机写入的性能非常慢。如果是一个日志系统，每秒钟要写入上千条甚至上万条数据，这样的磁盘操作代价会使得系统性能急剧下降，甚至无法使用。</p><p>操作系统对磁盘的读写是以块为单位的，我们能否以块为单位写入，而不是每次插入一个数据都要随机写入磁盘呢？这样是不是就可以大幅度减少写入操作了呢？解决方案就是：<strong>LSM 树</strong>（Log Structured Merge Trees）。</p><p>LSM 树就是根据这个思路设计了这样一个机制：当数据写入时，延迟写磁盘，将数据先存放在内存中的树里，进行常规的存储和查询。当内存中的树持续变大达到阈值时，再批量地以块为单位写入磁盘的树中。因此，LSM 树至少需要由两棵树组成，一棵是存储在内存中较小的 C0 树，另一棵是存储在磁盘中较大的 C1 树。</p><p>LSM 树具有以下 3 个特点：</p><ol><li>将索引分为内存和磁盘两部分，并在内存达到阈值时启动树合并（Merge Trees）；</li><li>用批量写入代替随机写入，并且用预写日志 WAL 技术（Write AheadLog，预写日志技术）保证内存数据，在系统崩溃后可以被恢复；</li><li>数据采取类似日志追加写的方式写入（Log Structured）磁盘，以顺序写的方式提高写<br />入效率。</li></ol><p>LSM 树的这些特点，使得它相对于 B+ 树，在写入性能上有大幅提升。所以，许多 NoSQL 系统都使用 LSM 树作为检索引擎，而且还对 LSM 树进行了优化以提升检索性能。</p><h2 id="倒排索引"><a class="markdownIt-Anchor" href="#倒排索引"></a> 倒排索引</h2><p>倒排索引的核心其实并不复杂，它的具体实现其实是哈希表，只是它不是将文档 ID 或者题目作为 key，而是反过来，通过将内容或者属性作为 key 来存储对应的文档列表，使得我们能在 O(1) 的时间代价内完成查询。</p><p>尽管原理并不复杂，但是倒排索引是许多检索引擎的核心。比如说，数据库的全文索引功能、搜索引擎的索引、广告引擎和推荐引擎，都使用了倒排索引技术来实现检索功能。</p><h2 id="索引的维护"><a class="markdownIt-Anchor" href="#索引的维护"></a> 索引的维护</h2><h3 id="创建索引"><a class="markdownIt-Anchor" href="#创建索引"></a> 创建索引</h3><ul><li><strong>数据压缩</strong>：一个是尽可能地将数据加载到内存中，因为内存的检索效率大大高于磁盘。那为了将数据更多地加载到内存中，索引压缩是一个重要的研究方向。</li><li><strong>分支处理</strong>：另一个是将大数据集合拆成多个小数据集合来处理。这其实就是分布式系统的核心思想。</li></ul><h3 id="更新索引"><a class="markdownIt-Anchor" href="#更新索引"></a> 更新索引</h3><p>（1）Double Buffer（双缓冲）机制</p><p>就是在内存中同时保存两份一样的索引，一个是索引 A，一个是索引 B。两个索引保持一个读、一个写，并且来回切换，最终完成高性能的索引更新。</p><p>优点：简单高效</p><p>缺点：达到一定数据量级后，会带来翻倍的内存开销，甚至有些索引存储在磁盘上的情况下，更是无法使用此机制。</p><p>（2）全量索引和增量索引</p><p>将新接收到的数据单独建立一个可以存在内存中的倒排索引，也就是增量索引。当查询发生的时候，我们会同时查询全量索引和增量索引，将合并的结果作为总的结果输出。</p><p>因为增量索引相对全量索引而言会小很多，内存资源消耗在可承受范围，所以我们可以使用 Double Buffer 机制<br />对增量索引进行索引更新。这样一来，增量索引就可以做到无锁访问。而全量索引本身就是只读的，也不需要加锁。因此，整个检索过程都可以做到无锁访问，也就提高了系统的检索效率。</p><h2 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h2><ul><li><a href="https://book.douban.com/subject/30329536/" target="_blank" rel="noopener">《数据密集型应用系统设计》</a></li><li><a href="https://time.geekbang.org/column/intro/100017301" target="_blank" rel="noopener">数据结构与算法之美</a></li><li><a href="https://time.geekbang.org/column/intro/100048401" target="_blank" rel="noopener">检索技术核心 20 讲</a></li><li><a href="https://www.cise.ufl.edu/~mschneid/Research/papers/HS05BoCh.pdf" target="_blank" rel="noopener">Data Structures for Databases</a></li><li><a href="https://people.csail.mit.edu/bradley/BenderKuszmaul-tutorial-xldb12.pdf" target="_blank" rel="noopener">Data Structures and Algorithms for Big Databases</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;数据结构与数据库索引&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#数据结构与数据库索引&quot;&gt;&lt;/a&gt; 数据结构与数据库索引&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;关键词：链表、数组、散列表、红黑树、B+ 树、LSM 树、跳表&lt;/p&gt;
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="数据库综合" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%BC%E5%90%88/"/>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="综合" scheme="https://dunwu.github.io/blog/tags/%E7%BB%BC%E5%90%88/"/>
    
      <category term="数据结构" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
      <category term="索引" scheme="https://dunwu.github.io/blog/tags/%E7%B4%A2%E5%BC%95/"/>
    
  </entry>
  
  <entry>
    <title>检索技术核心 20 讲笔记</title>
    <link href="https://dunwu.github.io/blog/2022/03/04/%E6%A3%80%E7%B4%A2%E6%8A%80%E6%9C%AF%E6%A0%B8%E5%BF%83-20-%E8%AE%B2%E7%AC%94%E8%AE%B0/"/>
    <id>https://dunwu.github.io/blog/2022/03/04/%E6%A3%80%E7%B4%A2%E6%8A%80%E6%9C%AF%E6%A0%B8%E5%BF%83-20-%E8%AE%B2%E7%AC%94%E8%AE%B0/</id>
    <published>2022-03-04T12:03:00.000Z</published>
    <updated>2022-04-14T08:45:53.614Z</updated>
    
    <content type="html"><![CDATA[<h1 id="检索技术核心-20-讲笔记"><a class="markdownIt-Anchor" href="#检索技术核心-20-讲笔记"></a> 检索技术核心 20 讲笔记</h1><blockquote><p>伸缩性架构是指不需要改变系统的软硬件设计，仅通过改变部署服务器数量就可以扩大或缩小系统的服务处理能力。</p></blockquote><h2 id="1-线性结构检索"><a class="markdownIt-Anchor" href="#1-线性结构检索"></a> 1. 线性结构检索</h2><p>检索的核心思想：合理组织数据，尽可能快速减少查询范围，可以提升检索效率。</p><p><strong><em>数组和链表的比较</em></strong></p><ul><li><strong>存储方式</strong><ul><li>数组用 <strong>连续</strong> 的内存空间来存储数据。</li><li>链表用 <strong>不连续</strong> 的内存空间来存储数据；并通过一个指针按顺序将这些空间串起来，形成一条链。</li></ul></li><li><strong>访问方式</strong><ul><li>数组<strong>支持随机访问</strong>。根据下标随机访问的时间复杂度为 <code>O(1)</code></li><li>链表<strong>不支持随机访问</strong>，只能顺序访问。</li></ul></li><li><strong>空间大小</strong><ul><li>数组空间<strong>大小固定</strong>，扩容只能采用复制数组的方式。</li><li>链表空间<strong>大小不固定</strong>，扩容灵活。</li></ul></li><li><strong>效率比较</strong><ul><li>数组的 <strong>查找</strong> 效率高于链表。</li><li>链表的 <strong>添加</strong>、<strong>删除</strong> 效率高于数组。</li></ul></li></ul><h2 id="2-非线性结构检索"><a class="markdownIt-Anchor" href="#2-非线性结构检索"></a> 2. 非线性结构检索</h2><ul><li>对于无序数组，只能顺序查找，其时间复杂度为 <code>O(n)</code>。</li><li>对于有序数组，可以应用二分查找法，其时间复杂度为 <code>O(log n)</code>。</li></ul><p>显然，二分查找法很高效，但是它有限制条件：数据有序。为了保证数据有序，添加、删除数组数据时，必须要进行数据调整，来保证其有序。</p><p>首先，对于数据频繁变化的应用场景，有序数组并不是最适合的解决方案。我们一般要考虑采用非连续存储的数据结构来灵活调整。同时，为了提高检索效率，我们还要采取合理的组织方式，让这些非连续存储的数据结构能够使用二分查找算法。</p><p>数据组织的方式有两种，一种是二叉检索树。一个平衡的二叉检索树使用二分查找的检索效率是 <code>O(log n)</code>，但如果我们不做额外的平衡控制的话，二叉检索树的检索性能最差会退化到 <code>O(n)</code>，也就和单链表一样了。所以，AVL 树和红黑树这样平衡性更强的二叉检索树，在实际工作中应用更多。</p><p>除了树结构以外，另一种数据组织方式是跳表。跳表也具备二分查找的能力，理想跳表的检索效率是 <code>O(log n)</code>。为了保证跳表的检索空间平衡，跳表为每个节点随机生成层级，这样的实现方式比 AVL 树和红黑树更简单。</p><p>无论是二叉检索树还是跳表，它们都是通过将数据进行合理组织，然后尽可能地平衡划分检索空间，使得我们能采用二分查找的思路快速地缩减查找范围，达到 <code>O(log n)</code> 的检索效率。</p><h2 id="3-哈希检索"><a class="markdownIt-Anchor" href="#3-哈希检索"></a> 3. 哈希检索</h2><p>散列表的思路是：使用 Hash 函数将 Key 转换为数组下标。</p><p>哈希表的本质是一个数组，它通过 Hash 函数将查询的 Key 转为数组下标，利用数组的随机访问特性，使得我们能在 O(1) 的时间代价内完成检索。</p><p>尽管哈希检索没有使用二分查找，但无论是设计理想的哈希函数，还是保证哈希表有足够的空闲位置，包括解决冲突的“二次探查”和“双散列”方案，本质上都是希望数据插入哈希表的时候，分布能均衡，这样检索才能更高效。从这个角度来看，其实哈希检索提高检索效率的原理，和二叉检索树需要平衡左右子树深度的原理是一样的，也就是说，高效的检索需要均匀划分检索空间。</p><h2 id="4-状态检索"><a class="markdownIt-Anchor" href="#4-状态检索"></a> 4. 状态检索</h2><p>在海量数据中，快速判断一个对象是否存在。相比于有序数组、二叉检索树和哈希表这三种方案，位图和布隆过滤器其实更适合解决这类状态检索的问题。这是因为，在不要求 100% 判断正确的情况下，使用位图和布隆过滤器可以达到 <code>O(1)</code> 时间代价的检索效率，同时空间使用率也非常高效。</p><p>为了判断一个很大的数据范围中，某数值是否存在，可以将这个范围的数据存为数组，其数组值为布尔型（true 或 false）。由于很多语言中，布尔类型需要 1 个字节，而二进制位（bit）的值 0 或 1 也可以表示 true 或 false，并且占用空间更小，所以更加合适。而这种基于位运算的哈希结构，即为位图。</p><p>布隆过滤器最大的特点，就是对一个对象使用多个哈希函数。如果我们使用了 k 个哈希函数，就会得到 k 个哈希值，也就是 k 个下标，我们会把数组中对应下标位置的值都置为 1。布隆过滤器和位图最大的区别就在于，我们不再使用一位来表示一个对象，而是使用 k 位来表示一个对象。这样两个对象的 k 位都相同的概率就会大大降低，从而能够解决哈希冲突的问题了。</p><p>布隆过滤器的误判有一个特点，那就是，它只会对存在的情况有误判。如果某个数字经过布隆过滤器判断不存在，那说明这个数字真的不存在，不会发生误判；如果某个数字经过布隆过滤器判断存在，这个时候才会有可能误判，有可能并不存在。不过，只要我们调整哈希函数的个数、位图大小跟要存储数字的个数之间的比例，那就可以将这种误判的概率降到非常低。</p><p>布隆过滤器过滤器适用于对误判有一定容忍度的场景。</p><h2 id="5-倒排索引"><a class="markdownIt-Anchor" href="#5-倒排索引"></a> 5. 倒排索引</h2><p>倒排索引的核心其实并不复杂，它的具体实现其实是哈希表，只是它不是将文档 ID 或者题目作为 key，而是反过来，通过将内容或者属性作为 key 来存储对应的文档列表，使得我们能在 O(1) 的时间代价内完成查询。</p><p>尽管原理并不复杂，但是倒排索引是许多检索引擎的核心。比如说，数据库的全文索引功能、搜索引擎的索引、广告引擎和推荐引擎，都使用了倒排索引技术来实现检索功能。</p><h2 id="6-b-树检索"><a class="markdownIt-Anchor" href="#6-b-树检索"></a> 6. B+ 树检索</h2><p>内存是半导体元件。对于内存而言，只要给出了内存地址，我们就可以直接访问该地址取出数据。这个过程具有高效的随机访问特性，因此内存也叫随机访问存储器（Random Access Memory，即 RAM）。内存的访问速度很快，但是价格相对较昂贵，因此一般的计算机内存空间都相对较小。</p><p>而磁盘是机械器件。磁盘访问数据时，需要等磁盘盘片旋转到磁头下，才能读取相应的数据。尽管磁盘的旋转速度很快，但是和内存的随机访问相比，性能差距非常大。一般来说，如果是随机读写，会有 10 万到 100 万倍左右的差距。但如果是顺序访问大批量数据的话，磁盘的性能和内存就是一个数量级的。</p><p>磁盘的最小读写单位是扇区，较早期的磁盘一个扇区是 <strong><code>512</code></strong> 字节。随着磁盘技术的发展，目前常见的磁盘扇区是 <strong><code>4K</code></strong> 个字节。操作系统一次会读写多个扇区，所以操作系统的最小读写单位是块（Block），也叫作簇（Cluster）。当我们要从磁盘中读取一个数据时，操作系统会一次性将整个块都读出来。因此，对于大批量的顺序读写来说，磁盘的效率会比随机读写高许多。</p><p>假设有一个有序数组存储在硬盘中，如果它足够大，那么它会存储在多个块中。当我们要对这个数组使用二分查找时，需要先找到中间元素所在的块，将这个块从磁盘中读到内存里，然后在内存中进行二分查找。如果下一步要读的元素在其他块中，则需要再将相应块从磁盘中读入内存。直到查询结束，这个过程可能会多次访问磁盘。我们可以看到，这样的检索性能非常低。</p><p>由于磁盘相对于内存而言访问速度实在太慢，因此，对于磁盘上数据的高效检索，我们有一个极其重要的原则：对磁盘的访问次数要尽可能的少！</p><p>将索引和数据分离就是一种常见的设计思路。在数据频繁变化的场景中，有序数组并不是一个最好的选择，二叉检索树或者哈希表往往更有普适性。但是，哈希表由于缺乏范围检索的能力，在一些场合也不适用。因此，二叉检索树这种树形结构是许多常见检索系统的实施方案。</p><p>随着索引数据越来越大，直到无法完全加载到内存中，这是需要将索引数据也存入磁盘中。B+ 树给出了将树形索引的所有节点都存在磁盘上的高效检索方案。操作系统对磁盘数据的访问是以块为单位的。因此，如果我们想将树型索引的一个节点从磁盘中读出，即使该节点的数据量很小（比如说只有几个字节），但磁盘依然会将整个块的数据全部读出来，而不是只读这一小部分数据，这会让有效读取效率很低。B+ 树的一个关键设计，就是让一个节点的大小等于一个块的大小。节点内存储的数据，不是一个元素，而是一个可以装 m 个元素的有序数组。这样一来，我们就可以将磁盘一次读取的数据全部利用起来，使得读取效率最大化。</p><p>B+ 树还有另一个设计，就是将所有的节点分为内部节点和叶子节点。内部节点仅存储 key 和维持树形结构的指针，并不存储 key 对应的数据（无论是具体数据还是文件位置信息）。这样内部节点就能存储更多的索引数据，我们也就可以使用最少的内部节点，将所有数据组织起来了。而叶子节点仅存储 key 和对应数据，不存储维持树形结构的指针。通过这样的设计，B+ 树就能做到节点的空间利用率最大化。此外，B+ 树还将同一层的所有节点串成了有序的双向链表，这样一来，B+ 树就同时具备了良好的范围查询能力和灵活调整的能力了。</p><p>因此，B+ 树是一棵完全平衡的 m 阶多叉树。所谓的 m 阶，指的是每个节点最多有 m 个子节点，并且每个节点里都存了一个紧凑的可包含 m 个元素的数组。</p><p>即使是复杂的 B+ 树，我们将它拆解开来，其实也是由简单的数组、链表和树组成的，而且 B+ 树的检索过程其实也是二分查找。因此，如果 B+ 树完全加载在内存中的话，它的检索效率其实并不会比有序数组或者二叉检索树更<br />高，也还是二分查找的 log(n) 的效率。并且，它还比数组和二叉检索树更加复杂，还会带来额外的开销。</p><p>另外，这一节还有一个很重要的设计思想需要你掌握，那就是将索引和数据分离。通过这样的方式，我们能将索引的数组大小保持在一个较小的范围内，让它能加载在内存中。在许多大规模系统中，都是使用这个设计思想来精简索引的。而且，B+ 树的内部节点和叶子节点的区分，其实也是索引和数据分离的一次实践。</p><p>MySQL 中的 B+ 树实现其实有两种，一种是 MyISAM 引擎，另一种是 InnoDB 引擎。它们的核心区别就在于，数据和索引是否是分离的。</p><p>在 MyISAM 引擎中，B+ 树的叶子节点仅存储了数据的位置指针，这是一种索引和数据分离的设计方案，叫作非聚集索引。如果要保证 MyISAM 的数据一致性，那我们需要在表级别上进行加锁处理。</p><p>在 InnoDB 中，B+ 树的叶子节点直接存储了具体数据，这是一种索引和数据一体的方案。叫作聚集索引。由于数据直接就存在索引的叶子节点中，因此 InnoDB 不需要给全表加锁来保证一致性，它只需要支持行级的锁就可以了。</p><h2 id="7-lsm-树检索"><a class="markdownIt-Anchor" href="#7-lsm-树检索"></a> 7. LSM 树检索</h2><p>B+ 树的数据都存储在叶子节点中，而叶子节点一般都存储在磁盘中。因此，每次插入的新数据都需要随机写入磁盘，而随机写入的性能非常慢。如果是一个日志系统，每秒钟要写入上千条甚至上万条数据，这样的磁盘操作代价会使得系统性能急剧下降，甚至无法使用。</p><p>操作系统对磁盘的读写是以块为单位的，我们能否以块为单位写入，而不是每次插入一个数据都要随机写入磁盘呢？这样是不是就可以大幅度减少写入操作了呢？解决方案就是：<strong>LSM 树</strong>（Log Structured Merge Trees）。</p><p>LSM 树就是根据这个思路设计了这样一个机制：当数据写入时，延迟写磁盘，将数据先存放在内存中的树里，进行常规的存储和查询。当内存中的树持续变大达到阈值时，再批量地以块为单位写入磁盘的树中。因此，LSM 树至少需要由两棵树组成，一棵是存储在内存中较小的 C0 树，另一棵是存储在磁盘中较大的 C1 树。</p><p>LSM 树具有以下 3 个特点：</p><ol><li>将索引分为内存和磁盘两部分，并在内存达到阈值时启动树合并（Merge Trees）；</li><li>用批量写入代替随机写入，并且用预写日志 WAL 技术（Write AheadLog，预写日志技术）保证内存数据，在系统崩溃后可以被恢复；</li><li>数据采取类似日志追加写的方式写入（Log Structured）磁盘，以顺序写的方式提高写<br />入效率。</li></ol><p>LSM 树的这些特点，使得它相对于 B+ 树，在写入性能上有大幅提升。所以，许多 NoSQL 系统都使用 LSM 树作为检索引擎，而且还对 LSM 树进行了优化以提升检索性能。</p><h2 id="8-索引构建"><a class="markdownIt-Anchor" href="#8-索引构建"></a> 8. 索引构建</h2><ul><li><strong>数据压缩</strong>：一个是尽可能地将数据加载到内存中，因为内存的检索效率大大高于磁盘。那为了将数据更多地加载到内存中，索引压缩是一个重要的研究方向。</li><li><strong>分支处理</strong>：另一个是将大数据集合拆成多个小数据集合来处理。这其实就是分布式系统的核心思想。</li></ul><h2 id="9-索引更新"><a class="markdownIt-Anchor" href="#9-索引更新"></a> 9. 索引更新</h2><h3 id="91-double-buffer双缓冲机制"><a class="markdownIt-Anchor" href="#91-double-buffer双缓冲机制"></a> 9.1. Double Buffer（双缓冲）机制</h3><p>就是在内存中同时保存两份一样的索引，一个是索引 A，一个是索引 B。两个索引保持一个读、一个写，并且来回切换，最终完成高性能的索引更新。</p><p>优点：简单高效</p><p>缺点：达到一定数据量级后，会带来翻倍的内存开销，甚至有些索引存储在磁盘上的情况下，更是无法使用此机制。</p><h3 id="92-全量索引和增量索引"><a class="markdownIt-Anchor" href="#92-全量索引和增量索引"></a> 9.2. 全量索引和增量索引</h3><p>将新接收到的数据单独建立一个可以存在内存中的倒排索引，也就是增量索引。当查询发生的时候，我们会同时查询全量索引和增量索引，将合并的结果作为总的结果输出。</p><p>因为增量索引相对全量索引而言会小很多，内存资源消耗在可承受范围，所以我们可以使用 Double Buffer 机制<br />对增量索引进行索引更新。这样一来，增量索引就可以做到无锁访问。而全量索引本身就是只读的，也不需要加锁。因此，整个检索过程都可以做到无锁访问，也就提高了系统的检索效率。</p><h3 id="93-如何处理增量索引空间的持续增长"><a class="markdownIt-Anchor" href="#93-如何处理增量索引空间的持续增长"></a> 9.3. 如何处理增量索引空间的持续增长</h3><h4 id="完全重建法"><a class="markdownIt-Anchor" href="#完全重建法"></a> 完全重建法</h4><p>如果增量索引的增长速度不算很快，或者全量索引重建的代价不大，那么我们完全可以在增量索引写满内存空间之前，完全重建一次全量索引，然后将系统查询切换到新的全量索引上。</p><h4 id="再合并法"><a class="markdownIt-Anchor" href="#再合并法"></a> 再合并法</h4><p>直接归并全量索引和增量索引，生成一个新的全量索引，这也就避免了从头处理所有文档的重复开销。</p><h4 id="滚动合并法"><a class="markdownIt-Anchor" href="#滚动合并法"></a> 滚动合并法</h4><p>先生成多个不同层级的索引，然后逐层合并。</p><p>比如说，一个检索系统在磁盘中保存了全量索引、周级索引和天级索引。所谓周级索引，就<br />是根据本周的新数据生成的一份索引，那天级索引就是根据每天的新数据生成的一份索引。<br />在滚动合并法中，当内存中的增量索引增长到一定体量时，我们会用再合并法将它合并到磁<br />盘上当天的天级索引文件中。</p><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20220316134834.png" alt="img" /></p><h2 id="10-索引拆分"><a class="markdownIt-Anchor" href="#10-索引拆分"></a> 10. 索引拆分</h2><p>水平拆分和垂直拆分</p><h2 id="11-top-k-检索"><a class="markdownIt-Anchor" href="#11-top-k-检索"></a> 11. TOP K 检索</h2><h3 id="111-tf-idf-算法"><a class="markdownIt-Anchor" href="#111-tf-idf-算法"></a> 11.1. TF-IDF 算法</h3><p>TF-IDF 算法的公式是：相关性 = TF*IDF。其中，TF 是词频（Term Frequency），IDF 是逆文档频率（Inverse Document Frequency）。</p><ul><li><strong>词频</strong>定义的就是一个词项在文档中出现的次数。换一句话说就是，如果一个词项出现了越多次，那这个词在文档中就越重要。</li><li><strong>文档频率</strong>（Document Frequency），指的是这个词项出现在了多少个文档中。你也可以理解为，如果一个词出现在越多的文档中，那这个词就越普遍，越没有区分度。一个极端的例子，比如“的”字，它基本上在每个文档中都会出现，所以它的区分度就非常低。</li><li>逆文档频率是对文档频率取倒数，它的值越大，这个词的的区分度就越大。</li></ul><h3 id="112-bm25-算法"><a class="markdownIt-Anchor" href="#112-bm25-算法"></a> 11.2. BM25 算法</h3><p>BM25 算法的一个重要的设计思想是，它认为词频和相关性的关系并不是线性的。也就是说，随着词频的增加，相关性的增加会越来越不明显，并且还会有一个阈值上限。当词频达到阈值以后，那相关性就不会再增长了。</p><p>总结来说，BM25 算法就是一个对查询词和文档的相关性进行打分的概率模型算法。BM25 算法考虑了四个因子，分别为 IDF、文档长度、文档中的词频以及查询词中的词频。并且，公式中还加入了 3 个可以人工调整大小的参数，分别是 ：k1、k2 和 b。</p><h3 id="113-机器学习打分"><a class="markdownIt-Anchor" href="#113-机器学习打分"></a> 11.3. 机器学习打分</h3><p>机器学习可以更大规模地引入更多的打分因子，并且可以自动学习出各个打分因子的权重。所以，利用机器学习进行相关性打分，已经成了目前大规模检索引擎的标配。</p><h3 id="114-根据打分结果快速-top-k-检索"><a class="markdownIt-Anchor" href="#114-根据打分结果快速-top-k-检索"></a> 11.4. 根据打分结果快速 TOP K 检索</h3><p>完成打分阶段之后，排序阶段我们要重视排序的效率。对于精准 Top K 检索，我们可以使用堆排序来代替全排序，只返回我们认为最重要的 k 个结果。这样，时间代价就是 O(n) + O(k log n) ，在数据量级非常大的情况下，它比 O(n log n) 的检索性能会高得多。</p><h2 id="12-非精准-top-k-检索"><a class="markdownIt-Anchor" href="#12-非精准-top-k-检索"></a> 12. 非精准 TOP K 检索</h2><p>高质量的检索结果并不一定要非常精准，我们只需要保证质量足够高的结果，被包含在最终的 Top K 个结果中就够了。这就是非精准 Top K 检索的思路。</p><h2 id="13-空间检索"><a class="markdownIt-Anchor" href="#13-空间检索"></a> 13. 空间检索</h2><p>通过将二维空间在水平和垂直方向上不停二分，可以生成一维的区域编码，然后我们可以使用一维空间的检索技术对区域编码做好索引。</p><p>在需要动态调整查询范围的场景下，对于二进制编码的二维空间的最近邻检索问题，我们可以通过四叉树来完成。四叉树可以很好地快速划分查询空间，并通过递归的方式高效地扩大查询范围。但是满四叉树经常会造成无谓的空间浪费，为了避免这个问题，在实际应用的时候，我们会选择使用非满四叉树来存储和索引编码。对于 GeoHash 编码的二维空间最近邻检索问题，我们也能通过类似的前缀树来提高检索效率。</p><h2 id="14-最近邻检索"><a class="markdownIt-Anchor" href="#14-最近邻检索"></a> 14. 最近邻检索</h2><p>如何计算两篇文章的相似性</p><p>最常见的方式就是使用向量空间模型（Vector Space Model）。所谓向量空间模型，就是将所有文档中出现过的所有关键词都提取出来。如果一共有 n 个关键词，那每个关键词就是一个维度，这就组成了一个 n 维的向量空间。</p><h2 id="15-存储系统"><a class="markdownIt-Anchor" href="#15-存储系统"></a> 15. 存储系统</h2><p>LevelDB 是由 Google 开源的存储系统。</p><p>LevelDB 是基于 LSM 树优化而来的存储系统。LSM 树会将索引分为内存和磁盘两部分，并在内存达到阈值时启动树合并。但是，这里面存在着大量的细节问题。</p><h3 id="151-数据在内存中如何高效检索"><a class="markdownIt-Anchor" href="#151-数据在内存中如何高效检索"></a> 15.1. 数据在内存中如何高效检索？</h3><p>首先，对内存中索引的高效检索，我们可以用很多检索技术，如红黑树、跳表等，这些数据结构会比 B+ 树更高效。LevelDB 对于 LSM 树的第一个改进，就是使用跳表代替 B+ 树来实现内存中的 C0 树。</p><h3 id="152-数据是如何高效地从内存转移到磁盘的"><a class="markdownIt-Anchor" href="#152-数据是如何高效地从内存转移到磁盘的"></a> 15.2. 数据是如何高效地从内存转移到磁盘的？</h3><p>LevelDB 做了读写分离的设计。它将内存中的数据分为两块，一块叫作 MemTable，它是可读可写的。另一块叫作 Immutable MemTable，它是只读的。这两块数据的数据结构完全一样，都是跳表。</p><p>当 MemTable 的存储数据达到上限时，我们直接将它切换为只读的 Immutable MemTable，然后重新生成一个新的 MemTable，来支持新数据的写入和查询。这时，将内存索引存储到磁盘的问题，就变成了将 Immutable MemTable 写入磁盘的问题。而且，由于 Immutable MemTable 是只读的，因此，它不需要加锁就可以高效<br />地写入磁盘中。</p><h3 id="153-数据如何合并"><a class="markdownIt-Anchor" href="#153-数据如何合并"></a> 15.3. 数据如何合并</h3><p>在原始 LSM 树的设计中，内存索引写入磁盘时是直接和磁盘中的 C1 树进行归并的。但如果工程中也这么<br />实现的话，会有两个很严重的问题：</p><ul><li>合并代价很高，因为 C1 树很大，而 C0 树很小，这会导致它们在合并时产生大量的磁盘 IO；</li><li>合并频率会很频繁，由于 C0 树很小，很容易被写满，因此系统会频繁进行 C0 树和 C1 树的合并，这样频繁合并会带来的大量磁盘 IO，这更是系统无法承受的。</li></ul><p>LevelDB 采用了延迟合并的设计来优化。具体来说就是，先将 Immutable MemTable 顺序快速写入磁盘，直接变成一个个 SSTable（Sorted String Table）文件，之后再对这些 SSTable 文件进行合并。这样就避免了 C0 树和 C1 树昂贵的 合并代价。</p><p>而在管理多个 SSTable 文件的环节，LevelDB 使用分层和滚动合并的设计来组织多个 SSTable 文件，避免了 C0 树和 C1 树的合并带来的大量数据被复制的问题。</p><h3 id="154-数据如何检索"><a class="markdownIt-Anchor" href="#154-数据如何检索"></a> 15.4. 数据如何检索</h3><p>先在 MemTable 中查找，如果查找不到再去 Immutable MemTable 中查找。如果 Immutable MemTable 也查询不到，才会到磁盘中去查找。</p><p>在磁盘中检索数据的环节，因为 SSTable 文件是有序的，所以我们通过多层二分查找的方式，就能快速定位到需要查询的 SSTable 文件。接着，在 SSTable 文件内查找元素时，LevelDB 先是使用索引与数据分离的设计，减少磁盘 IO，又使用 BloomFilter 和二分查找来完成检索加速。加速检索的过程中，LevelDB 又使用缓存技术，将会被反复读取的数据缓存在内存中，从而避免了磁盘开销。</p><h2 id="16-搜索系统"><a class="markdownIt-Anchor" href="#16-搜索系统"></a> 16. 搜索系统</h2><p>搜索流程：</p><ul><li>先对查询内容分词，搜索引擎还会纠错和相似推荐，得到检索词</li><li>根据检索词在倒排索引中进行短语检索。然后，根据相关性打分，将得分高的结果保留。</li></ul><h2 id="17-广告系统"><a class="markdownIt-Anchor" href="#17-广告系统"></a> 17. 广告系统</h2><p>广告引擎处理一个广告请求的过程，本质上就是根据用户的广告请求信息，找出标签匹配的广告设置，并将广告进行排序返回的过程。</p><ul><li>在标签检索引擎中，我们通过合理地将标签使用在树形检索 + 倒排索引 + 结果过滤这三个环节，来提高检索效率。</li><li>在向量检索引擎中，我们可以使用聚类 + 倒排索引 + 乘积量化的技术来加速检索。</li><li>在打分排序环节，增加一个非精准打分环节，这样我们就可以大幅降低使用深度学习模型带来的开销。</li><li>在索引构建环节，我们还可以将一些过滤条件前置，仅将当前有效的广告设置加入索引，然后通过全量索引 + 增量索引的更新方式，来保证过滤逻辑的有效。</li></ul><h2 id="18-推荐引擎"><a class="markdownIt-Anchor" href="#18-推荐引擎"></a> 18. 推荐引擎</h2><p>相比于搜索引擎和广告引擎，推荐引擎具有更灵活的检索能力，也就是可以使用更灵活的检索技术，来进行文章的召回服务。</p><h2 id="19-参考资料"><a class="markdownIt-Anchor" href="#19-参考资料"></a> 19. 参考资料</h2><ul><li><a href="https://time.geekbang.org/column/intro/100048401" target="_blank" rel="noopener">检索技术核心 20 讲</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;检索技术核心-20-讲笔记&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#检索技术核心-20-讲笔记&quot;&gt;&lt;/a&gt; 检索技术核心 20 讲笔记&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;伸缩性架构是指不需要改变系统的软硬件设计，仅通过改变
      
    
    </summary>
    
    
      <category term="笔记" scheme="https://dunwu.github.io/blog/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="架构" scheme="https://dunwu.github.io/blog/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch 集群和分片</title>
    <link href="https://dunwu.github.io/blog/2022/03/01/elasticsearch-%E9%9B%86%E7%BE%A4%E5%92%8C%E5%88%86%E7%89%87/"/>
    <id>https://dunwu.github.io/blog/2022/03/01/elasticsearch-%E9%9B%86%E7%BE%A4%E5%92%8C%E5%88%86%E7%89%87/</id>
    <published>2022-03-01T12:52:25.000Z</published>
    <updated>2022-04-14T08:45:53.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="elasticsearch-集群和分片"><a class="markdownIt-Anchor" href="#elasticsearch-集群和分片"></a> Elasticsearch 集群和分片</h1><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#1-%E9%9B%86%E7%BE%A4">1. 集群</a><ul><li><a href="#11-%E7%A9%BA%E9%9B%86%E7%BE%A4">1.1. 空集群</a></li><li><a href="#12-%E9%9B%86%E7%BE%A4%E5%81%A5%E5%BA%B7">1.2. 集群健康</a></li><li><a href="#13-%E6%B7%BB%E5%8A%A0%E7%B4%A2%E5%BC%95">1.3. 添加索引</a></li><li><a href="#14-%E6%B7%BB%E5%8A%A0%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB">1.4. 添加故障转移</a></li><li><a href="#15-%E6%B0%B4%E5%B9%B3%E6%89%A9%E5%AE%B9">1.5. 水平扩容</a></li><li><a href="#16-%E6%9B%B4%E5%A4%9A%E7%9A%84%E6%89%A9%E5%AE%B9">1.6. 更多的扩容</a></li><li><a href="#17-%E5%BA%94%E5%AF%B9%E6%95%85%E9%9A%9C">1.7. 应对故障</a></li></ul></li><li><a href="#2-%E5%88%86%E7%89%87">2. 分片</a><ul><li><a href="#21-%E4%BD%BF%E6%96%87%E6%9C%AC%E5%8F%AF%E8%A2%AB%E6%90%9C%E7%B4%A2">2.1. 使文本可被搜索</a></li><li><a href="#22-%E4%B8%8D%E5%8F%98%E6%80%A7">2.2. 不变性</a></li><li><a href="#23-%E5%8A%A8%E6%80%81%E6%9B%B4%E6%96%B0%E7%B4%A2%E5%BC%95">2.3. 动态更新索引</a></li><li><a href="#24-%E5%88%A0%E9%99%A4%E5%92%8C%E6%9B%B4%E6%96%B0">2.4. 删除和更新</a></li><li><a href="#25-%E8%BF%91%E5%AE%9E%E6%97%B6%E6%90%9C%E7%B4%A2">2.5. 近实时搜索</a></li><li><a href="#26-refresh-api">2.6. refresh API</a></li><li><a href="#27-%E6%8C%81%E4%B9%85%E5%8C%96%E5%8F%98%E6%9B%B4">2.7. 持久化变更</a></li><li><a href="#28-flush-api">2.8. flush API</a></li><li><a href="#29-%E6%AE%B5%E5%90%88%E5%B9%B6">2.9. 段合并</a></li><li><a href="#210-optimize-api">2.10. optimize API</a></li></ul></li><li><a href="#3-%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">3. 参考资料</a></li></ul><!-- /TOC --><h2 id="1-集群"><a class="markdownIt-Anchor" href="#1-集群"></a> 1. 集群</h2><h3 id="11-空集群"><a class="markdownIt-Anchor" href="#11-空集群"></a> 1.1. 空集群</h3><p>如果我们启动了一个单独的节点，里面不包含任何的数据和索引，那我们的集群看起来就是一个包含空内容节点的集群。</p><p><strong>Figure 1. 包含空内容节点的集群</strong></p><p><img src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_0201.png" alt="包含空内容节点的集群" /></p><p>图 1：只有一个空节点的集群</p><p>一个运行中的 Elasticsearch 实例称为一个<strong>节点</strong>，而<strong>集群</strong>是由一个或者多个拥有相同 <code>cluster.name</code> 配置的节点组成， 它们共同承担数据和负载的压力。当有节点加入集群中或者从集群中移除节点时，集群将会重新平均分布所有的数据。</p><p>当一个节点被选举成为<strong>主节点</strong>时， 它将负责管理集群范围内的<strong>所有变更</strong>，例如增加、删除索引，或者增加、删除节点等。 而主节点并不需要涉及到文档级别的变更和搜索等操作，所以当集群只拥有一个主节点的情况下，即使流量的增加它也不会成为瓶颈。 任何节点都可以成为主节点。我们的示例集群就只有一个节点，所以它同时也成为了主节点。</p><p>作为用户，我们可以将请求发送到集群中的任何节点，包括主节点。 每个节点都知道任意文档所处的位置，并且能够将我们的请求直接转发到存储我们所需文档的节点。 无论我们将请求发送到哪个节点，它都能负责从各个包含我们所需文档的节点收集回数据，并将最终结果返回給客户端。 Elasticsearch 对这一切的管理都是透明的。</p><h3 id="12-集群健康"><a class="markdownIt-Anchor" href="#12-集群健康"></a> 1.2. 集群健康</h3><p>Elasticsearch 的集群监控信息中包含了许多的统计数据，其中最为重要的一项就是 <em>集群健康</em> ， 它在 <code>status</code> 字段中展示为 <code>green</code> 、 <code>yellow</code> 或者 <code>red</code> 。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_cluster/health</span><br></pre></td></tr></table></figure><p>在一个不包含任何索引的空集群中，它将会有一个类似于如下所示的返回内容：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"cluster_name"</span>: <span class="string">"elasticsearch"</span>,</span><br><span class="line">  <span class="attr">"status"</span>: <span class="string">"green"</span>,</span><br><span class="line">  <span class="attr">"timed_out"</span>: <span class="literal">false</span>,</span><br><span class="line">  <span class="attr">"number_of_nodes"</span>: <span class="number">1</span>,</span><br><span class="line">  <span class="attr">"number_of_data_nodes"</span>: <span class="number">1</span>,</span><br><span class="line">  <span class="attr">"active_primary_shards"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"active_shards"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"relocating_shards"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"initializing_shards"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"unassigned_shards"</span>: <span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>status</code> 字段指示着当前集群在总体上是否工作正常。它的三种颜色含义如下：</p><ul><li><strong><code>green</code></strong>：所有的主分片和副本分片都正常运行。</li><li><strong><code>yellow</code></strong>：所有的主分片都正常运行，但不是所有的副本分片都正常运行。</li><li><strong><code>red</code></strong>：有主分片没能正常运行。</li></ul><h3 id="13-添加索引"><a class="markdownIt-Anchor" href="#13-添加索引"></a> 1.3. 添加索引</h3><p>我们往 Elasticsearch 添加数据时需要用到 <em>索引</em> —— 保存相关数据的地方。索引实际上是指向一个或者多个物理分片的逻辑命名空间 。</p><p>一个 <em>分片</em> 是一个底层的 <em>工作单元</em> ，它仅保存了全部数据中的一部分。现在我们只需知道一个分片是一个 Lucene 的实例，以及它本身就是一个完整的搜索引擎。 我们的文档被存储和索引到分片内，但是应用程序是直接与索引而不是与分片进行交互。</p><p>Elasticsearch 是利用分片将数据分发到集群内各处的。分片是数据的容器，文档保存在分片内，分片又被分配到集群内的各个节点里。 当你的集群规模扩大或者缩小时， Elasticsearch 会自动的在各节点中迁移分片，使得数据仍然均匀分布在集群里。</p><p>一个分片可以是 <em>主</em> 分片或者 <em>副本</em> 分片。 索引内任意一个文档都归属于一个主分片，所以主分片的数目决定着索引能够保存的最大数据量。</p><blockquote><p>技术上来说，一个主分片最大能够存储 <code>Integer.MAX_VALUE - 128</code> 个文档，但是实际最大值还需要参考你的使用场景：包括你使用的硬件， 文档的大小和复杂程度，索引和查询文档的方式以及你期望的响应时长。</p></blockquote><p>一个副本分片只是一个主分片的拷贝。副本分片作为硬件故障时保护数据不丢失的冗余备份，并为搜索和返回文档等读操作提供服务。</p><p>在索引建立的时候就已经确定了主分片数，但是副本分片数可以随时修改。</p><p>让我们在包含一个空节点的集群内创建名为 <code>blogs</code> 的索引。 索引在默认情况下会被分配 5 个主分片， 但是为了演示目的，我们将分配 3 个主分片和一份副本（每个主分片拥有一个副本分片）：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">PUT /blogs</span><br><span class="line">&#123;</span><br><span class="line">   <span class="string">"settings"</span> : &#123;</span><br><span class="line">      <span class="string">"number_of_shards"</span> : <span class="number">3</span>,</span><br><span class="line">      <span class="string">"number_of_replicas"</span> : <span class="number">1</span></span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们的集群现在是 <em>拥有一个索引的单节点集群</em>。所有 3 个主分片都被分配在 <code>Node 1</code> 。</p><p><strong>Figure 2. 拥有一个索引的单节点集群</strong></p><p><img src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_0202.png" alt="拥有一个索引的单节点集群" /></p><p>如果我们现在查看集群健康，我们将看到如下内容：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"cluster_name"</span>: <span class="string">"elasticsearch"</span>,</span><br><span class="line">  <span class="attr">"status"</span>: <span class="string">"yellow"</span>,</span><br><span class="line">  <span class="attr">"timed_out"</span>: <span class="literal">false</span>,</span><br><span class="line">  <span class="attr">"number_of_nodes"</span>: <span class="number">1</span>,</span><br><span class="line">  <span class="attr">"number_of_data_nodes"</span>: <span class="number">1</span>,</span><br><span class="line">  <span class="attr">"active_primary_shards"</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="attr">"active_shards"</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="attr">"relocating_shards"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"initializing_shards"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"unassigned_shards"</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="attr">"delayed_unassigned_shards"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"number_of_pending_tasks"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"number_of_in_flight_fetch"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"task_max_waiting_in_queue_millis"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"active_shards_percent_as_number"</span>: <span class="number">50</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>集群 status 值为 yellow</li><li>没有被分配到任何节点的副本数</li></ul><p>集群的健康状况为 <code>yellow</code> 则表示全部 <em>主</em> 分片都正常运行（集群可以正常服务所有请求），但是 <em>副本</em> 分片没有全部处在正常状态。 实际上，所有 3 个副本分片都是 <code>unassigned</code> —— 它们都没有被分配到任何节点。 在同一个节点上既保存原始数据又保存副本是没有意义的，因为一旦失去了那个节点，我们也将丢失该节点上的所有副本数据。</p><p>当前我们的集群是正常运行的，但是在硬件故障时有丢失数据的风险。</p><h3 id="14-添加故障转移"><a class="markdownIt-Anchor" href="#14-添加故障转移"></a> 1.4. 添加故障转移</h3><p>当集群中只有一个节点在运行时，意味着会有一个单点故障问题——没有冗余。 幸运的是，我们只需再启动一个节点即可防止数据丢失。</p><blockquote><p>为了测试第二个节点启动后的情况，你可以在同一个目录内，完全依照启动第一个节点的方式来启动一个新节点（参考安装并运行 Elasticsearch）。多个节点可以共享同一个目录。</p><p>当你在同一台机器上启动了第二个节点时，只要它和第一个节点有同样的 <a href="http://cluster.name" target="_blank" rel="noopener">cluster.name</a> 配置，它就会自动发现集群并加入到其中。 但是在不同机器上启动节点的时候，为了加入到同一集群，你需要配置一个可连接到的单播主机列表。</p></blockquote><p>如果启动了第二个节点，我们的集群将会拥有两个节点的集群——所有主分片和副本分片都已被分配。</p><p><strong>Figure 3. 拥有两个节点的集群——所有主分片和副本分片都已被分配</strong></p><p><img src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_0203.png" alt="拥有两个节点的集群" /></p><p>当第二个节点加入到集群后，3 个 <em>副本分片</em> 将会分配到这个节点上——每个主分片对应一个副本分片。 这意味着当集群内任何一个节点出现问题时，我们的数据都完好无损。</p><p>所有新近被索引的文档都将会保存在主分片上，然后被并行的复制到对应的副本分片上。这就保证了我们既可以从主分片又可以从副本分片上获得文档。</p><p><code>cluster-health</code> 现在展示的状态为 <code>green</code> ，这表示所有 6 个分片（包括 3 个主分片和 3 个副本分片）都在正常运行。</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"cluster_name"</span>: <span class="string">"elasticsearch"</span>,</span><br><span class="line">  <span class="attr">"status"</span>: <span class="string">"green"</span>,</span><br><span class="line">  <span class="attr">"timed_out"</span>: <span class="literal">false</span>,</span><br><span class="line">  <span class="attr">"number_of_nodes"</span>: <span class="number">2</span>,</span><br><span class="line">  <span class="attr">"number_of_data_nodes"</span>: <span class="number">2</span>,</span><br><span class="line">  <span class="attr">"active_primary_shards"</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="attr">"active_shards"</span>: <span class="number">6</span>,</span><br><span class="line">  <span class="attr">"relocating_shards"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"initializing_shards"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"unassigned_shards"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"delayed_unassigned_shards"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"number_of_pending_tasks"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"number_of_in_flight_fetch"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"task_max_waiting_in_queue_millis"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"active_shards_percent_as_number"</span>: <span class="number">100</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>集群 <code>status</code> 值为 <code>green</code></li></ul><p>我们的集群现在不仅仅是正常运行的，并且还处于 <em>始终可用</em> 的状态。</p><h3 id="15-水平扩容"><a class="markdownIt-Anchor" href="#15-水平扩容"></a> 1.5. 水平扩容</h3><p>怎样为我们的正在增长中的应用程序按需扩容呢？ 当启动了第三个节点，我们的集群将拥有三个节点的集群——为了分散负载而对分片进行重新分配。</p><p><strong>Figure 4. 拥有三个节点的集群——为了分散负载而对分片进行重新分配</strong></p><p><img src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_0204.png" alt="拥有三个节点的集群" /></p><p><code>Node 1</code> 和 <code>Node 2</code> 上各有一个分片被迁移到了新的 <code>Node 3</code> 节点，现在每个节点上都拥有 2 个分片，而不是之前的 3 个。 这表示每个节点的硬件资源（CPU, RAM, I/O）将被更少的分片所共享，每个分片的性能将会得到提升。</p><p>分片是一个功能完整的搜索引擎，它拥有使用一个节点上的所有资源的能力。 我们这个拥有 6 个分片（3 个主分片和 3 个副本分片）的索引可以最大扩容到 6 个节点，每个节点上存在一个分片，并且每个分片拥有所在节点的全部资源。</p><h3 id="16-更多的扩容"><a class="markdownIt-Anchor" href="#16-更多的扩容"></a> 1.6. 更多的扩容</h3><p>但是如果我们想要扩容超过 6 个节点怎么办呢？</p><p>主分片的数目在索引创建时就已经确定了下来。实际上，这个数目定义了这个索引能够 <em>存储</em> 的最大数据量。（实际大小取决于你的数据、硬件和使用场景。） 但是，读操作——搜索和返回数据——可以同时被主分片 <em>或</em> 副本分片所处理，所以当你拥有越多的副本分片时，也将拥有越高的吞吐量。</p><p>在运行中的集群上是可以动态调整副本分片数目的，我们可以按需伸缩集群。让我们把副本数从默认的 <code>1</code> 增加到 <code>2</code> ：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT &#x2F;blogs&#x2F;_settings</span><br><span class="line">&#123;</span><br><span class="line">   &quot;number_of_replicas&quot; : 2</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>blogs</code> 索引现在拥有 9 个分片：3 个主分片和 6 个副本分片。 这意味着我们可以将集群扩容到 9 个节点，每个节点上一个分片。相比原来 3 个节点时，集群搜索性能可以提升 <em>3</em> 倍。</p><p><strong>Figure 5. 将参数 <code>number_of_replicas</code> 调大到 2</strong></p><p><img src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_0205.png" alt="拥有2份副本分片3个节点的集群" /></p><blockquote><p>当然，如果只是在相同节点数目的集群上增加更多的副本分片并不能提高性能，因为每个分片从节点上获得的资源会变少。 你需要增加更多的硬件资源来提升吞吐量。</p><p>但是更多的副本分片数提高了数据冗余量：按照上面的节点配置，我们可以在失去 2 个节点的情况下不丢失任何数据。</p></blockquote><h3 id="17-应对故障"><a class="markdownIt-Anchor" href="#17-应对故障"></a> 1.7. 应对故障</h3><p>我们之前说过 Elasticsearch 可以应对节点故障，接下来让我们尝试下这个功能。 如果我们关闭第一个节点，这时集群的状态为关闭了一个节点后的集群。</p><p><strong>Figure 6. 关闭了一个节点后的集群</strong></p><p><img src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_0206.png" alt="关闭了一个节点后的集群" /></p><p>我们关闭的节点是一个主节点。而集群必须拥有一个主节点来保证正常工作，所以发生的第一件事情就是选举一个新的主节点： <code>Node 2</code> 。</p><p>在我们关闭 <code>Node 1</code> 的同时也失去了主分片 <code>1</code> 和 <code>2</code> ，并且在缺失主分片的时候索引也不能正常工作。 如果此时来检查集群的状况，我们看到的状态将会为 <code>red</code> ：不是所有主分片都在正常工作。</p><p>幸运的是，在其它节点上存在着这两个主分片的完整副本， 所以新的主节点立即将这些分片在 <code>Node 2</code> 和 <code>Node 3</code> 上对应的副本分片提升为主分片， 此时集群的状态将会为 <code>yellow</code> 。 这个提升主分片的过程是瞬间发生的，如同按下一个开关一般。</p><p>为什么我们集群状态是 <code>yellow</code> 而不是 <code>green</code> 呢？ 虽然我们拥有所有的三个主分片，但是同时设置了每个主分片需要对应 2 份副本分片，而此时只存在一份副本分片。 所以集群不能为 <code>green</code> 的状态，不过我们不必过于担心：如果我们同样关闭了 <code>Node 2</code> ，我们的程序 <em>依然</em> 可以保持在不丢任何数据的情况下运行，因为 <code>Node 3</code> 为每一个分片都保留着一份副本。</p><p>如果我们重新启动 <code>Node 1</code> ，集群可以将缺失的副本分片再次进行分配，那么集群的状态也将如 Figure 5. 将参数 <code>number_of_replicas</code> 调大到 2 所示。 如果 <code>Node 1</code> 依然拥有着之前的分片，它将尝试去重用它们，同时仅从主分片复制发生了修改的数据文件。</p><p>到目前为止，你应该对分片如何使得 Elasticsearch 进行水平扩容以及数据保障等知识有了一定了解。 接下来我们将讲述关于分片生命周期的更多细节。</p><h2 id="2-分片"><a class="markdownIt-Anchor" href="#2-分片"></a> 2. 分片</h2><blockquote><ul><li>为什么搜索是 <em>近</em> 实时的？</li><li>为什么文档的 CRUD (创建-读取-更新-删除) 操作是 <em>实时</em> 的?</li><li>Elasticsearch 是怎样保证更新被持久化在断电时也不丢失数据?</li><li>为什么删除文档不会立刻释放空间？</li><li><code>refresh</code>, <code>flush</code>, 和 <code>optimize</code> API 都做了什么, 你什么情况下应该使用他们？</li></ul></blockquote><h3 id="21-使文本可被搜索"><a class="markdownIt-Anchor" href="#21-使文本可被搜索"></a> 2.1. 使文本可被搜索</h3><p>必须解决的第一个挑战是如何使文本可被搜索。 传统的数据库每个字段存储单个值，但这对全文检索并不够。文本字段中的每个单词需要被搜索，对数据库意味着需要单个字段有索引多值(这里指单词)的能力。</p><p>最好的支持 <em>一个字段多个值</em> 需求的数据结构是我们在 <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/inverted-index.html" target="_blank" rel="noopener">倒排索引</a> 章节中介绍过的 <em>倒排索引</em> 。 倒排索引包含一个有序列表，列表包含所有文档出现过的不重复个体，或称为 <em>词项</em> ，对于每一个词项，包含了它所有曾出现过文档的列表。</p><figure class="highlight gherkin"><table><tr><td class="code"><pre><span class="line">Term  |<span class="string"> Doc 1 </span>|<span class="string"> Doc 2 </span>|<span class="string"> Doc 3 </span>|<span class="string"> ...</span></span><br><span class="line"><span class="string">------------------------------------</span></span><br><span class="line"><span class="string">brown </span>|<span class="string">   X   </span>|<span class="string">       </span>|<span class="string">  X    </span>|<span class="string"> ...</span></span><br><span class="line"><span class="string">fox   </span>|<span class="string">   X   </span>|<span class="string">   X   </span>|<span class="string">  X    </span>|<span class="string"> ...</span></span><br><span class="line"><span class="string">quick </span>|<span class="string">   X   </span>|<span class="string">   X   </span>|<span class="string">       </span>|<span class="string"> ...</span></span><br><span class="line"><span class="string">the   </span>|<span class="string">   X   </span>|<span class="string">       </span>|<span class="string">  X    </span>|<span class="string"> ...</span></span><br></pre></td></tr></table></figure><blockquote><p>当讨论倒排索引时，我们会谈到 <em>文档</em> 标引，因为历史原因，倒排索引被用来对整个非结构化文本文档进行标引。 Elasticsearch 中的 <em>文档</em> 是有字段和值的结构化 JSON 文档。事实上，在 JSON 文档中， 每个被索引的字段都有自己的倒排索引。</p></blockquote><p>这个倒排索引相比特定词项出现过的文档列表，会包含更多其它信息。它会保存每一个词项出现过的文档总数， 在对应的文档中一个具体词项出现的总次数，词项在文档中的顺序，每个文档的长度，所有文档的平均长度，等等。这些统计信息允许 Elasticsearch 决定哪些词比其它词更重要，哪些文档比其它文档更重要，这些内容在 <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/relevance-intro.html" target="_blank" rel="noopener">什么是相关性?</a> 中有描述。</p><p>为了能够实现预期功能，倒排索引需要知道集合中的 <em>所有</em> 文档，这是需要认识到的关键问题。</p><p>早期的全文检索会为整个文档集合建立一个很大的倒排索引并将其写入到磁盘。 一旦新的索引就绪，旧的就会被其替换，这样最近的变化便可以被检索到。</p><h3 id="22-不变性"><a class="markdownIt-Anchor" href="#22-不变性"></a> 2.2. 不变性</h3><p>倒排索引被写入磁盘后是 <em>不可改变</em> 的:它永远不会修改。 不变性有重要的价值：</p><ul><li>不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。</li><li>一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。</li><li>其它缓存(像 filter 缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。</li><li>写入单个大的倒排索引允许数据被压缩，减少磁盘 I/O 和 需要被缓存到内存的索引的使用量。</li></ul><p>当然，一个不变的索引也有不好的地方。主要事实是它是不可变的! 你不能修改它。如果你需要让一个新的文档 可被搜索，你需要重建整个索引。这要么对一个索引所能包含的数据量造成了很大的限制，要么对索引可被更新的频率造成了很大的限制。</p><h3 id="23-动态更新索引"><a class="markdownIt-Anchor" href="#23-动态更新索引"></a> 2.3. 动态更新索引</h3><p>下一个需要被解决的问题是怎样在保留不变性的前提下实现倒排索引的更新？答案是: 用更多的索引。</p><p>通过增加新的补充索引来反映新近的修改，而不是直接重写整个倒排索引。每一个倒排索引都会被轮流查询到—从最早的开始—查询完后再对结果进行合并。</p><p>Elasticsearch 基于 Lucene, 这个 java 库引入了 按段搜索 的概念。 每一 段 本身都是一个倒排索引， 但 索引 在 Lucene 中除表示所有 段 的集合外， 还增加了 提交点 的概念 — 一个列出了所有已知段的文件，就像在 Figure 16, “一个 Lucene 索引包含一个提交点和三个段” 中描绘的那样。 如 Figure 17, “一个在内存缓存中包含新文档的 Lucene 索引” 所示，新的文档首先被添加到内存索引缓存中，然后写入到一个基于磁盘的段，如 Figure 18, “在一次提交后，一个新的段被添加到提交点而且缓存被清空。” 所示。</p><p><strong>Figure 16. 一个 Lucene 索引包含一个提交点和三个段</strong></p><p><img src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1101.png" alt="A Lucene index with a commit point and three segments" /></p><blockquote><p>被混淆的概念是，一个 <em>Lucene 索引</em> 我们在 Elasticsearch 称作 <em>分片</em> 。 一个 Elasticsearch <em>索引</em> 是分片的集合。 当 Elasticsearch 在索引中搜索的时候， 他发送查询到每一个属于索引的分片(Lucene 索引)，然后像 <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/distributed-search.html" target="_blank" rel="noopener"><em>执行分布式检索</em></a> 提到的那样，合并每个分片的结果到一个全局的结果集。</p></blockquote><p>逐段搜索会以如下流程进行工作：</p><ol><li>新文档被收集到内存索引缓存， 见 Figure 17, “一个在内存缓存中包含新文档的 Lucene 索引” 。</li><li>不时地, 缓存被 <em>提交</em> ：<ul><li>一个新的段—一个追加的倒排索引—被写入磁盘。</li><li>一个新的包含新段名字的 <em>提交点</em> 被写入磁盘。</li><li>磁盘进行 <em>同步</em> — 所有在文件系统缓存中等待的写入都刷新到磁盘，以确保它们被写入物理文件。</li></ul></li><li>新的段被开启，让它包含的文档可见以被搜索。</li><li>内存缓存被清空，等待接收新的文档。</li></ol><p><strong>Figure 17. 一个在内存缓存中包含新文档的 Lucene 索引</strong></p><p><img src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1102.png" alt="A Lucene index with new documents in the in-memory buffer, ready to commit" /></p><p><strong>Figure 18. 在一次提交后，一个新的段被添加到提交点而且缓存被清空。</strong></p><p><img src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1103.png" alt="After a commit, a new segment is added to the index and the buffer is cleared" /></p><p>当一个查询被触发，所有已知的段按顺序被查询。词项统计会对所有段的结果进行聚合，以保证每个词和每个文档的关联都被准确计算。 这种方式可以用相对较低的成本将新文档添加到索引。</p><h3 id="24-删除和更新"><a class="markdownIt-Anchor" href="#24-删除和更新"></a> 2.4. 删除和更新</h3><p>段是不可改变的，所以既不能从把文档从旧的段中移除，也不能修改旧的段来进行反映文档的更新。 取而代之的是，每个提交点会包含一个 <code>.del</code> 文件，文件中会列出这些被删除文档的段信息。</p><p>当一个文档被 “删除” 时，它实际上只是在 <code>.del</code> 文件中被 <em>标记</em> 删除。一个被标记删除的文档仍然可以被查询匹配到， 但它会在最终结果被返回前从结果集中移除。</p><p>文档更新也是类似的操作方式：当一个文档被更新时，旧版本文档被标记删除，文档的新版本被索引到一个新的段中。 可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就已经被移除。</p><p>在 <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/merge-process.html" target="_blank" rel="noopener">段合并</a> , 我们展示了一个被删除的文档是怎样被文件系统移除的。</p><h3 id="25-近实时搜索"><a class="markdownIt-Anchor" href="#25-近实时搜索"></a> 2.5. 近实时搜索</h3><p>随着按段（per-segment）搜索的发展，一个新的文档从索引到可被搜索的延迟显著降低了。新文档在几分钟之内即可被检索，但这样还是不够快。</p><p>磁盘在这里成为了瓶颈。提交（Commiting）一个新的段到磁盘需要一个 <a href="http://en.wikipedia.org/wiki/Fsync" target="_blank" rel="noopener"><code>fsync</code></a> 来确保段被物理性地写入磁盘，这样在断电的时候就不会丢失数据。 但是 <code>fsync</code> 操作代价很大; 如果每次索引一个文档都去执行一次的话会造成很大的性能问题。</p><p>我们需要的是一个更轻量的方式来使一个文档可被搜索，这意味着 <code>fsync</code> 要从整个过程中被移除。</p><p>在 Elasticsearch 和磁盘之间是文件系统缓存。 像之前描述的一样， 在内存索引缓冲区（ <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/near-real-time.html#img-pre-refresh" target="_blank" rel="noopener">Figure 19, “在内存缓冲区中包含了新文档的 Lucene 索引”</a> ）中的文档会被写入到一个新的段中（ <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/near-real-time.html#img-post-refresh" target="_blank" rel="noopener">Figure 20, “缓冲区的内容已经被写入一个可被搜索的段中，但还没有进行提交”</a> ）。 但是这里新段会被先写入到文件系统缓存—这一步代价会比较低，稍后再被刷新到磁盘—这一步代价比较高。不过只要文件已经在缓存中， 就可以像其它文件一样被打开和读取了。</p><p><strong>Figure 19. 在内存缓冲区中包含了新文档的 Lucene 索引</strong></p><p><img src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1104.png" alt="A Lucene index with new documents in the in-memory buffer" /></p><p>Lucene 允许新段被写入和打开—使其包含的文档在未进行一次完整提交时便对搜索可见。 这种方式比进行一次提交代价要小得多，并且在不影响性能的前提下可以被频繁地执行。</p><p><strong>Figure 20. 缓冲区的内容已经被写入一个可被搜索的段中，但还没有进行提交</strong></p><p><img src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1105.png" alt="The buffer contents have been written to a segment, which is searchable, but is not yet commited" /></p><h3 id="26-refresh-api"><a class="markdownIt-Anchor" href="#26-refresh-api"></a> 2.6. refresh API</h3><p>在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做 <em>refresh</em> 。 默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch 是 <em>近</em> 实时搜索: 文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。</p><p>这些行为可能会对新用户造成困惑: 他们索引了一个文档然后尝试搜索它，但却没有搜到。这个问题的解决办法是用 <code>refresh</code> API 执行一次手动刷新:</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST /_refresh</span><br><span class="line">POST /blogs/_refresh</span><br></pre></td></tr></table></figure><p>刷新（Refresh）所有的索引</p><p>只刷新（Refresh） blogs 索引</p><blockquote><p>尽管刷新是比提交轻量很多的操作，它还是会有性能开销。当写测试的时候， 手动刷新很有用，但是不要在生产环境下每次索引一个文档都去手动刷新。 相反，你的应用需要意识到 Elasticsearch 的近实时的性质，并接受它的不足。</p></blockquote><p>并不是所有的情况都需要每秒刷新。可能你正在使用 Elasticsearch 索引大量的日志文件， 你可能想优化索引速度而不是近实时搜索， 可以通过设置 <code>refresh_interval</code> ， 降低每个索引的刷新频率：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">PUT /my_logs</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"refresh_interval"</span>: <span class="string">"30s"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>每 30 秒刷新 <code>my_logs</code> 索引。</p></blockquote><p><code>refresh_interval</code> 可以在既存索引上进行动态更新。 在生产环境中，当你正在建立一个大的新索引时，可以先关闭自动刷新，待开始使用该索引时，再把它们调回来：</p><figure class="highlight puppet"><table><tr><td class="code"><pre><span class="line">PUT /my_logs/_settings</span><br><span class="line">&#123; <span class="string">"refresh_interval"</span>: -1 &#125;</span><br><span class="line"></span><br><span class="line">PUT /my_logs/_settings</span><br><span class="line">&#123; <span class="string">"refresh_interval"</span>: <span class="string">"1s"</span> &#125;</span><br></pre></td></tr></table></figure><ul><li><p>关闭自动刷新。</p></li><li><p>每秒自动刷新。</p></li></ul><blockquote><p><code>refresh_interval</code> 需要一个 <em>持续时间</em> 值， 例如 <code>1s</code> （1 秒） 或 <code>2m</code> （2 分钟）。 一个绝对值 <em>1</em> 表示的是 <em>1 毫秒</em> --无疑会使你的集群陷入瘫痪。</p></blockquote><h3 id="27-持久化变更"><a class="markdownIt-Anchor" href="#27-持久化变更"></a> 2.7. 持久化变更</h3><p>如果没有用 <code>fsync</code> 把数据从文件系统缓存刷（flush）到硬盘，我们不能保证数据在断电甚至是程序正常退出之后依然存在。为了保证 Elasticsearch 的可靠性，需要确保数据变化被持久化到磁盘。</p><p>在 <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/dynamic-indices.html" target="_blank" rel="noopener">动态更新索引</a>，我们说一次完整的提交会将段刷到磁盘，并写入一个包含所有段列表的提交点。Elasticsearch 在启动或重新打开一个索引的过程中使用这个提交点来判断哪些段隶属于当前分片。</p><p>即使通过每秒刷新（refresh）实现了近实时搜索，我们仍然需要经常进行完整提交来确保能从失败中恢复。但在两次提交之间发生变化的文档怎么办？我们也不希望丢失掉这些数据。</p><p>Elasticsearch 增加了一个 <em>translog</em> ，或者叫事务日志，在每一次对 Elasticsearch 进行操作时均进行了日志记录。通过 translog ，整个流程看起来是下面这样：</p><p>一个文档被索引之后，就会被添加到内存缓冲区，<em>并且</em> 追加到了 translog ，正如 <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/translog.html#img-xlog-pre-refresh" target="_blank" rel="noopener">Figure 21, “新的文档被添加到内存缓冲区并且被追加到了事务日志”</a> 描述的一样。</p><p><strong>Figure 21. 新的文档被添加到内存缓冲区并且被追加到了事务日志</strong></p><p><img src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1106.png" alt="New documents are added to the in-memory buffer and appended to the transaction log" /></p><p>刷新（refresh）使分片处于 <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/translog.html#img-xlog-post-refresh" target="_blank" rel="noopener">Figure 22, “刷新（refresh）完成后, 缓存被清空但是事务日志不会”</a> 描述的状态，分片每秒被刷新（refresh）一次：</p><ul><li>这些在内存缓冲区的文档被写入到一个新的段中，且没有进行 <code>fsync</code> 操作。</li><li>这个段被打开，使其可被搜索。</li><li>内存缓冲区被清空。</li></ul><p><strong>Figure 22. 刷新（refresh）完成后, 缓存被清空但是事务日志不会</strong></p><p><img src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1107.png" alt="After a refresh, the buffer is cleared but the transaction log is not" /></p><p>这个进程继续工作，更多的文档被添加到内存缓冲区和追加到事务日志（见 <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/translog.html#img-xlog-pre-flush" target="_blank" rel="noopener">Figure 23, “事务日志不断积累文档”</a> ）。</p><p><strong>Figure 23. 事务日志不断积累文档</strong></p><p><img src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1108.png" alt="The transaction log keeps accumulating documents" /></p><ol><li>每隔一段时间—例如 translog 变得越来越大—索引被刷新（flush）；一个新的 translog 被创建，并且一个全量提交被执行（见 <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/translog.html#img-xlog-post-flush" target="_blank" rel="noopener">Figure 24, “在刷新（flush）之后，段被全量提交，并且事务日志被清空”</a> ）：<ul><li>所有在内存缓冲区的文档都被写入一个新的段。</li><li>缓冲区被清空。</li><li>一个提交点被写入硬盘。</li><li>文件系统缓存通过 <code>fsync</code> 被刷新（flush）。</li><li>老的 translog 被删除。</li></ul></li></ol><p>translog 提供所有还没有被刷到磁盘的操作的一个持久化纪录。当 Elasticsearch 启动的时候， 它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放 translog 中所有在最后一次提交后发生的变更操作。</p><p>translog 也被用来提供实时 CRUD 。当你试着通过 ID 查询、更新、删除一个文档，它会在尝试从相应的段中检索之前， 首先检查 translog 任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本。</p><p><strong>Figure 24. 在刷新（flush）之后，段被全量提交，并且事务日志被清空</strong></p><p><img src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1109.png" alt="After a flush, the segments are fully commited and the transaction log is cleared" /></p><h3 id="28-flush-api"><a class="markdownIt-Anchor" href="#28-flush-api"></a> 2.8. flush API</h3><p>这个执行一个提交并且截断 translog 的行为在 Elasticsearch 被称作一次 <em>flush</em> 。 分片每 30 分钟被自动刷新（flush），或者在 translog 太大的时候也会刷新。请查看 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/2.4/index-modules-translog.html#_translog_settings" target="_blank" rel="noopener"><code>translog</code> 文档</a> 来设置，它可以用来 控制这些阈值：</p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/indices-flush.html" target="_blank" rel="noopener"><code>flush</code> API</a> 可以被用来执行一个手工的刷新（flush）:</p><figure class="highlight jboss-cli"><table><tr><td class="code"><pre><span class="line">POST <span class="string">/blogs/_flush</span></span><br><span class="line">POST <span class="string">/_flush</span>?wait_for_ongoing</span><br></pre></td></tr></table></figure><ul><li>刷新（flush） blogs 索引。</li><li>刷新（flush）所有的索引并且并且等待所有刷新在返回前完成。</li></ul><p>你很少需要自己手动执行 <code>flush</code> 操作；通常情况下，自动刷新就足够了。</p><p>这就是说，在重启节点或关闭索引之前执行 <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/translog.html#flush-api" target="_blank" rel="noopener">flush</a> 有益于你的索引。当 Elasticsearch 尝试恢复或重新打开一个索引， 它需要重放 translog 中所有的操作，所以如果日志越短，恢复越快。</p><blockquote><p>translog 的目的是保证操作不会丢失。这引出了这个问题： Translog 有多安全？</p><p>在文件被 <code>fsync</code> 到磁盘前，被写入的文件在重启之后就会丢失。默认 translog 是每 5 秒被 <code>fsync</code> 刷新到硬盘， 或者在每次写请求完成之后执行(e.g. index, delete, update, bulk)。这个过程在主分片和复制分片都会发生。最终， 基本上，这意味着在整个请求被 <code>fsync</code> 到主分片和复制分片的 translog 之前，你的客户端不会得到一个 200 OK 响应。</p><p>在每次请求后都执行一个 fsync 会带来一些性能损失，尽管实践表明这种损失相对较小（特别是 bulk 导入，它在一次请求中平摊了大量文档的开销）。</p><p>但是对于一些大容量的偶尔丢失几秒数据问题也并不严重的集群，使用异步的 fsync 还是比较有益的。比如，写入的数据被缓存到内存中，再每 5 秒执行一次 <code>fsync</code> 。</p><p>这个行为可以通过设置 <code>durability</code> 参数为 <code>async</code> 来启用：</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">PUT /my_index/_settings</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"index.translog.durability"</span>: <span class="string">"async"</span>,</span><br><span class="line">    <span class="string">"index.translog.sync_interval"</span>: <span class="string">"5s"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个选项可以针对索引单独设置，并且可以动态进行修改。如果你决定使用异步 translog 的话，你需要 <em>保证</em> 在发生 crash 时，丢失掉 <code>sync_interval</code> 时间段的数据也无所谓。请在决定前知晓这个特性。</p><p>如果你不确定这个行为的后果，最好是使用默认的参数（ <code>&quot;index.translog.durability&quot;: &quot;request&quot;</code> ）来避免数据丢失。</p></blockquote><h3 id="29-段合并"><a class="markdownIt-Anchor" href="#29-段合并"></a> 2.9. 段合并</h3><p>由于自动刷新流程每秒会创建一个新的段 ，这样会导致短时间内的段数量暴增。而段数目太多会带来较大的麻烦。 每一个段都会消耗文件句柄、内存和 cpu 运行周期。更重要的是，每个搜索请求都必须轮流检查每个段；所以段越多，搜索也就越慢。</p><p>Elasticsearch 通过在后台进行段合并来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。</p><p>段合并的时候会将那些旧的已删除文档从文件系统中清除。被删除的文档（或被更新文档的旧版本）不会被拷贝到新的大段中。</p><p>启动段合并不需要你做任何事。进行索引和搜索时会自动进行。这个流程像在 <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/merge-process.html#img-merge" target="_blank" rel="noopener">Figure 25, “两个提交了的段和一个未提交的段正在被合并到一个更大的段”</a> 中提到的一样工作：</p><p>1、 当索引的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用。</p><p>2、 合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。</p><p><strong>Figure 25. 两个提交了的段和一个未提交的段正在被合并到一个更大的段</strong></p><p><img src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1110.png" alt="Two commited segments and one uncommited segment in the process of being merged into a bigger segment" /></p><p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/merge-process.html#img-post-merge" target="_blank" rel="noopener">Figure 26, “一旦合并结束，老的段被删除”</a> 说明合并完成时的活动：</p><ul><li>新的段被刷新（flush）到了磁盘。 ** 写入一个包含新段且排除旧的和较小的段的新提交点。</li><li>新的段被打开用来搜索。</li><li>老的段被删除。</li></ul><p><strong>Figure 26. 一旦合并结束，老的段被删除</strong></p><p><img src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1111.png" alt="一旦合并结束，老的段被删除" /></p><p>合并大的段需要消耗大量的 I/O 和 CPU 资源，如果任其发展会影响搜索性能。Elasticsearch 在默认情况下会对合并流程进行资源限制，所以搜索仍然 有足够的资源很好地执行。</p><h3 id="210-optimize-api"><a class="markdownIt-Anchor" href="#210-optimize-api"></a> 2.10. optimize API</h3><p><code>optimize</code> API 大可看做是 <em>强制合并</em> API。它会将一个分片强制合并到 <code>max_num_segments</code> 参数指定大小的段数目。 这样做的意图是减少段的数量（通常减少到一个），来提升搜索性能。</p><blockquote><p><code>optimize</code> API <em>不应该</em> 被用在一个活跃的索引————一个正积极更新的索引。后台合并流程已经可以很好地完成工作。 optimizing 会阻碍这个进程。不要干扰它！</p></blockquote><p>在特定情况下，使用 <code>optimize</code> API 颇有益处。例如在日志这种用例下，每天、每周、每月的日志被存储在一个索引中。 老的索引实质上是只读的；它们也并不太可能会发生变化。</p><p>在这种情况下，使用 optimize 优化老的索引，将每一个分片合并为一个单独的段就很有用了；这样既可以节省资源，也可以使搜索更加快速：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST /logstash-2014-10/_optimize?max_num_segments=1</span><br></pre></td></tr></table></figure><p>合并索引中的每个分片为一个单独的段</p><blockquote><p>请注意，使用 <code>optimize</code> API 触发段合并的操作不会受到任何资源上的限制。这可能会消耗掉你节点上全部的 I/O 资源, 使其没有余裕来处理搜索请求，从而有可能使集群失去响应。 如果你想要对索引执行 <code>optimize</code>，你需要先使用分片分配（查看 <a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/retiring-data.html#migrate-indices" target="_blank" rel="noopener">迁移旧索引</a>）把索引移到一个安全的节点，再执行。</p></blockquote><h2 id="3-参考资料"><a class="markdownIt-Anchor" href="#3-参考资料"></a> 3. 参考资料</h2><ul><li><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/distributed-cluster.html" target="_blank" rel="noopener">Elasticsearch 官方文档之 集群内的原理</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;elasticsearch-集群和分片&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#elasticsearch-集群和分片&quot;&gt;&lt;/a&gt; Elasticsearch 集群和分片&lt;/h1&gt;
&lt;!-- TOC depthFrom:2 dep
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/Elasticsearch/"/>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="分片" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E7%89%87/"/>
    
      <category term="集群" scheme="https://dunwu.github.io/blog/tags/%E9%9B%86%E7%BE%A4/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch Java API 之 High Level REST Client</title>
    <link href="https://dunwu.github.io/blog/2022/03/01/elasticsearch-java-api-%E4%B9%8B-high-level-rest-client/"/>
    <id>https://dunwu.github.io/blog/2022/03/01/elasticsearch-java-api-%E4%B9%8B-high-level-rest-client/</id>
    <published>2022-03-01T10:55:46.000Z</published>
    <updated>2022-04-14T08:45:53.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="elasticsearch-java-api-之-high-level-rest-client"><a class="markdownIt-Anchor" href="#elasticsearch-java-api-之-high-level-rest-client"></a> ElasticSearch Java API 之 High Level REST Client</h1><blockquote><p>Elasticsearch 官方的 High Level REST Client 在 7.1.5.0 版本废弃。所以本文中的 API 不推荐使用。</p></blockquote><h2 id="1-快速开始"><a class="markdownIt-Anchor" href="#1-快速开始"></a> 1. 快速开始</h2><h3 id="11-引入依赖"><a class="markdownIt-Anchor" href="#11-引入依赖"></a> 1.1. 引入依赖</h3><p>在 pom.xml 中引入以下依赖：</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.elasticsearch.client<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>elasticsearch-rest-high-level-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>7.17.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="12-创建连接和关闭"><a class="markdownIt-Anchor" href="#12-创建连接和关闭"></a> 1.2. 创建连接和关闭</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建连接</span></span><br><span class="line">RestHighLevelClient client = <span class="keyword">new</span> RestHighLevelClient(</span><br><span class="line">        RestClient.builder(</span><br><span class="line">                <span class="keyword">new</span> HttpHost(<span class="string">"localhost"</span>, <span class="number">9200</span>, <span class="string">"http"</span>),</span><br><span class="line">                <span class="keyword">new</span> HttpHost(<span class="string">"localhost"</span>, <span class="number">9201</span>, <span class="string">"http"</span>)));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 关闭</span></span><br><span class="line">client.close();</span><br></pre></td></tr></table></figure><h2 id="2-索引-api"><a class="markdownIt-Anchor" href="#2-索引-api"></a> 2. 索引 API</h2><h3 id="21-测试准备"><a class="markdownIt-Anchor" href="#21-测试准备"></a> 2.1. 测试准备</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String INDEX = <span class="string">"mytest"</span>;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String INDEX_ALIAS = <span class="string">"mytest_alias"</span>;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &#123;<span class="doctag">@link</span> User&#125; 的 mapping 结构（json形式）</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String MAPPING_JSON =</span><br><span class="line">  <span class="string">"&#123;\n"</span> + <span class="string">"  \"properties\": &#123;\n"</span> + <span class="string">"    \"_class\": &#123;\n"</span> + <span class="string">"      \"type\": \"keyword\",\n"</span></span><br><span class="line">  + <span class="string">"      \"index\": false,\n"</span> + <span class="string">"      \"doc_values\": false\n"</span> + <span class="string">"    &#125;,\n"</span> + <span class="string">"    \"description\": &#123;\n"</span></span><br><span class="line">  + <span class="string">"      \"type\": \"text\",\n"</span> + <span class="string">"      \"fielddata\": true\n"</span> + <span class="string">"    &#125;,\n"</span> + <span class="string">"    \"enabled\": &#123;\n"</span></span><br><span class="line">  + <span class="string">"      \"type\": \"boolean\"\n"</span> + <span class="string">"    &#125;,\n"</span> + <span class="string">"    \"name\": &#123;\n"</span> + <span class="string">"      \"type\": \"text\",\n"</span></span><br><span class="line">  + <span class="string">"      \"fielddata\": true\n"</span> + <span class="string">"    &#125;\n"</span> + <span class="string">"  &#125;\n"</span> + <span class="string">"&#125;"</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> RestHighLevelClient client;</span><br></pre></td></tr></table></figure><h3 id="22-创建索引"><a class="markdownIt-Anchor" href="#22-创建索引"></a> 2.2. 创建索引</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建索引</span></span><br><span class="line">CreateIndexRequest createIndexRequest = <span class="keyword">new</span> CreateIndexRequest(INDEX);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 设置索引的 settings</span></span><br><span class="line">  createIndexRequest.settings(</span><br><span class="line">  Settings.builder().put(<span class="string">"index.number_of_shards"</span>, <span class="number">3</span>).put(<span class="string">"index.number_of_replicas"</span>, <span class="number">2</span>));</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 设置索引的 mapping</span></span><br><span class="line">  createIndexRequest.mapping(MAPPING_JSON, XContentType.JSON);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 设置索引的别名</span></span><br><span class="line">  createIndexRequest.alias(<span class="keyword">new</span> Alias(INDEX_ALIAS));</span><br><span class="line"></span><br><span class="line">  AcknowledgedResponse createIndexResponse = client.indices().create(createIndexRequest, RequestOptions.DEFAULT);</span><br><span class="line">  Assertions.assertTrue(createIndexResponse.isAcknowledged());</span><br></pre></td></tr></table></figure><h3 id="23-删除索引"><a class="markdownIt-Anchor" href="#23-删除索引"></a> 2.3. 删除索引</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 删除索引</span></span><br><span class="line">DeleteIndexRequest deleteIndexRequest = <span class="keyword">new</span> DeleteIndexRequest(INDEX);</span><br><span class="line">  AcknowledgedResponse deleteResponse = client.indices().delete(deleteIndexRequest, RequestOptions.DEFAULT);</span><br><span class="line">  Assertions.assertTrue(deleteResponse.isAcknowledged());</span><br></pre></td></tr></table></figure><h3 id="24-判断索引是否存在"><a class="markdownIt-Anchor" href="#24-判断索引是否存在"></a> 2.4. 判断索引是否存在</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">GetIndexRequest getIndexRequest = <span class="keyword">new</span> GetIndexRequest(INDEX);</span><br><span class="line">  Assertions.assertTrue(client.indices().exists(getIndexRequest, RequestOptions.DEFAULT));</span><br><span class="line">  GetIndexRequest getIndexAliasRequest = <span class="keyword">new</span> GetIndexRequest(INDEX_ALIAS);</span><br><span class="line">  Assertions.assertTrue(client.indices().exists(getIndexAliasRequest, RequestOptions.DEFAULT));</span><br></pre></td></tr></table></figure><h2 id="3-文档-api"><a class="markdownIt-Anchor" href="#3-文档-api"></a> 3. 文档 API</h2><h3 id="31-文档测试准备"><a class="markdownIt-Anchor" href="#31-文档测试准备"></a> 3.1. 文档测试准备</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String INDEX = <span class="string">"mytest"</span>;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String INDEX_ALIAS = <span class="string">"mytest_alias"</span>;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &#123;<span class="doctag">@link</span> User&#125; 的 mapping 结构（json形式）</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String MAPPING_JSON =</span><br><span class="line">  <span class="string">"&#123;\n"</span> + <span class="string">"  \"properties\": &#123;\n"</span> + <span class="string">"    \"_class\": &#123;\n"</span> + <span class="string">"      \"type\": \"keyword\",\n"</span></span><br><span class="line">  + <span class="string">"      \"index\": false,\n"</span> + <span class="string">"      \"doc_values\": false\n"</span> + <span class="string">"    &#125;,\n"</span> + <span class="string">"    \"description\": &#123;\n"</span></span><br><span class="line">  + <span class="string">"      \"type\": \"text\",\n"</span> + <span class="string">"      \"fielddata\": true\n"</span> + <span class="string">"    &#125;,\n"</span> + <span class="string">"    \"enabled\": &#123;\n"</span></span><br><span class="line">  + <span class="string">"      \"type\": \"boolean\"\n"</span> + <span class="string">"    &#125;,\n"</span> + <span class="string">"    \"name\": &#123;\n"</span> + <span class="string">"      \"type\": \"text\",\n"</span></span><br><span class="line">  + <span class="string">"      \"fielddata\": true\n"</span> + <span class="string">"    &#125;\n"</span> + <span class="string">"  &#125;\n"</span> + <span class="string">"&#125;"</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> RestHighLevelClient client;</span><br><span class="line"></span><br><span class="line"><span class="meta">@BeforeEach</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 创建索引</span></span><br><span class="line">  CreateIndexRequest createIndexRequest = <span class="keyword">new</span> CreateIndexRequest(INDEX);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 设置索引的 settings</span></span><br><span class="line">  createIndexRequest.settings(</span><br><span class="line">  Settings.builder().put(<span class="string">"index.number_of_shards"</span>, <span class="number">3</span>).put(<span class="string">"index.number_of_replicas"</span>, <span class="number">2</span>));</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 设置索引的 mapping</span></span><br><span class="line">  createIndexRequest.mapping(MAPPING_JSON, XContentType.JSON);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 设置索引的别名</span></span><br><span class="line">  createIndexRequest.alias(<span class="keyword">new</span> Alias(INDEX_ALIAS));</span><br><span class="line"></span><br><span class="line">  AcknowledgedResponse response = client.indices().create(createIndexRequest, RequestOptions.DEFAULT);</span><br><span class="line">  Assertions.assertTrue(response.isAcknowledged());</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 判断索引是否存在</span></span><br><span class="line">  GetIndexRequest getIndexRequest = <span class="keyword">new</span> GetIndexRequest(INDEX_ALIAS);</span><br><span class="line">  Assertions.assertTrue(client.indices().exists(getIndexRequest, RequestOptions.DEFAULT));</span><br><span class="line">  GetIndexRequest getIndexAliasRequest = <span class="keyword">new</span> GetIndexRequest(INDEX_ALIAS);</span><br><span class="line">  Assertions.assertTrue(client.indices().exists(getIndexAliasRequest, RequestOptions.DEFAULT));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@AfterEach</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">destroy</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// 删除索引</span></span><br><span class="line">  DeleteIndexRequest request = <span class="keyword">new</span> DeleteIndexRequest(INDEX);</span><br><span class="line">  AcknowledgedResponse response = client.indices().delete(request, RequestOptions.DEFAULT);</span><br><span class="line">  Assertions.assertTrue(response.isAcknowledged());</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h3 id="32-创建文档"><a class="markdownIt-Anchor" href="#32-创建文档"></a> 3.2. 创建文档</h3><p>RestHighLevelClient Api 使用 <code>IndexRequest</code> 来构建创建文档的请求参数。</p><p>【示例】创建 id 为 1 的文档</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">IndexRequest request = <span class="keyword">new</span> IndexRequest(<span class="string">"product"</span>);</span><br><span class="line">  request.id(<span class="string">"1"</span>);</span><br><span class="line">  Product product = <span class="keyword">new</span> Product();</span><br><span class="line">  product.setName(<span class="string">"机器人"</span>);</span><br><span class="line">  product.setDescription(<span class="string">"人工智能机器人"</span>);</span><br><span class="line">  product.setEnabled(<span class="keyword">true</span>);</span><br><span class="line">  String jsonString = JSONUtil.toJsonStr(product);</span><br><span class="line">  request.source(jsonString, XContentType.JSON);</span><br></pre></td></tr></table></figure><p>同步执行</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">IndexResponse indexResponse = client.index(request, RequestOptions.DEFAULT);</span><br></pre></td></tr></table></figure><p>异步执行</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 异步执行</span></span><br><span class="line">client.indexAsync(request, RequestOptions.DEFAULT, <span class="keyword">new</span> ActionListener&lt;IndexResponse&gt;() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onResponse</span><span class="params">(IndexResponse indexResponse)</span> </span>&#123;</span><br><span class="line">  System.out.println(indexResponse);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(Exception e)</span> </span>&#123;</span><br><span class="line">  System.out.println(<span class="string">"执行失败"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  &#125;);</span><br></pre></td></tr></table></figure><h3 id="33-删除文档"><a class="markdownIt-Anchor" href="#33-删除文档"></a> 3.3. 删除文档</h3><p>RestHighLevelClient Api 使用 <code>DeleteRequest</code> 来构建删除文档的请求参数。</p><p>【示例】删除 id 为 1 的文档</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DeleteRequest deleteRequest = <span class="keyword">new</span> DeleteRequest(INDEX_ALIAS, <span class="string">"1"</span>);</span><br></pre></td></tr></table></figure><p>同步执行</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">DeleteResponse deleteResponse = client.delete(deleteRequest, RequestOptions.DEFAULT);</span><br><span class="line">  System.out.println(deleteResponse);</span><br></pre></td></tr></table></figure><p>异步执行</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">client.deleteAsync(deleteRequest, RequestOptions.DEFAULT, <span class="keyword">new</span> ActionListener&lt;DeleteResponse&gt;() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onResponse</span><span class="params">(DeleteResponse deleteResponse)</span> </span>&#123;</span><br><span class="line">  System.out.println(deleteResponse);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(Exception e)</span> </span>&#123;</span><br><span class="line">  System.out.println(<span class="string">"执行失败"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  &#125;);</span><br></pre></td></tr></table></figure><h3 id="34-更新文档"><a class="markdownIt-Anchor" href="#34-更新文档"></a> 3.4. 更新文档</h3><p>RestHighLevelClient Api 使用 <code>UpdateRequest</code> 来构建更新文档的请求参数。</p><p>【示例】更新 id 为 1 的文档</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">UpdateRequest updateRequest = <span class="keyword">new</span> UpdateRequest(INDEX_ALIAS, <span class="string">"1"</span>);</span><br><span class="line">  Product product3 = <span class="keyword">new</span> Product();</span><br><span class="line">  product3.setName(<span class="string">"扫地机器人"</span>);</span><br><span class="line">  product3.setDescription(<span class="string">"人工智能扫地机器人"</span>);</span><br><span class="line">  product3.setEnabled(<span class="keyword">true</span>);</span><br><span class="line">  String jsonString2 = JSONUtil.toJsonStr(product3);</span><br><span class="line">  updateRequest.doc(jsonString2, XContentType.JSON);</span><br></pre></td></tr></table></figure><p>同步执行</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">UpdateResponse updateResponse = client.update(updateRequest, RequestOptions.DEFAULT);</span><br><span class="line">  System.out.println(updateResponse);</span><br></pre></td></tr></table></figure><p>异步执行</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">client.updateAsync(updateRequest, RequestOptions.DEFAULT, <span class="keyword">new</span> ActionListener&lt;UpdateResponse&gt;() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onResponse</span><span class="params">(UpdateResponse updateResponse)</span> </span>&#123;</span><br><span class="line">  System.out.println(updateResponse);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(Exception e)</span> </span>&#123;</span><br><span class="line">  System.out.println(<span class="string">"执行失败"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  &#125;);</span><br></pre></td></tr></table></figure><h3 id="35-查看文档"><a class="markdownIt-Anchor" href="#35-查看文档"></a> 3.5. 查看文档</h3><p>RestHighLevelClient Api 使用 <code>GetRequest</code> 来构建查看文档的请求参数。</p><p>【示例】查看 id 为 1 的文档</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">GetRequest getRequest = <span class="keyword">new</span> GetRequest(INDEX_ALIAS, <span class="string">"1"</span>);</span><br></pre></td></tr></table></figure><p>同步执行</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">GetResponse getResponse = client.get(getRequest, RequestOptions.DEFAULT);</span><br></pre></td></tr></table></figure><p>异步执行</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">client.getAsync(getRequest, RequestOptions.DEFAULT, <span class="keyword">new</span> ActionListener&lt;GetResponse&gt;() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onResponse</span><span class="params">(GetResponse getResponse)</span> </span>&#123;</span><br><span class="line">  System.out.println(getResponse);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onFailure</span><span class="params">(Exception e)</span> </span>&#123;</span><br><span class="line">  System.out.println(<span class="string">"执行失败"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h3 id="36-获取匹配条件的记录总数"><a class="markdownIt-Anchor" href="#36-获取匹配条件的记录总数"></a> 3.6. 获取匹配条件的记录总数</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="meta">@DisplayName</span>(<span class="string">"获取匹配条件的记录总数"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">count</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    SearchSourceBuilder sourceBuilder = <span class="keyword">new</span> SearchSourceBuilder();</span><br><span class="line">    sourceBuilder.query(QueryBuilders.matchPhraseQuery(<span class="string">"customer_gender"</span>, <span class="string">"MALE"</span>));</span><br><span class="line">    sourceBuilder.trackTotalHits(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">    CountRequest countRequest = <span class="keyword">new</span> CountRequest(INDEX);</span><br><span class="line">    countRequest.source(sourceBuilder);</span><br><span class="line"></span><br><span class="line">    CountResponse countResponse = client.count(countRequest, RequestOptions.DEFAULT);</span><br><span class="line">    <span class="keyword">long</span> count = countResponse.getCount();</span><br><span class="line">    System.out.println(<span class="string">"命中记录数："</span> + count);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="37-分页查询"><a class="markdownIt-Anchor" href="#37-分页查询"></a> 3.7. 分页查询</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ParameterizedTest</span></span><br><span class="line"><span class="meta">@ValueSource</span>(ints = &#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;)</span><br><span class="line"><span class="meta">@DisplayName</span>(<span class="string">"分页查询测试"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">pageTest</span><span class="params">(<span class="keyword">int</span> page)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> size = <span class="number">10</span>;</span><br><span class="line">    <span class="keyword">int</span> offset = page * size;</span><br><span class="line">    SearchSourceBuilder sourceBuilder = <span class="keyword">new</span> SearchSourceBuilder();</span><br><span class="line">    sourceBuilder.query(QueryBuilders.matchPhraseQuery(<span class="string">"customer_gender"</span>, <span class="string">"MALE"</span>));</span><br><span class="line">    sourceBuilder.from(offset);</span><br><span class="line">    sourceBuilder.size(size);</span><br><span class="line">    sourceBuilder.trackTotalHits(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">    SearchRequest searchRequest = <span class="keyword">new</span> SearchRequest(INDEX);</span><br><span class="line">    searchRequest.source(sourceBuilder);</span><br><span class="line">    SearchResponse response = client.search(searchRequest, RequestOptions.DEFAULT);</span><br><span class="line">    SearchHit[] hits = response.getHits().getHits();</span><br><span class="line">    <span class="keyword">for</span> (SearchHit hit : hits) &#123;</span><br><span class="line">        KibanaSampleDataEcommerceBean bean =</span><br><span class="line">            BeanUtil.mapToBean(hit.getSourceAsMap(), KibanaSampleDataEcommerceBean<span class="class">.<span class="keyword">class</span>, <span class="title">true</span>,</span></span><br><span class="line"><span class="class">                               <span class="title">CopyOptions</span>.<span class="title">create</span>())</span>;</span><br><span class="line">        System.out.println(bean);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="38-条件查询"><a class="markdownIt-Anchor" href="#38-条件查询"></a> 3.8. 条件查询</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="meta">@DisplayName</span>(<span class="string">"条件查询"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">matchPhraseQuery</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    SearchRequest searchRequest = <span class="keyword">new</span> SearchRequest(INDEX);</span><br><span class="line">    SearchSourceBuilder sourceBuilder = <span class="keyword">new</span> SearchSourceBuilder();</span><br><span class="line"></span><br><span class="line">    BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();</span><br><span class="line">    boolQueryBuilder.must(QueryBuilders.matchPhraseQuery(<span class="string">"customer_last_name"</span>, <span class="string">"Jensen"</span>));</span><br><span class="line">    sourceBuilder.query(boolQueryBuilder);</span><br><span class="line">    sourceBuilder.trackTotalHits(<span class="keyword">true</span>);</span><br><span class="line">    searchRequest.source(sourceBuilder);</span><br><span class="line">    SearchResponse response = client.search(searchRequest, RequestOptions.DEFAULT);</span><br><span class="line">    SearchHit[] hits = response.getHits().getHits();</span><br><span class="line">    <span class="keyword">for</span> (SearchHit hit : hits) &#123;</span><br><span class="line">        KibanaSampleDataEcommerceBean bean =</span><br><span class="line">            BeanUtil.mapToBean(hit.getSourceAsMap(), KibanaSampleDataEcommerceBean<span class="class">.<span class="keyword">class</span>, <span class="title">true</span>,</span></span><br><span class="line"><span class="class">                               <span class="title">CopyOptions</span>.<span class="title">create</span>())</span>;</span><br><span class="line">        System.out.println(bean);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4-参考资料"><a class="markdownIt-Anchor" href="#4-参考资料"></a> 4. 参考资料</h2><ul><li><strong>官方</strong><ul><li><a href="https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/java-rest-high.html" target="_blank" rel="noopener">Java High Level REST Client</a></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;elasticsearch-java-api-之-high-level-rest-client&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#elasticsearch-java-api-之-high-level-rest-client
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/Elasticsearch/"/>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/tags/Elasticsearch/"/>
    
      <category term="API" scheme="https://dunwu.github.io/blog/tags/API/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch 简介</title>
    <link href="https://dunwu.github.io/blog/2022/02/22/elasticsearch-%E7%AE%80%E4%BB%8B/"/>
    <id>https://dunwu.github.io/blog/2022/02/22/elasticsearch-%E7%AE%80%E4%BB%8B/</id>
    <published>2022-02-22T13:01:01.000Z</published>
    <updated>2022-04-14T08:45:53.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="elasticsearch-简介"><a class="markdownIt-Anchor" href="#elasticsearch-简介"></a> Elasticsearch 简介</h1><p>Elasticsearch 是一个基于 Lucene 的搜索和数据分析工具，它提供了一个分布式服务。Elasticsearch 是遵从 Apache 开源条款的一款开源产品，是当前主流的企业级搜索引擎。</p><p>它用于全文搜索、结构化搜索、分析以及将这三者混合使用：</p><ul><li>维基百科使用 Elasticsearch 提供全文搜索并高亮关键字，以及**输入实时搜索(search-as-you-type)<strong>和</strong>搜索纠错(did-you-mean)**等搜索建议功能。</li><li>英国卫报使用 Elasticsearch 结合用户日志和社交网络数据提供给他们的编辑以实时的反馈，以便及时了解公众对新发表的文章的回应。</li><li>StackOverflow 结合全文搜索与地理位置查询，以及<strong>more-like-this</strong>功能来找到相关的问题和答案。</li><li>Github 使用 Elasticsearch 检索 1300 亿行的代码。</li></ul><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#1-elasticsearch-%E7%89%B9%E7%82%B9">1. Elasticsearch 特点</a></li><li><a href="#2-elasticsearch-%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2">2. Elasticsearch 发展历史</a></li><li><a href="#3-elasticsearch-%E6%A6%82%E5%BF%B5">3. Elasticsearch 概念</a><ul><li><a href="#31-%E8%BF%91%E5%AE%9E%E6%97%B6nrt">3.1. 近实时（NRT）</a></li><li><a href="#32-%E7%B4%A2%E5%BC%95index">3.2. 索引（Index）</a></li><li><a href="#33-%E7%B1%BB%E5%9E%8Btype">3.3. <s>类型（Type）</s></a></li><li><a href="#34-%E6%96%87%E6%A1%A3document">3.4. 文档（Document）</a></li><li><a href="#35-%E8%8A%82%E7%82%B9node">3.5. 节点（Node）</a></li><li><a href="#36-%E9%9B%86%E7%BE%A4cluster">3.6. 集群（Cluster）</a></li><li><a href="#37-%E5%88%86%E7%89%87shards">3.7. 分片（Shards）</a></li><li><a href="#38-%E5%89%AF%E6%9C%ACreplicas">3.8. 副本（Replicas）</a></li></ul></li><li><a href="#4-%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">4. 参考资料</a></li></ul><!-- /TOC --><h2 id="1-elasticsearch-特点"><a class="markdownIt-Anchor" href="#1-elasticsearch-特点"></a> 1. Elasticsearch 特点</h2><ul><li>分布式的实时文件存储，每个字段都被索引并可被搜索；</li><li>分布式的实时分析搜索引擎；</li><li>可弹性扩展到上百台服务器规模，处理 PB 级结构化或非结构化数据；</li><li>开箱即用（安装即可使用），它提供了许多合理的缺省值，并对初学者隐藏了复杂的搜索引擎理论。只需很少的学习既可在生产环境中使用。</li></ul><h2 id="2-elasticsearch-发展历史"><a class="markdownIt-Anchor" href="#2-elasticsearch-发展历史"></a> 2. Elasticsearch 发展历史</h2><ul><li><p>2010 年 2 月 8 日，Elasticsearch 第一个公开版本发布。</p></li><li><p>2010 年 5 月 14 日，发布第一个具有里程碑意义的初始版本 <strong>0.7.0</strong> ，具有如下特征：</p></li><li><p>Zen Discovery 自动发现模块；</p><ul><li>支持 Groovy Client；</li></ul></li><li><p>简单的插件管理机制；</p><ul><li>更好地支持 icu 分词器；</li></ul></li><li><p>更多的管理 api。</p></li><li><p>2013 年初，GitHub 抛弃了 Solr，采取 ElasticSearch 来做其 PB 级的搜索。</p></li><li><p>2014 年 2 月 14 日，发布 <strong>1.0.0</strong> 版本，增加如下重要特性：</p></li><li><p>支持 Snapshot/Restore API 备份恢复 API；</p><ul><li>支持聚合分析 Aggregations；</li></ul></li><li><p>支持 cat api；</p><ul><li>支持断路器；</li></ul></li><li><p>引入 Doc values。</p></li><li><p>2015 年 10 月 28 日，发布 <strong>2.0.0</strong> 版本，有如下重要特性：</p></li><li><p>增加了 Pipleline Aggregations；</p><ul><li>query/filter 查询合并，都合并到 query 中，根据不同的上下文执行不同的查询；</li></ul></li><li><p>压缩存储可配置；</p><ul><li>Rivers 模块被移除；</li></ul></li><li><p>Multicast 组播发现被移除，成为一个插件，生产环境必须配置单播地址。</p></li><li><p>2016 年 10 月 26 日，发布 <strong>5.0.0</strong> 版本，有如下重大特性变化：</p></li><li><p>Lucene 6.x 的支持，磁盘空间少一半；索引时间少一半；查询性能提升 25%；支持 IPV6；</p><ul><li>Internal Engine 级别移除了用于避免同一文档并发更新的竞争锁，带来 15%-20% 的性能提升；</li></ul></li><li><p>Shrink API，它可将分片数进行收缩成它的因数，如之前你是 15 个分片，你可以收缩成 5 个或者 3 个又或者 1 个，那么我们就可以想象成这样一种场景，在写入压力非常大的收集阶段，设置足够多的索引，充分利用 shard 的并行写能力，索引写完之后收缩成更少的 shard，提高查询性能；</p><ul><li>提供了第一个 Java 原生的 REST 客户端 SDK；</li></ul></li><li><p>IngestNode，之前如果需要对数据进行加工，都是在索引之前进行处理，比如 logstash 可以对日志进行结构化和转换，现在直接在 es 就可以处理了；</p><ul><li>提供了 Painless 脚本，代替 Groovy 脚本；</li><li>移除 site plugins，就是说 head、bigdesk 都不能直接装 es 里面了，不过可以部署独立站点（反正都是静态文件）或开发 kibana 插件；</li><li>新增 Sliced Scroll 类型，现在 Scroll 接口可以并发来进行数据遍历了。每个 Scroll 请求，可以分成多个 Slice 请求，可以理解为切片，各 Slice 独立并行，利用 Scroll 重建或者遍历要快很多倍；</li><li>新增了 Profile API；</li><li>新增了 Rollover API；</li><li>新增 Reindex；</li><li>引入新的字段类型 Text/Keyword 来替换 String；</li><li>限制索引请求大小，避免大量并发请求压垮 ES；</li><li>限制单个请求的 shards 数量，默认 1000 个。</li></ul></li><li><p>2017 年 8 月 31 日，发布 <strong>6.0.0</strong> 版本，具有如下重要特性：</p></li><li><p>稀疏性 Doc Values 的支持；</p><ul><li>Index Sorting，即索引阶段的排序；</li></ul></li><li><p>顺序号的支持，每个 es 的操作都有一个顺序编号（类似增量设计）；</p><ul><li>无缝滚动升级；</li></ul></li><li><p>从 6.0 开始不支持一个 index 里面存在多个 type；</p><ul><li>Index-template inheritance，索引版本的继承，目前索引模板是所有匹配的都会合并，这样会造成索引模板有一些冲突问题， 6.0 将会只匹配一个，索引创建时也会进行验证；</li><li>Load aware shard routing， 基于负载的请求路由，目前的搜索请求是全节点轮询，那么性能最慢的节点往往会造成整体的延迟增加，新的实现方式将基于队列的耗费时间自动调节队列长度，负载高的节点的队列长度将减少，让其他节点分摊更多的压力，搜索和索引都将基于这种机制；</li><li>已经关闭的索引将也支持 replica 的自动处理，确保数据可靠。</li></ul></li><li><p>2019 年 4 月 10 日，发布 <strong>7.0.0</strong> 版本，具有如下重要特性：</p></li><li><p>集群连接变化：TransportClient 被废弃，es7 的 java 代码，只能使用 restclient；对于 java 编程，建议采用 High-level-rest-client 的方式操作 ES 集群；</p><ul><li>ES 程序包默认打包 jdk：7.x 版本的程序包大小变成 300MB+，对比 6.x，包大了 200MB+，这正是 JDK 的大小；</li></ul></li><li><p>采用基于 Lucene 9.0；</p><ul><li>正式废除单个索引下多 Type 的支持，es6 时，官方就提到了 es7 会删除 type，并且 es6 时，已经规定每一个 index 只能有一个 type。在 es7 中，使用默认的 _doc 作为 type，官方说在 8.x 版本会彻底移除 type。api 请求方式也发送变化，如获得某索引的某 ID 的文档：GET index/_doc/id 其中 index 和 id 为具体的值；</li></ul></li><li><p>引入了真正的内存断路器，它可以更精准地检测出无法处理的请求，并防止它们使单个节点不稳定；</p><ul><li>Zen2 是 Elasticsearch 的全新集群协调层，提高了可靠性、性能和用户体验，变得更快、更安全，并更易于使用。</li></ul></li></ul><h2 id="3-elasticsearch-概念"><a class="markdownIt-Anchor" href="#3-elasticsearch-概念"></a> 3. Elasticsearch 概念</h2><p>下列有一些概念是 Elasticsearch 的核心。从一开始就理解这些概念将极大地帮助简化学习 Elasticsearch 的过程。</p><h3 id="31-近实时nrt"><a class="markdownIt-Anchor" href="#31-近实时nrt"></a> 3.1. 近实时（NRT）</h3><p>Elasticsearch 是一个近乎实时的搜索平台。这意味着<strong>从索引文档到可搜索文档的时间有一点延迟</strong>（通常是一秒）。</p><h3 id="32-索引index"><a class="markdownIt-Anchor" href="#32-索引index"></a> 3.2. 索引（Index）</h3><p>索引在不同语境，有着不同的含义</p><ul><li>索引（名词）：一个 <strong>索引</strong> 类似于传统关系数据库中的一个 <strong>数据库</strong> ，是一个存储关系型文档的容器。 索引 (<em>index</em>) 的复数词为 indices 或 indexes 。索引实际上是指向一个或者多个<strong>物理分片</strong>的<strong>逻辑命名空间</strong> 。</li><li>索引（动词）：索引一个文档 就是存储一个文档到一个 <em>索引</em> （名词）中以便被检索和查询。这非常类似于 SQL 语句中的 <code>INSERT</code> 关键词，除了文档已存在时，新文档会替换旧文档情况之外。</li><li>倒排索引：关系型数据库通过增加一个索引比如一个 B 树索引到指定的列上，以便提升数据检索速度。Elasticsearch 和 Lucene 使用了一个叫做 <strong>倒排索引</strong> 的结构来达到相同的目的。</li></ul><p>索引的 Mapping 和 Setting</p><ul><li><strong><code>Mapping</code></strong> 定义文档字段的类型</li><li><strong><code>Setting</code></strong> 定义不同的数据分布</li></ul><p>示例：</p><figure class="highlight"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    "settings": &#123; ... any settings ... &#125;,</span><br><span class="line">    "mappings": &#123;</span><br><span class="line">        "type_one": &#123; ... any mappings ... &#125;,</span><br><span class="line">        "type_two": &#123; ... any mappings ... &#125;,</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="倒排索引"><a class="markdownIt-Anchor" href="#倒排索引"></a> 倒排索引</h4><p><img src="https://raw.githubusercontent.com/dunwu/images/dev/snap/20220108215559.PNG" alt="img" /></p><h4 id="index-template"><a class="markdownIt-Anchor" href="#index-template"></a> index template</h4><p><strong><code>index template</code></strong>（索引模板）帮助用户设定 Mapping 和 Setting，并按照一定的规则，自动匹配到新创建的索引之上。</p><ul><li>模板仅在一个索引被创建时，才会产生作用。修改模板不会影响已创建的索引。</li><li>你可以设定多个索引模板，这些设置会被 merge 在一起。</li><li>你可以指定 order 的数值，控制 merge 的过程。</li></ul><p>当新建一个索引时</p><ul><li>应用 ES 默认的 Mapping 和 Setting</li><li>应用 order 数值低的 index template 中的设定</li><li>应用 order 数值高的 index template 中的设定，之前的设定会被覆盖</li><li>应用创建索引是，用户所指定的 Mapping 和 Setting，并覆盖之前模板中的设定。</li></ul><p>示例：创建默认索引模板</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PUT _template/template_default</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"index_patterns"</span>: [<span class="string">"*"</span>],</span><br><span class="line">  <span class="string">"order"</span>: 0,</span><br><span class="line">  <span class="string">"version"</span>: 1,</span><br><span class="line">  <span class="string">"settings"</span>: &#123;</span><br><span class="line">    <span class="string">"number_of_shards"</span>: 1,</span><br><span class="line">    <span class="string">"number_of_replicas"</span>: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT /_template/template_test</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"index_patterns"</span>: [<span class="string">"test*"</span>],</span><br><span class="line">  <span class="string">"order"</span>: 1,</span><br><span class="line">  <span class="string">"settings"</span>: &#123;</span><br><span class="line">    <span class="string">"number_of_shards"</span>: 1,</span><br><span class="line">    <span class="string">"number_of_replicas"</span>: 2</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"mappings"</span>: &#123;</span><br><span class="line">    <span class="string">"date_detection"</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="string">"numeric_detection"</span>: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看索引模板</span></span><br><span class="line">GET /_template/template_default</span><br><span class="line">GET /_template/temp*</span><br><span class="line"></span><br><span class="line"><span class="comment">#写入新的数据，index以test开头</span></span><br><span class="line">PUT testtemplate/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"someNumber"</span>: <span class="string">"1"</span>,</span><br><span class="line">  <span class="string">"someDate"</span>: <span class="string">"2019/01/01"</span></span><br><span class="line">&#125;</span><br><span class="line">GET testtemplate/_mapping</span><br><span class="line">GET testtemplate/_settings</span><br><span class="line"></span><br><span class="line">PUT testmy</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"settings"</span>:&#123;</span><br><span class="line"><span class="string">"number_of_replicas"</span>:5</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT testmy/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"key"</span>: <span class="string">"value"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET testmy/_settings</span><br><span class="line">DELETE testmy</span><br><span class="line">DELETE /_template/template_default</span><br><span class="line">DELETE /_template/template_test</span><br></pre></td></tr></table></figure><h4 id="dynamic-template"><a class="markdownIt-Anchor" href="#dynamic-template"></a> dynamic template</h4><ul><li>根据 ES 识别的数据类型，结合字段名称，来动态设定字段类型<ul><li>所有的字符串类型都设定成 Keyword，或者关闭 keyword 字段。</li><li>is 开头的字段都设置成 boolean</li><li>long_ 开头的都设置成 long 类型</li></ul></li><li>dynamic template 是定义在某个索引的 Mapping 中</li><li>template 有一个名称</li><li>匹配规则是一个数组</li><li>为匹配到字段设置 Mapping</li></ul><p>示例：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Dynaminc Mapping 根据类型和字段名</span></span><br><span class="line">DELETE my_index</span><br><span class="line"></span><br><span class="line">PUT my_index/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"firstName"</span>: <span class="string">"Ruan"</span>,</span><br><span class="line">  <span class="string">"isVIP"</span>: <span class="string">"true"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET my_index/_mapping</span><br><span class="line"></span><br><span class="line">DELETE my_index</span><br><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"mappings"</span>: &#123;</span><br><span class="line">    <span class="string">"dynamic_templates"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="string">"strings_as_boolean"</span>: &#123;</span><br><span class="line">          <span class="string">"match_mapping_type"</span>: <span class="string">"string"</span>,</span><br><span class="line">          <span class="string">"match"</span>: <span class="string">"is*"</span>,</span><br><span class="line">          <span class="string">"mapping"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"boolean"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="string">"strings_as_keywords"</span>: &#123;</span><br><span class="line">          <span class="string">"match_mapping_type"</span>: <span class="string">"string"</span>,</span><br><span class="line">          <span class="string">"mapping"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"keyword"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">GET my_index/_mapping</span><br><span class="line"></span><br><span class="line">DELETE my_index</span><br><span class="line"><span class="comment">#结合路径</span></span><br><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"mappings"</span>: &#123;</span><br><span class="line">    <span class="string">"dynamic_templates"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="string">"full_name"</span>: &#123;</span><br><span class="line">          <span class="string">"path_match"</span>: <span class="string">"name.*"</span>,</span><br><span class="line">          <span class="string">"path_unmatch"</span>: <span class="string">"*.middle"</span>,</span><br><span class="line">          <span class="string">"mapping"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">            <span class="string">"copy_to"</span>: <span class="string">"full_name"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">GET my_index/_mapping</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">PUT my_index/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"name"</span>: &#123;</span><br><span class="line">    <span class="string">"first"</span>: <span class="string">"John"</span>,</span><br><span class="line">    <span class="string">"middle"</span>: <span class="string">"Winston"</span>,</span><br><span class="line">    <span class="string">"last"</span>: <span class="string">"Lennon"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET my_index/_search?q=full_name:John</span><br><span class="line">DELETE my_index</span><br></pre></td></tr></table></figure><h3 id="33-类型type"><a class="markdownIt-Anchor" href="#33-类型type"></a> 3.3. <s>类型（Type）</s></h3><p><s>type 是一个逻辑意义上的分类或者叫分区，允许在同一索引中建立多个 type。本质是相当于一个过滤条件，高版本将会废弃 type 概念。</s></p><blockquote><p><s><strong>6.0.0 版本及之后，废弃 type</strong></s></p></blockquote><h3 id="34-文档document"><a class="markdownIt-Anchor" href="#34-文档document"></a> 3.4. 文档（Document）</h3><p>Elasticsearch 是面向文档的，<strong>文档是所有可搜索数据的最小单位</strong>。</p><p>Elasticsearch 使用 <a href="http://en.wikipedia.org/wiki/Json" target="_blank" rel="noopener"><em>JSON</em></a> 作为文档的序列化格式。</p><p>在索引/类型中，可以根据需要存储任意数量的文档。</p><p>每个文档都有一个 <strong>Unique ID</strong></p><ul><li>用户可以自己指定</li><li>或通过 Elasticsearch 自动生成</li></ul><h4 id="文档的元数据"><a class="markdownIt-Anchor" href="#文档的元数据"></a> 文档的元数据</h4><p>一个文档不仅仅包含它的数据 ，也包含<strong>元数据</strong> —— 有关文档的信息。</p><ul><li><code>_index</code>：文档在哪存放</li><li><code>_type</code>：文档表示的对象类别</li><li><code>_id</code>：文档唯一标识</li><li><code>_source</code>：文档的原始 Json 数据</li><li><code>_all</code>：整合所有字段内容到该字段，已被废除</li><li><code>_version</code>：文档的版本信息</li><li><code>_score</code>：相关性打分</li></ul><p>示例：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"_index"</span>: <span class="string">"megacorp"</span>,</span><br><span class="line">  <span class="attr">"_type"</span>: <span class="string">"employee"</span>,</span><br><span class="line">  <span class="attr">"_id"</span>: <span class="string">"1"</span>,</span><br><span class="line">  <span class="attr">"_version"</span>: <span class="number">1</span>,</span><br><span class="line">  <span class="attr">"found"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"_source"</span>: &#123;</span><br><span class="line">    <span class="attr">"first_name"</span>: <span class="string">"John"</span>,</span><br><span class="line">    <span class="attr">"last_name"</span>: <span class="string">"Smith"</span>,</span><br><span class="line">    <span class="attr">"age"</span>: <span class="number">25</span>,</span><br><span class="line">    <span class="attr">"about"</span>: <span class="string">"I love to go rock climbing"</span>,</span><br><span class="line">    <span class="attr">"interests"</span>: [<span class="string">"sports"</span>, <span class="string">"music"</span>]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="35-节点node"><a class="markdownIt-Anchor" href="#35-节点node"></a> 3.5. 节点（Node）</h3><h4 id="节点简介"><a class="markdownIt-Anchor" href="#节点简介"></a> 节点简介</h4><p>一个运行中的 Elasticsearch 实例称为一个<strong>节点</strong>。</p><p>Elasticsearch 实例本质上是一个 Java 进程。一台机器上可以运行多个 Elasticsearch 进程，但是生产环境建议一台机器上只运行一个 Elasticsearch 进程</p><p>每个节点都有名字，通过配置文件配置，或启动时通过 <code>-E node.name=node1</code> 指定。</p><p>每个节点在启动后，会分配一个 UID，保存在 <code>data</code> 目录下。</p><h4 id="节点类型"><a class="markdownIt-Anchor" href="#节点类型"></a> 节点类型</h4><ul><li><strong>主节点（master node）</strong>：每个节点都保存了集群的状态，只有 master 节点才能修改集群的状态信息（保证数据一致性）。<strong>集群状态</strong>，维护了以下信息：<ul><li>所有的节点信息</li><li>所有的索引和其相关的 mapping 和 setting 信息</li><li>分片的路由信息</li></ul></li><li><strong>候选节点（master eligible node）</strong>：master eligible 节点可以参加选主流程。第一个启动的节点，会将自己选举为 mater 节点。<ul><li>每个节点启动后，默认为 master eligible 节点，可以通过配置 <code>node.master: false</code> 禁止</li></ul></li><li><strong>数据节点（data node）</strong>：负责保存分片数据。</li><li><strong>协调节点（coordinating node）</strong>：负责接收客户端的请求，将请求分发到合适的接地那，最终把结果汇集到一起。每个 Elasticsearch 节点默认都是协调节点（coordinating node）。</li><li><strong>冷/热节点（warm/hot node）</strong>：针对不同硬件配置的数据节点（data node），用来实现 Hot &amp; Warm 架构，降低集群部署的成本。</li><li><strong>机器学习节点（machine learning node）</strong>：负责执行机器学习的 Job，用来做异常检测。</li></ul><h4 id="节点配置"><a class="markdownIt-Anchor" href="#节点配置"></a> 节点配置</h4><table><thead><tr><th>配置参数</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>node.master</td><td>true</td><td>是否为主节点</td></tr><tr><td>node.data</td><td>true</td><td>是否为数据节点</td></tr><tr><td>node.ingest</td><td>true</td><td></td></tr><tr><td><a href="http://node.ml" target="_blank" rel="noopener">node.ml</a></td><td>true</td><td>是否为机器学习节点（需要开启 x-pack）</td></tr></tbody></table><blockquote><p><strong>建议</strong></p><p>开发环境中一个节点可以承担多种角色。但是，在生产环境中，节点应该设置为单一角色。</p></blockquote><h3 id="36-集群cluster"><a class="markdownIt-Anchor" href="#36-集群cluster"></a> 3.6. 集群（Cluster）</h3><h4 id="集群简介"><a class="markdownIt-Anchor" href="#集群简介"></a> 集群简介</h4><p>拥有相同 <code>cluster.name</code> 配置的 Elasticsearch 节点组成一个<strong>集群</strong>。 <code>cluster.name</code> 默认名为 <code>elasticsearch</code>，可以通过配置文件修改，或启动时通过 <code>-E cluster.name=xxx</code> 指定。</p><p>当有节点加入集群中或者从集群中移除节点时，集群将会重新平均分布所有的数据。</p><p>当一个节点被选举成为主节点时，它将负责管理集群范围内的所有变更，例如增加、删除索引，或者增加、删除节点等。 而主节点并不需要涉及到文档级别的变更和搜索等操作，所以当集群只拥有一个主节点的情况下，即使流量增加，它也不会成为瓶颈。 任何节点都可以成为主节点。</p><p>作为用户，我们可以将请求发送到集群中的任何节点 ，包括主节点。 每个节点都知道任意文档所处的位置，并且能够将我们的请求直接转发到存储我们所需文档的节点。 无论我们将请求发送到哪个节点，它都能负责从各个包含我们所需文档的节点收集回数据，并将最终结果返回給客户端。 Elasticsearch 对这一切的管理都是透明的。</p><h4 id="集群健康"><a class="markdownIt-Anchor" href="#集群健康"></a> 集群健康</h4><p>Elasticsearch 的集群监控信息中包含了许多的统计数据，其中最为重要的一项就是 <em>集群健康</em> ， 它在 <code>status</code> 字段中展示为 <code>green</code> 、 <code>yellow</code> 或者 <code>red</code> 。</p><p>在一个不包含任何索引的空集群中，它将会有一个类似于如下所示的返回内容：</p><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"cluster_name"</span> : <span class="string">"elasticsearch"</span>,</span><br><span class="line">  <span class="string">"status"</span> : <span class="string">"green"</span>,</span><br><span class="line">  <span class="string">"timed_out"</span> : <span class="literal">false</span>,</span><br><span class="line">  <span class="string">"number_of_nodes"</span> : <span class="number">1</span>,</span><br><span class="line">  <span class="string">"number_of_data_nodes"</span> : <span class="number">1</span>,</span><br><span class="line">  <span class="string">"active_primary_shards"</span> : <span class="number">5</span>,</span><br><span class="line">  <span class="string">"active_shards"</span> : <span class="number">5</span>,</span><br><span class="line">  <span class="string">"relocating_shards"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="string">"initializing_shards"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="string">"unassigned_shards"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="string">"delayed_unassigned_shards"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="string">"number_of_pending_tasks"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="string">"number_of_in_flight_fetch"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="string">"task_max_waiting_in_queue_millis"</span> : <span class="number">0</span>,</span><br><span class="line">  <span class="string">"active_shards_percent_as_number"</span> : <span class="number">100.0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>status</code> 字段指示着当前集群在总体上是否工作正常。它的三种颜色含义如下：</p><ul><li><strong><code>green</code></strong>：所有的主分片和副本分片都正常运行。</li><li><strong><code>yellow</code></strong>：所有的主分片都正常运行，但不是所有的副本分片都正常运行。</li><li><strong><code>red</code></strong>：有主分片没能正常运行。</li></ul><h3 id="37-分片shards"><a class="markdownIt-Anchor" href="#37-分片shards"></a> 3.7. 分片（Shards）</h3><h4 id="分片简介"><a class="markdownIt-Anchor" href="#分片简介"></a> 分片简介</h4><p>索引实际上是指向一个或者多个<strong>物理分片</strong>的<strong>逻辑命名空间</strong> 。</p><p>一个分片是一个底层的工作单元 ，它仅保存了全部数据中的一部分。一个分片可以视为一个 Lucene 的实例，并且它本身就是一个完整的搜索引擎。 我们的文档被存储和索引到分片内，但是应用程序是直接与索引而不是与分片进行交互。</p><p>Elasticsearch 是利用分片将数据分发到集群内各处的。分片是数据的容器，文档保存在分片内，分片又被分配到集群内的各个节点里。 当你的集群规模扩大或者缩小时， Elasticsearch 会自动的在各节点中迁移分片，使得数据仍然均匀分布在集群里。</p><h4 id="主分片和副分片"><a class="markdownIt-Anchor" href="#主分片和副分片"></a> 主分片和副分片</h4><p>分片分为主分片（Primary Shard）和副分片（Replica Shard）。</p><p>主分片：用于解决数据水平扩展的问题。通过主分片，可以将数据分布到集群内不同节点上。</p><ul><li>索引内任意一个文档都归属于一个主分片。</li><li>主分片数在索引创建时指定，后序不允许修改，除非 Reindex</li></ul><p>副分片（Replica Shard）：用于解决数据高可用的问题。副分片是主分片的拷贝。副本分片作为硬件故障时保护数据不丢失的冗余备份，并为搜索和返回文档等读操作提供服务。</p><ul><li>副分片数可以动态调整</li><li>增加副本数，还可以在一定程度上提高服务的可用性（读取的吞吐）</li></ul><p>对于生产环境中分片的设定，需要提前做好容量规划</p><p>分片数过小</p><ul><li>无法水平扩展</li><li>单个分片的数量太大，导致数据重新分配耗时</li></ul><p>分片数过大</p><ul><li>影响搜索结果的相关性打分，影响统计结果的准确性</li><li>单节点上过多的分片，会导致资源浪费，同时也会影响性能</li></ul><h3 id="38-副本replicas"><a class="markdownIt-Anchor" href="#38-副本replicas"></a> 3.8. 副本（Replicas）</h3><p>副本主要是针对主分片（Shards）的复制，Elasticsearch 中主分片可以拥有 0 个或多个的副本。</p><p>副本分片的主要目的就是为了故障转移。</p><p>分片副本很重要，主要有两个原因：</p><ul><li>它在分片或节点发生故障时提供高可用性。因此，副本分片永远不会在与其复制的主分片相同的节点；</li><li>副本分片也可以接受搜索的请求，可以并行搜索，从而提高系统的吞吐量。</li></ul><blockquote><p>每个 Elasticsearch 分片都是 Lucene 索引。单个 Lucene 索引中可以包含最大数量的文档。截止 LUCENE-5843，限制是 2,147,483,519（= <code>Integer.MAX_VALUE</code> - 128）文档。您可以使用_cat/shardsAPI 监控分片大小。</p></blockquote><h2 id="4-参考资料"><a class="markdownIt-Anchor" href="#4-参考资料"></a> 4. 参考资料</h2><ul><li><a href="https://www.elastic.co/" target="_blank" rel="noopener">Elasticsearch 官网</a></li><li><a href="https://www.knowledgedict.com/tutorial/elasticsearch-intro.html" target="_blank" rel="noopener">Elasticsearch 简介</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;elasticsearch-简介&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#elasticsearch-简介&quot;&gt;&lt;/a&gt; Elasticsearch 简介&lt;/h1&gt;
&lt;p&gt;Elasticsearch 是一个基于 Lucene 的搜索
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/Elasticsearch/"/>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch 索引</title>
    <link href="https://dunwu.github.io/blog/2022/02/22/elasticsearch-%E7%B4%A2%E5%BC%95/"/>
    <id>https://dunwu.github.io/blog/2022/02/22/elasticsearch-%E7%B4%A2%E5%BC%95/</id>
    <published>2022-02-22T13:01:01.000Z</published>
    <updated>2022-04-14T08:45:53.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="elasticsearch-索引"><a class="markdownIt-Anchor" href="#elasticsearch-索引"></a> Elasticsearch 索引</h1><h2 id="1-索引管理操作"><a class="markdownIt-Anchor" href="#1-索引管理操作"></a> 1. 索引管理操作</h2><p>Elasticsearch 索引管理主要包括如何进行索引的创建、索引的删除、副本的更新、索引读写权限、索引别名的配置等等内容。</p><h3 id="11-索引删除"><a class="markdownIt-Anchor" href="#11-索引删除"></a> 1.1. 索引删除</h3><p>ES 索引删除操作向 ES 集群的 http 接口发送指定索引的 delete http 请求即可，可以通过 curl 命令，具体如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -X DELETE http://&#123;es_host&#125;:&#123;es_http_port&#125;/&#123;index&#125;</span><br></pre></td></tr></table></figure><p>如果删除成功，它会返回如下信息，具体示例如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -X DELETE http://10.10.10.66:9200/my_index?pretty</span><br></pre></td></tr></table></figure><p>为了返回的信息便于读取，增加了 pretty 参数：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"acknowledged"</span> : <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="12-索引别名"><a class="markdownIt-Anchor" href="#12-索引别名"></a> 1.2. 索引别名</h3><p>ES 的索引别名就是给一个索引或者多个索引起的另一个名字，典型的应用场景是针对索引使用的平滑切换。</p><p>首先，创建索引 my_index，然后将别名 my_alias 指向它，示例如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PUT /my_index</span><br><span class="line">PUT /my_index/_alias/my_alias</span><br></pre></td></tr></table></figure><p>也可以通过如下形式：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"actions"</span>: [</span><br><span class="line">    &#123; <span class="string">"add"</span>: &#123; <span class="string">"index"</span>: <span class="string">"my_index"</span>, <span class="string">"alias"</span>: <span class="string">"my_alias"</span> &#125;&#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>也可以在一次请求中增加别名和移除别名混合使用：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"actions"</span>: [</span><br><span class="line">    &#123; <span class="string">"remove"</span>: &#123; <span class="string">"index"</span>: <span class="string">"my_index"</span>, <span class="string">"alias"</span>: <span class="string">"my_alias"</span> &#125;&#125;</span><br><span class="line">    &#123; <span class="string">"add"</span>: &#123; <span class="string">"index"</span>: <span class="string">"my_index_v2"</span>, <span class="string">"alias"</span>: <span class="string">"my_alias"</span> &#125;&#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>需要注意的是，如果别名与索引是一对一的，使用别名索引文档或者查询文档是可以的，但是如果别名和索引是一对多的，使用别名会发生错误，因为 ES 不知道把文档写入哪个索引中去或者从哪个索引中读取文档。</p></blockquote><p>ES 索引别名有个典型的应用场景是平滑切换，更多细节可以查看 <a href="https://www.knowledgedict.com/tutorial/elasticsearch-index-smooth-shift.html" target="_blank" rel="noopener">Elasticsearch（ES）索引零停机（无需重启）无缝平滑切换的方法</a>。</p><h2 id="2-settings-详解"><a class="markdownIt-Anchor" href="#2-settings-详解"></a> 2. Settings 详解</h2><p>Elasticsearch 索引的配置项主要分为<strong>静态配置属性</strong>和<strong>动态配置属性</strong>，静态配置属性是索引创建后不能修改，而动态配置属性则可以随时修改。</p><p>ES 索引设置的 api 为 <strong><em><code>_settings</code></em></strong>，完整的示例如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PUT /my_index</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"settings"</span>: &#123;</span><br><span class="line">    <span class="string">"index"</span>: &#123;</span><br><span class="line">      <span class="string">"number_of_shards"</span>: <span class="string">"1"</span>,</span><br><span class="line">      <span class="string">"number_of_replicas"</span>: <span class="string">"1"</span>,</span><br><span class="line">      <span class="string">"refresh_interval"</span>: <span class="string">"60s"</span>,</span><br><span class="line">      <span class="string">"analysis"</span>: &#123;</span><br><span class="line">        <span class="string">"filter"</span>: &#123;</span><br><span class="line">          <span class="string">"tsconvert"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"stconvert"</span>,</span><br><span class="line">            <span class="string">"convert_type"</span>: <span class="string">"t2s"</span>,</span><br><span class="line">            <span class="string">"delimiter"</span>: <span class="string">","</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="string">"synonym"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"synonym"</span>,</span><br><span class="line">            <span class="string">"synonyms_path"</span>: <span class="string">"analysis/synonyms.txt"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"analyzer"</span>: &#123;</span><br><span class="line">          <span class="string">"ik_max_word_synonym"</span>: &#123;</span><br><span class="line">            <span class="string">"filter"</span>: [</span><br><span class="line">              <span class="string">"synonym"</span>,</span><br><span class="line">              <span class="string">"tsconvert"</span>,</span><br><span class="line">              <span class="string">"standard"</span>,</span><br><span class="line">              <span class="string">"lowercase"</span>,</span><br><span class="line">              <span class="string">"stop"</span></span><br><span class="line">            ],</span><br><span class="line">            <span class="string">"tokenizer"</span>: <span class="string">"ik_max_word"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="string">"ik_smart_synonym"</span>: &#123;</span><br><span class="line">            <span class="string">"filter"</span>: [</span><br><span class="line">              <span class="string">"synonym"</span>,</span><br><span class="line">              <span class="string">"standard"</span>,</span><br><span class="line">              <span class="string">"lowercase"</span>,</span><br><span class="line">              <span class="string">"stop"</span></span><br><span class="line">            ],</span><br><span class="line">            <span class="string">"tokenizer"</span>: <span class="string">"ik_smart"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line"><span class="string">"mapping"</span>: &#123;</span><br><span class="line"><span class="string">"coerce"</span>: <span class="string">"false"</span>,</span><br><span class="line"><span class="string">"ignore_malformed"</span>: <span class="string">"false"</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"indexing"</span>: &#123;</span><br><span class="line"><span class="string">"slowlog"</span>: &#123;</span><br><span class="line"><span class="string">"threshold"</span>: &#123;</span><br><span class="line"><span class="string">"index"</span>: &#123;</span><br><span class="line"><span class="string">"warn"</span>: <span class="string">"2s"</span>,</span><br><span class="line"><span class="string">"info"</span>: <span class="string">"1s"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"provided_name"</span>: <span class="string">"hospital_202101070533"</span>,</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"default_field"</span>: <span class="string">"timestamp"</span>,</span><br><span class="line"><span class="string">"parse"</span>: &#123;</span><br><span class="line"><span class="string">"allow_unmapped_fields"</span>: <span class="string">"false"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"requests"</span>: &#123;</span><br><span class="line"><span class="string">"cache"</span>: &#123;</span><br><span class="line"><span class="string">"enable"</span>: <span class="string">"true"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"search"</span>: &#123;</span><br><span class="line"><span class="string">"slowlog"</span>: &#123;</span><br><span class="line"><span class="string">"threshold"</span>: &#123;</span><br><span class="line"><span class="string">"fetch"</span>: &#123;</span><br><span class="line"><span class="string">"warn"</span>: <span class="string">"1s"</span>,</span><br><span class="line"><span class="string">"info"</span>: <span class="string">"200ms"</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"warn"</span>: <span class="string">"1s"</span>,</span><br><span class="line"><span class="string">"info"</span>: <span class="string">"500ms"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="21-固定属性"><a class="markdownIt-Anchor" href="#21-固定属性"></a> 2.1. 固定属性</h3><ul><li><strong><em><code>index.creation_date</code></em></strong>：顾名思义索引的创建时间戳。</li><li><strong><em><code>index.uuid</code></em></strong>：索引的 uuid 信息。</li><li><strong><em><code>index.version.created</code></em></strong>：索引的版本号。</li></ul><h3 id="22-索引静态配置"><a class="markdownIt-Anchor" href="#22-索引静态配置"></a> 2.2. 索引静态配置</h3><ul><li><strong><em><code>index.number_of_shards</code></em></strong>：索引的主分片数，默认值是 <strong><em><code>5</code></em></strong>。这个配置在索引创建后不能修改；在 es 层面，可以通过 <strong><em><code>es.index.max_number_of_shards</code></em></strong> 属性设置索引最大的分片数，默认为 <strong><em><code>1024</code></em></strong>。</li><li><strong><em><code>index.codec</code></em></strong>：数据存储的压缩算法，默认值为 <strong><em><code>LZ4</code></em></strong>，可选择值还有 <strong><em><code>best_compression</code></em></strong>，它比 LZ4 可以获得更好的压缩比（即占据较小的磁盘空间，但存储性能比 LZ4 低）。</li><li><strong><em><code>index.routing_partition_size</code></em></strong>：路由分区数，如果设置了该参数，其路由算法为：<code>( hash(_routing) + hash(_id) % index.routing_parttion_size ) % number_of_shards</code>。如果该值不设置，则路由算法为 <code>hash(_routing) % number_of_shardings</code>，<code>_routing</code> 默认值为 <code>_id</code>。</li></ul><p>静态配置里，有重要的部分是配置分析器（config analyzers）。</p><ul><li><p><strong><code>index.analysis</code></strong></p><p>：分析器最外层的配置项，内部主要分为 char_filter、tokenizer、filter 和 analyzer。</p><ul><li><strong><em><code>char_filter</code></em></strong>：定义新的字符过滤器件。</li><li><strong><em><code>tokenizer</code></em></strong>：定义新的分词器。</li><li><strong><em><code>filter</code></em></strong>：定义新的 token filter，如同义词 filter。</li><li><strong><em><code>analyzer</code></em></strong>：配置新的分析器，一般是 char_filter、tokenizer 和一些 token filter 的组合。</li></ul></li></ul><h3 id="23-索引动态配置"><a class="markdownIt-Anchor" href="#23-索引动态配置"></a> 2.3. 索引动态配置</h3><ul><li><strong><em><code>index.number_of_replicas</code></em></strong>：索引主分片的副本数，默认值是 <strong><em><code>1</code></em></strong>，该值必须大于等于 0，这个配置可以随时修改。</li><li><strong><em><code>index.refresh_interval</code></em></strong>：执行新索引数据的刷新操作频率，该操作使对索引的最新更改对搜索可见，默认为 <strong><em><code>1s</code></em></strong>。也可以设置为 <strong><em><code>-1</code></em></strong> 以禁用刷新。更详细信息参考 <a href="https://www.knowledgedict.com/tutorial/elasticsearch-refresh_interval-settings.html" target="_blank" rel="noopener">Elasticsearch 动态修改 refresh_interval 刷新间隔设置</a>。</li></ul><h2 id="3-mapping-详解"><a class="markdownIt-Anchor" href="#3-mapping-详解"></a> 3. Mapping 详解</h2><p>在 Elasticsearch 中，<strong><code>Mapping</code></strong>（映射），用来定义一个文档以及其所包含的字段如何被存储和索引，可以在映射中事先定义字段的数据类型、字段的权重、分词器等属性，就如同在关系型数据库中创建数据表时会设置字段的类型。</p><p>Mapping 会把 json 文档映射成 Lucene 所需要的扁平格式</p><p>一个 Mapping 属于一个索引的 Type</p><ul><li>每个文档都属于一个 Type</li><li>一个 Type 有一个 Mapping 定义</li><li>7.0 开始，不需要在 Mapping 定义中指定 type 信息</li></ul><h3 id="31-映射分类"><a class="markdownIt-Anchor" href="#31-映射分类"></a> 3.1. 映射分类</h3><p>在 Elasticsearch 中，映射可分为静态映射和动态映射。在关系型数据库中写入数据之前首先要建表，在建表语句中声明字段的属性，在 Elasticsearch 中，则不必如此，Elasticsearch 最重要的功能之一就是让你尽可能快地开始探索数据，文档写入 Elasticsearch 中，它会根据字段的类型自动识别，这种机制称为<strong>动态映射</strong>，而<strong>静态映射</strong>则是写入数据之前对字段的属性进行手工设置。</p><h4 id="静态映射"><a class="markdownIt-Anchor" href="#静态映射"></a> 静态映射</h4><p><strong>静态映射</strong>是在创建索引时手工指定索引映射。静态映射和 SQL 中在建表语句中指定字段属性类似。相比动态映射，通过静态映射可以添加更详细、更精准的配置信息。</p><p>如何定义一个 Mapping</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PUT /books</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"mappings"</span>: &#123;</span><br><span class="line">        <span class="string">"type_one"</span>: &#123; ... any mappings ... &#125;,</span><br><span class="line">        <span class="string">"type_two"</span>: &#123; ... any mappings ... &#125;,</span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="动态映射"><a class="markdownIt-Anchor" href="#动态映射"></a> 动态映射</h4><p><strong>动态映射</strong>是一种偷懒的方式，可直接创建索引并写入文档，文档中字段的类型是 Elasticsearch <strong>自动识别</strong>的，不需要在创建索引的时候设置字段的类型。在实际项目中，如果遇到的业务在导入数据之前不确定有哪些字段，也不清楚字段的类型是什么，使用动态映射非常合适。当 Elasticsearch 在文档中碰到一个以前没见过的字段时，它会利用动态映射来决定该字段的类型，并自动把该字段添加到映射中，根据字段的取值自动推测字段类型的规则见下表：</p><table><thead><tr><th style="text-align:left">JSON 格式的数据</th><th style="text-align:left">自动推测的字段类型</th></tr></thead><tbody><tr><td style="text-align:left">null</td><td style="text-align:left">没有字段被添加</td></tr><tr><td style="text-align:left">true or false</td><td style="text-align:left">boolean 类型</td></tr><tr><td style="text-align:left">浮点类型数字</td><td style="text-align:left">float 类型</td></tr><tr><td style="text-align:left">数字</td><td style="text-align:left">long 类型</td></tr><tr><td style="text-align:left">JSON 对象</td><td style="text-align:left">object 类型</td></tr><tr><td style="text-align:left">数组</td><td style="text-align:left">由数组中第一个非空值决定</td></tr><tr><td style="text-align:left">string</td><td style="text-align:left">有可能是 date 类型（若开启日期检测）、double 或 long 类型、text 类型、keyword 类型</td></tr></tbody></table><p>下面举一个例子认识动态 mapping，在 Elasticsearch 中创建一个新的索引并查看它的 mapping，命令如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PUT books</span><br><span class="line">GET books/_mapping</span><br></pre></td></tr></table></figure><p>此时 books 索引的 mapping 是空的，返回结果如下：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"books"</span>: &#123;</span><br><span class="line">    <span class="attr">"mappings"</span>: &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再往 books 索引中写入一条文档，命令如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PUT books/it/1</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"id"</span>: 1,</span><br><span class="line"><span class="string">"publish_date"</span>: <span class="string">"2019-11-10"</span>,</span><br><span class="line"><span class="string">"name"</span>: <span class="string">"master Elasticsearch"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>文档写入完成之后，再次查看 mapping，返回结果如下：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"books"</span>: &#123;</span><br><span class="line">    <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">      <span class="attr">"properties"</span>: &#123;</span><br><span class="line">        <span class="attr">"id"</span>: &#123;</span><br><span class="line">          <span class="attr">"type"</span>: <span class="string">"long"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"name"</span>: &#123;</span><br><span class="line">          <span class="attr">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">          <span class="attr">"fields"</span>: &#123;</span><br><span class="line">            <span class="attr">"keyword"</span>: &#123;</span><br><span class="line">              <span class="attr">"type"</span>: <span class="string">"keyword"</span>,</span><br><span class="line">              <span class="attr">"ignore_above"</span>: <span class="number">256</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"publish_date"</span>: &#123;</span><br><span class="line">          <span class="attr">"type"</span>: <span class="string">"date"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用动态 mapping 要结合实际业务需求来综合考虑，如果将 Elasticsearch 当作主要的数据存储使用，并且希望出现未知字段时抛出异常来提醒你注意这一问题，那么开启动态 mapping 并不适用。在 mapping 中可以通过 <code>dynamic</code> 设置来控制是否自动新增字段，接受以下参数：</p><ul><li><strong><code>true</code></strong>：默认值为 true，自动添加字段。</li><li><strong><code>false</code></strong>：忽略新的字段。</li><li><strong><code>strict</code></strong>：严格模式，发现新的字段抛出异常。</li></ul><h3 id="32-基础类型"><a class="markdownIt-Anchor" href="#32-基础类型"></a> 3.2. 基础类型</h3><table><thead><tr><th style="text-align:left">类型</th><th style="text-align:left">关键字</th></tr></thead><tbody><tr><td style="text-align:left">字符串类型</td><td style="text-align:left">string、text、keyword</td></tr><tr><td style="text-align:left">数字类型</td><td style="text-align:left">long、integer、short、byte、double、float、half_float、scaled_float</td></tr><tr><td style="text-align:left">日期类型</td><td style="text-align:left">date</td></tr><tr><td style="text-align:left">布尔类型</td><td style="text-align:left">boolean</td></tr><tr><td style="text-align:left">二进制类型</td><td style="text-align:left">binary</td></tr><tr><td style="text-align:left">范围类型</td><td style="text-align:left">range</td></tr></tbody></table><h3 id="33-复杂类型"><a class="markdownIt-Anchor" href="#33-复杂类型"></a> 3.3. 复杂类型</h3><table><thead><tr><th style="text-align:left">类型</th><th style="text-align:left">关键字</th></tr></thead><tbody><tr><td style="text-align:left">数组类型</td><td style="text-align:left">array</td></tr><tr><td style="text-align:left">对象类型</td><td style="text-align:left">object</td></tr><tr><td style="text-align:left">嵌套类型</td><td style="text-align:left">nested</td></tr></tbody></table><h3 id="34-特殊类型"><a class="markdownIt-Anchor" href="#34-特殊类型"></a> 3.4. 特殊类型</h3><table><thead><tr><th style="text-align:left">类型</th><th style="text-align:left">关键字</th></tr></thead><tbody><tr><td style="text-align:left">地理类型</td><td style="text-align:left">geo_point</td></tr><tr><td style="text-align:left">地理图形类型</td><td style="text-align:left">geo_shape</td></tr><tr><td style="text-align:left">IP 类型</td><td style="text-align:left">ip</td></tr><tr><td style="text-align:left">范围类型</td><td style="text-align:left">completion</td></tr><tr><td style="text-align:left">令牌计数类型</td><td style="text-align:left">token_count</td></tr><tr><td style="text-align:left">附件类型</td><td style="text-align:left">attachment</td></tr><tr><td style="text-align:left">抽取类型</td><td style="text-align:left">percolator</td></tr></tbody></table><h3 id="35-mapping-属性"><a class="markdownIt-Anchor" href="#35-mapping-属性"></a> 3.5. Mapping 属性</h3><p>Elasticsearch 的 mapping 中的字段属性非常多，具体如下表格：</p><p>| 属性名 | 描述 |<br />| :- | :- | |<br />| <strong><em><code>type</code></em></strong> | 字段类型，常用的有 text、integer 等等。 |<br />| <strong><em><code>index</code></em></strong> | 当前字段是否被作为索引。可选值为 <strong><em><code>true</code></em></strong>，默认为 true。 |<br />| <strong><em><code>store</code></em></strong> | 是否存储指定字段，可选值为 <strong><em><code>true</code></em></strong> | <strong><em><code>false</code></em></strong>，设置 true 意味着需要开辟单独的存储空间为这个字段做存储，而且这个存储是独立于 <strong><em><code>_source</code></em></strong> 的存储的。 |<br />| <strong><em><code>norms</code></em></strong> | 是否使用归一化因子，可选值为 <strong><em><code>true</code></em></strong> | <strong><em><code>false</code></em></strong>，不需要对某字段进行打分排序时，可禁用它，节省空间；<em>type</em> 为 <em>text</em> 时，默认为 <em>true</em>；而 <em>type</em> 为 <em>keyword</em> 时，默认为 <em>false</em>。 |<br />| <strong><em><code>index_options</code></em></strong> | 索引选项控制添加到倒排索引（Inverted Index）的信息，这些信息用于搜索（Search）和高亮显示：<strong><em><code>docs</code></em></strong>：只索引文档编号(Doc Number)；<strong><em><code>freqs</code></em></strong>：索引文档编号和词频率（term frequency）；<strong><em><code>positions</code></em></strong>：索引文档编号，词频率和词位置（序号）；<strong><em><code>offsets</code></em></strong>：索引文档编号，词频率，词偏移量（开始和结束位置）和词位置（序号）。默认情况下，被分析的字符串（analyzed string）字段使用 <em>positions</em>，其他字段默认使用 <em>docs</em>。此外，需要注意的是 <em>index_option</em> 是 elasticsearch 特有的设置属性；临近搜索和短语查询时，<em>index_option</em> 必须设置为 <em>offsets</em>，同时高亮也可使用 postings highlighter。 |<br />| <strong><em><code>term_vector</code></em></strong> | 索引选项控制词向量相关信息：<strong><em><code>no</code></em></strong>：默认值，表示不存储词向量相关信息；<strong><em><code>yes</code></em></strong>：只存储词向量信息；<strong><em><code>with_positions</code></em></strong>：存储词项和词项位置；<strong><em><code>with_offsets</code></em></strong>：存储词项和字符偏移位置；<strong><em><code>with_positions_offsets</code></em></strong>：存储词项、词项位置、字符偏移位置。<em>term_vector</em> 是 lucene 层面的索引设置。 |<br />| <strong><em><code>similarity</code></em></strong> | 指定文档相似度算法（也可以叫评分模型）：<strong><em><code>BM25</code></em></strong>：ES 5 之后的默认设置。 |<br />| <strong><em><code>copy_to</code></em></strong> | 复制到自定义 _all 字段，值是数组形式，即表明可以指定多个自定义的字段。 |<br />| <strong><em><code>analyzer</code></em></strong> | 指定索引和搜索时的分析器，如果同时指定 <em>search_analyzer</em> 则搜索时会优先使用 <em>search_analyzer</em>。 |<br />| <strong><em><code>search_analyzer</code></em></strong> | 指定搜索时的分析器，搜索时的优先级最高。 |<br />| <strong><em><code>null_value</code></em></strong> | 用于需要对 Null 值实现搜索的场景，只有 Keyword 类型支持此配置。 |</p><h2 id="4-索引查询"><a class="markdownIt-Anchor" href="#4-索引查询"></a> 4. 索引查询</h2><h3 id="41-多个-index-多个-type-查询"><a class="markdownIt-Anchor" href="#41-多个-index-多个-type-查询"></a> 4.1. 多个 index、多个 type 查询</h3><p>Elasticsearch 的搜索 api 支持<strong>一个索引（index）的多个类型（type）查询</strong>以及**多个索引（index）**的查询。</p><p>例如，我们可以搜索 twitter 索引下面所有匹配条件的所有类型中文档，如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /twitter/_search?q=user:shay</span><br></pre></td></tr></table></figure><p>我们也可以搜索一个索引下面指定多个 type 下匹配条件的文档，如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /twitter/tweet,user/_search?q=user:banon</span><br></pre></td></tr></table></figure><p>我们也可以搜索多个索引下匹配条件的文档，如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /twitter,elasticsearch/_search?q=tag:wow</span><br></pre></td></tr></table></figure><p>此外我们也可以搜索所有索引下匹配条件的文档，用_all 表示所有索引，如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_all/_search?q=tag:wow</span><br></pre></td></tr></table></figure><p>甚至我们可以搜索所有索引及所有 type 下匹配条件的文档，如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_search?q=tag:wow</span><br></pre></td></tr></table></figure><h3 id="42-uri-搜索"><a class="markdownIt-Anchor" href="#42-uri-搜索"></a> 4.2. URI 搜索</h3><p>Elasticsearch 支持用 uri 搜索，可用 get 请求里面拼接相关的参数，并用 curl 相关的命令就可以进行测试。</p><p>如下有一个示例：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET twitter/_search?q=user:kimchy</span><br></pre></td></tr></table></figure><p>如下是上一个请求的相应实体：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"timed_out"</span>: <span class="literal">false</span>,</span><br><span class="line">  <span class="attr">"took"</span>: <span class="number">62</span>,</span><br><span class="line">  <span class="attr">"_shards"</span>: &#123;</span><br><span class="line">    <span class="attr">"total"</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="attr">"successful"</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="attr">"skipped"</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="attr">"failed"</span>: <span class="number">0</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"hits"</span>: &#123;</span><br><span class="line">    <span class="attr">"total"</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="attr">"max_score"</span>: <span class="number">1.3862944</span>,</span><br><span class="line">    <span class="attr">"hits"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"_index"</span>: <span class="string">"twitter"</span>,</span><br><span class="line">        <span class="attr">"_type"</span>: <span class="string">"_doc"</span>,</span><br><span class="line">        <span class="attr">"_id"</span>: <span class="string">"0"</span>,</span><br><span class="line">        <span class="attr">"_score"</span>: <span class="number">1.3862944</span>,</span><br><span class="line">        <span class="attr">"_source"</span>: &#123;</span><br><span class="line">          <span class="attr">"user"</span>: <span class="string">"kimchy"</span>,</span><br><span class="line">          <span class="attr">"date"</span>: <span class="string">"2009-11-15T14:12:12"</span>,</span><br><span class="line">          <span class="attr">"message"</span>: <span class="string">"trying out Elasticsearch"</span>,</span><br><span class="line">          <span class="attr">"likes"</span>: <span class="number">0</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>URI 中允许的参数：</p><table><thead><tr><th style="text-align:left">名称</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">q</td><td style="text-align:left">查询字符串，映射到 query_string 查询</td></tr><tr><td style="text-align:left">df</td><td style="text-align:left">在查询中未定义字段前缀时使用的默认字段</td></tr><tr><td style="text-align:left">analyzer</td><td style="text-align:left">查询字符串时指定的分词器</td></tr><tr><td style="text-align:left">analyze_wildcard</td><td style="text-align:left">是否允许通配符和前缀查询，默认设置为 false</td></tr><tr><td style="text-align:left">batched_reduce_size</td><td style="text-align:left">应在协调节点上一次减少的分片结果数。如果请求中潜在的分片数量很大，则应将此值用作保护机制，以减少每个搜索请求的内存开销</td></tr><tr><td style="text-align:left">default_operator</td><td style="text-align:left">默认使用的匹配运算符，可以是<em>AND</em>或者<em>OR</em>，默认是<em>OR</em></td></tr><tr><td style="text-align:left">lenient</td><td style="text-align:left">如果设置为 true，将会忽略由于格式化引起的问题（如向数据字段提供文本），默认为 false</td></tr><tr><td style="text-align:left">explain</td><td style="text-align:left">对于每个 hit，包含了具体如何计算得分的解释</td></tr><tr><td style="text-align:left">_source</td><td style="text-align:left">请求文档内容的参数，默认 true；设置 false 的话，不返回_source 字段，可以使用**_source_include<strong>和</strong>_source_exclude**参数分别指定返回字段和不返回的字段</td></tr><tr><td style="text-align:left">stored_fields</td><td style="text-align:left">指定每个匹配返回的文档中的存储字段，多个用逗号分隔。不指定任何值将导致没有字段返回</td></tr><tr><td style="text-align:left">sort</td><td style="text-align:left">排序方式，可以是<em>fieldName</em>、<em>fieldName:asc</em>或者<em>fieldName:desc</em>的形式。fieldName 可以是文档中的实际字段，也可以是诸如_score 字段，其表示基于分数的排序。此外可以指定多个 sort 参数（顺序很重要）</td></tr><tr><td style="text-align:left">track_scores</td><td style="text-align:left">当排序时，若设置 true，返回每个命中文档的分数</td></tr><tr><td style="text-align:left">track_total_hits</td><td style="text-align:left">是否返回匹配条件命中的总文档数，默认为 true</td></tr><tr><td style="text-align:left">timeout</td><td style="text-align:left">设置搜索的超时时间，默认无超时时间</td></tr><tr><td style="text-align:left">terminate_after</td><td style="text-align:left">在达到查询终止条件之前，指定每个分片收集的最大文档数。如果设置，则在响应中多了一个 terminated_early 的布尔字段，以指示查询执行是否实际上已终止。默认为 no terminate_after</td></tr><tr><td style="text-align:left">from</td><td style="text-align:left">从第几条（索引以 0 开始）结果开始返回，默认为 0</td></tr><tr><td style="text-align:left">size</td><td style="text-align:left">返回命中的文档数，默认为 10</td></tr><tr><td style="text-align:left">search_type</td><td style="text-align:left">搜索的方式，可以是<em>dfs_query_then_fetch</em>或<em>query_then_fetch</em>。默认为<em>query_then_fetch</em></td></tr><tr><td style="text-align:left">allow_partial_search_results</td><td style="text-align:left">是否可以返回部分结果。如设置为 false，表示如果请求产生部分结果，则设置为返回整体故障；默认为 true，表示允许请求在超时或部分失败的情况下获得部分结果</td></tr></tbody></table><h3 id="43-查询流程"><a class="markdownIt-Anchor" href="#43-查询流程"></a> 4.3. 查询流程</h3><p>在 Elasticsearch 中，查询是一个比较复杂的执行模式，因为我们不知道那些 document 会被匹配到，任何一个 shard 上都有可能，所以一个 search 请求必须查询一个索引或多个索引里面的所有 shard 才能完整的查询到我们想要的结果。</p><p>找到所有匹配的结果是查询的第一步，来自多个 shard 上的数据集在分页返回到客户端之前会被合并到一个排序后的 list 列表，由于需要经过一步取 top N 的操作，所以 search 需要进过两个阶段才能完成，分别是 query 和 fetch。</p><h2 id="5-参考资料"><a class="markdownIt-Anchor" href="#5-参考资料"></a> 5. 参考资料</h2><ul><li><a href="https://www.elastic.co/" target="_blank" rel="noopener">Elasticsearch 官网</a></li><li><a href="https://www.knowledgedict.com/tutorial/elasticsearch-index-mapping.html" target="_blank" rel="noopener">Elasticsearch 索引映射类型及 mapping 属性详解</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;elasticsearch-索引&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#elasticsearch-索引&quot;&gt;&lt;/a&gt; Elasticsearch 索引&lt;/h1&gt;
&lt;h2 id=&quot;1-索引管理操作&quot;&gt;&lt;a class=&quot;markd
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/Elasticsearch/"/>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="索引" scheme="https://dunwu.github.io/blog/tags/%E7%B4%A2%E5%BC%95/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch 高亮搜索及显示</title>
    <link href="https://dunwu.github.io/blog/2022/02/22/elasticsearch-%E9%AB%98%E4%BA%AE%E6%90%9C%E7%B4%A2%E5%8F%8A%E6%98%BE%E7%A4%BA/"/>
    <id>https://dunwu.github.io/blog/2022/02/22/elasticsearch-%E9%AB%98%E4%BA%AE%E6%90%9C%E7%B4%A2%E5%8F%8A%E6%98%BE%E7%A4%BA/</id>
    <published>2022-02-22T13:01:01.000Z</published>
    <updated>2022-04-14T08:45:53.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="elasticsearch-高亮搜索及显示"><a class="markdownIt-Anchor" href="#elasticsearch-高亮搜索及显示"></a> Elasticsearch 高亮搜索及显示</h1><p>Elasticsearch 的高亮（highlight）可以让您从搜索结果中的一个或多个字段中获取突出显示的摘要，以便向用户显示查询匹配的位置。当您请求突出显示（即高亮）时，响应结果的 highlight 字段中包括高亮的字段和高亮的片段。Elasticsearch 默认会用 <code>&lt;em&gt;&lt;/em&gt;</code> 标签标记关键字。</p><h2 id="1-高亮参数"><a class="markdownIt-Anchor" href="#1-高亮参数"></a> 1. 高亮参数</h2><p>ES 提供了如下高亮参数：</p><table><thead><tr><th style="text-align:left">参数</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left"><code>boundary_chars</code></td><td style="text-align:left">包含每个边界字符的字符串。默认为,! ?\ \ n。</td></tr><tr><td style="text-align:left"><code>boundary_max_scan</code></td><td style="text-align:left">扫描边界字符的距离。默认为 20。</td></tr><tr><td style="text-align:left"><code>boundary_scanner</code></td><td style="text-align:left">指定如何分割突出显示的片段，支持 chars、sentence、word 三种方式。</td></tr><tr><td style="text-align:left"><code>boundary_scanner_locale</code></td><td style="text-align:left">用来设置搜索和确定单词边界的本地化设置，此参数使用语言标记的形式（“en-US”, “fr-FR”, “ja-JP”）</td></tr><tr><td style="text-align:left"><code>encoder</code></td><td style="text-align:left">表示代码段应该是 HTML 编码的:默认(无编码)还是 HTML (HTML-转义代码段文本，然后插入高亮标记)</td></tr><tr><td style="text-align:left"><code>fields</code></td><td style="text-align:left">指定检索高亮显示的字段。可以使用通配符来指定字段。例如，可以指定 comment**来获取以 comment*开头的所有文本和关键字字段的高亮显示。</td></tr><tr><td style="text-align:left"><code>force_source</code></td><td style="text-align:left">根据源高亮显示。默认值为 false。</td></tr><tr><td style="text-align:left"><code>fragmenter</code></td><td style="text-align:left">指定文本应如何在突出显示片段中拆分:支持参数 simple 或者 span。</td></tr><tr><td style="text-align:left"><code>fragment_offset</code></td><td style="text-align:left">控制要开始突出显示的空白。仅在使用 fvh highlighter 时有效。</td></tr><tr><td style="text-align:left"><code>fragment_size</code></td><td style="text-align:left">字符中突出显示的片段的大小。默认为 100。</td></tr><tr><td style="text-align:left"><code>highlight_query</code></td><td style="text-align:left">突出显示搜索查询之外的其他查询的匹配项。这在使用重打分查询时特别有用，因为默认情况下高亮显示不会考虑这些问题。</td></tr><tr><td style="text-align:left"><code>matched_fields</code></td><td style="text-align:left">组合多个匹配结果以突出显示单个字段，对于使用不同方式分析同一字符串的多字段。所有的 matched_fields 必须将 term_vector 设置为 with_positions_offsets，但是只有将匹配项组合到的字段才会被加载，因此只有将 store 设置为 yes 才能使该字段受益。只适用于 fvh highlighter。</td></tr><tr><td style="text-align:left"><code>no_match_size</code></td><td style="text-align:left">如果没有要突出显示的匹配片段，则希望从字段开头返回的文本量。默认为 0(不返回任何内容)。</td></tr><tr><td style="text-align:left"><code>number_of_fragments</code></td><td style="text-align:left">返回的片段的最大数量。如果片段的数量设置为 0，则不会返回任何片段。相反，突出显示并返回整个字段内容。当需要突出显示短文本(如标题或地址)，但不需要分段时，使用此配置非常方便。如果 number_of_fragments 为 0，则忽略 fragment_size。默认为 5。</td></tr><tr><td style="text-align:left"><code>order</code></td><td style="text-align:left">设置为 score 时，按分数对突出显示的片段进行排序。默认情况下，片段将按照它们在字段中出现的顺序输出(order:none)。将此选项设置为 score 将首先输出最相关的片段。每个高亮应用自己的逻辑来计算相关性得分。</td></tr><tr><td style="text-align:left"><code>phrase_limit</code></td><td style="text-align:left">控制文档中所考虑的匹配短语的数量。防止 fvh highlighter 分析太多的短语和消耗太多的内存。提高限制会增加查询时间并消耗更多内存。默认为 256。</td></tr><tr><td style="text-align:left"><code>pre_tags</code></td><td style="text-align:left">与 post_tags 一起使用，定义用于突出显示文本的 HTML 标记。默认情况下，突出显示的文本被包装在和标记中。指定为字符串数组。</td></tr><tr><td style="text-align:left"><code>post_tags</code></td><td style="text-align:left">与 pre_tags 一起使用，定义用于突出显示文本的 HTML 标记。默认情况下，突出显示的文本被包装在和标记中。指定为字符串数组。</td></tr><tr><td style="text-align:left"><code>require_field_match</code></td><td style="text-align:left">默认情况下，只突出显示包含查询匹配的字段。将 require_field_match 设置为 false 以突出显示所有字段。默认值为 true。</td></tr><tr><td style="text-align:left"><code>tags_schema</code></td><td style="text-align:left">设置为使用内置标记模式的样式。</td></tr><tr><td style="text-align:left"><code>type</code></td><td style="text-align:left">使用的高亮模式，可选项为**<em><code>unified</code></em><strong>、</strong><em><code>plain</code></em><strong>或</strong><em><code>fvh</code></em>**。默认为 <em><code>unified</code></em>。</td></tr></tbody></table><h2 id="2-自定义高亮片段"><a class="markdownIt-Anchor" href="#2-自定义高亮片段"></a> 2. 自定义高亮片段</h2><p>如果我们想使用自定义标签，在高亮属性中给需要高亮的字段加上 <code>pre_tags</code> 和 <code>post_tags</code> 即可。例如，搜索 title 字段中包含关键词 javascript 的书籍并使用自定义 HTML 标签高亮关键词，查询语句如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /books/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"match"</span>: &#123; <span class="string">"title"</span>: <span class="string">"javascript"</span> &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"highlight"</span>: &#123;</span><br><span class="line">    <span class="string">"fields"</span>: &#123;</span><br><span class="line">      <span class="string">"title"</span>: &#123;</span><br><span class="line">        <span class="string">"pre_tags"</span>: [<span class="string">"&lt;strong&gt;"</span>],</span><br><span class="line">        <span class="string">"post_tags"</span>: [<span class="string">"&lt;/strong&gt;"</span>]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-多字段高亮"><a class="markdownIt-Anchor" href="#3-多字段高亮"></a> 3. 多字段高亮</h2><p>关于搜索高亮，还需要掌握如何设置多字段搜索高亮。比如，搜索 title 字段的时候，我们期望 description 字段中的关键字也可以高亮，这时候就需要把 <code>require_field_match</code> 属性的取值设置为 <code>fasle</code>。<code>require_field_match</code> 的默认值为 <code>true</code>，只会高亮匹配的字段。多字段高亮的查询语句如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /books/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"match"</span>: &#123; <span class="string">"title"</span>: <span class="string">"javascript"</span> &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"highlight"</span>: &#123;</span><br><span class="line">    <span class="string">"require_field_match"</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="string">"fields"</span>: &#123;</span><br><span class="line">      <span class="string">"title"</span>: &#123;&#125;,</span><br><span class="line">      <span class="string">"description"</span>: &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4-高亮性能分析"><a class="markdownIt-Anchor" href="#4-高亮性能分析"></a> 4. 高亮性能分析</h2><p>Elasticsearch 提供了三种高亮器，分别是<strong>默认的 highlighter 高亮器</strong>、<strong>postings-highlighter 高亮器</strong>和 <strong>fast-vector-highlighter 高亮器</strong>。</p><p>默认的 <strong>highlighter</strong> 是最基本的高亮器。highlighter 高亮器实现高亮功能需要对 <code>_source</code> 中保存的原始文档进行二次分析，其速度在三种高亮器里最慢，优点是不需要额外的存储空间。</p><p><strong>postings-highlighter</strong> 高亮器实现高亮功能不需要二次分析，但是需要在字段的映射中设置 <code>index_options</code> 参数的取值为 <code>offsets</code>，即保存关键词的偏移量，速度快于默认的 highlighter 高亮器。例如，配置 comment 字段使用 postings-highlighter 高亮器，映射如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PUT /example</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"mappings"</span>: &#123;</span><br><span class="line">    <span class="string">"doc"</span>: &#123;</span><br><span class="line">      <span class="string">"properties"</span>: &#123;</span><br><span class="line">        <span class="string">"comment"</span>: &#123;</span><br><span class="line">          <span class="string">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">          <span class="string">"index_options"</span>: <span class="string">"offsets"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>fast-vector-highlighter</strong> 高亮器实现高亮功能速度最快，但是需要在字段的映射中设置 <code>term_vector</code> 参数的取值为 <code>with_positions_offsets</code>，即保存关键词的位置和偏移信息，占用的存储空间最大，是典型的空间换时间的做法。例如，配置 comment 字段使用 fast-vector-highlighter 高亮器，映射如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PUT /example</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"mappings"</span>: &#123;</span><br><span class="line">    <span class="string">"doc"</span>: &#123;</span><br><span class="line">      <span class="string">"properties"</span>: &#123;</span><br><span class="line">        <span class="string">"comment"</span>: &#123;</span><br><span class="line">          <span class="string">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">          <span class="string">"term_vector"</span>: <span class="string">"with_positions_offsets"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;elasticsearch-高亮搜索及显示&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#elasticsearch-高亮搜索及显示&quot;&gt;&lt;/a&gt; Elasticsearch 高亮搜索及显示&lt;/h1&gt;
&lt;p&gt;Elasticsearch 的
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/Elasticsearch/"/>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/tags/Elasticsearch/"/>
    
      <category term="高亮" scheme="https://dunwu.github.io/blog/tags/%E9%AB%98%E4%BA%AE/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch 分析器</title>
    <link href="https://dunwu.github.io/blog/2022/02/22/elasticsearch-%E5%88%86%E6%9E%90%E5%99%A8/"/>
    <id>https://dunwu.github.io/blog/2022/02/22/elasticsearch-%E5%88%86%E6%9E%90%E5%99%A8/</id>
    <published>2022-02-22T13:01:01.000Z</published>
    <updated>2022-04-14T08:45:53.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="elasticsearch-分析器"><a class="markdownIt-Anchor" href="#elasticsearch-分析器"></a> Elasticsearch 分析器</h1><p>在 ES 中，不管是索引任务还是搜索工作，都需要使用 analyzer（分析器）。分析器，分为<strong>内置分析器</strong>和<strong>自定义的分析器</strong>。</p><p>分析器进一步由<strong>字符过滤器</strong>（<strong>Character Filters</strong>）、<strong>分词器</strong>（<strong>Tokenizer</strong>）和<strong>词元过滤器</strong>（<strong>Token Filters</strong>）三部分组成。它的执行顺序如下：</p><p><strong><em>character filters</em></strong> -&gt; <strong><em>tokenizer</em></strong> -&gt; <strong><em>token filters</em></strong></p><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#1-%E5%AD%97%E7%AC%A6%E8%BF%87%E6%BB%A4%E5%99%A8character-filters">1. 字符过滤器（Character Filters）</a><ul><li><a href="#11-html-strip-character-filter">1.1. HTML strip character filter</a></li><li><a href="#12-mapping-character-filter">1.2. Mapping character filter</a></li><li><a href="#13-pattern-replace-character-filter">1.3. Pattern Replace character filter</a></li></ul></li><li><a href="#2-%E5%88%86%E8%AF%8D%E5%99%A8tokenizer">2. 分词器（Tokenizer）</a><ul><li><a href="#21-elasticsearch-plugin-%E4%BD%BF%E7%94%A8">2.1. elasticsearch-plugin 使用</a></li><li><a href="#22-elasticsearch-analysis-ik-%E5%AE%89%E8%A3%85">2.2. elasticsearch-analysis-ik 安装</a></li><li><a href="#23-elasticsearch-analysis-ik-%E4%BD%BF%E7%94%A8">2.3. elasticsearch-analysis-ik 使用</a></li></ul></li><li><a href="#3-%E8%AF%8D%E5%85%83%E8%BF%87%E6%BB%A4%E5%99%A8token-filters">3. 词元过滤器（Token Filters）</a><ul><li><a href="#31-%E5%90%8C%E4%B9%89%E8%AF%8D">3.1. 同义词</a></li></ul></li><li><a href="#4-%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">4. 参考资料</a></li></ul><!-- /TOC --><h2 id="1-字符过滤器character-filters"><a class="markdownIt-Anchor" href="#1-字符过滤器character-filters"></a> 1. 字符过滤器（Character Filters）</h2><p>character filter 的输入是原始的文本 text，如果配置了多个，它会按照配置的顺序执行，目前 ES 自带的 character filter 主要由如下 3 类：</p><ol><li>html strip character filter：从文本中剥离 HTML 元素，并用其解码值替换 HTML 实体（如，将 <strong><em><code>＆amp;</code></em></strong> 替换为 <strong><em><code>＆</code></em></strong>）。</li><li>mapping character filter：自定义一个 map 映射，可以进行一些自定义的替换，如常用的大写变小写也可以在该环节设置。</li><li>pattern replace character filter：使用 java 正则表达式来匹配应替换为指定替换字符串的字符，此外，替换字符串可以引用正则表达式中的捕获组。</li></ol><h3 id="11-html-strip-character-filter"><a class="markdownIt-Anchor" href="#11-html-strip-character-filter"></a> 1.1. HTML strip character filter</h3><p>HTML strip 如下示例：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_analyze</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"tokenizer"</span>: <span class="string">"keyword"</span>,</span><br><span class="line">  <span class="string">"char_filter"</span>: [</span><br><span class="line">    <span class="string">"html_strip"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="string">"text"</span>: <span class="string">"&lt;p&gt;I&amp;apos;m so &lt;b&gt;happy&lt;/b&gt;!&lt;/p&gt;"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>经过 <strong><em><code>html_strip</code></em></strong> 字符过滤器处理后，输出如下：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">[ \nI'm so happy!\n ]</span><br></pre></td></tr></table></figure><h3 id="12-mapping-character-filter"><a class="markdownIt-Anchor" href="#12-mapping-character-filter"></a> 1.2. Mapping character filter</h3><p>Mapping character filter 接收键和值映射（key =&gt; value）作为配置参数，每当在预处理过程中遇到与键值映射中的键相同的字符串时，就会使用该键对应的值去替换它。</p><p>原始文本中的字符串和键值映射中的键的匹配是贪心的，在对给定的文本进行预处理过程中如果配置的键值映射存在包含关系，会优先<strong>匹配最长键</strong>。同样也可以用空字符串进行替换。</p><p>mapping char_filter 不像 html_strip 那样拆箱即可用，必须先进行配置才能使用，它有两个属性可以配置：</p><table><thead><tr><th style="text-align:left">参数名称</th><th style="text-align:left">参数说明</th></tr></thead><tbody><tr><td style="text-align:left"><strong><em><code>mappings</code></em></strong></td><td style="text-align:left">一组映射，每个元素的格式为 <em>key =&gt; value</em>。</td></tr><tr><td style="text-align:left"><strong><em><code>mappings_path</code></em></strong></td><td style="text-align:left">一个相对或者绝对的文件路径，指向一个每行包含一个 <em>key =&gt;value</em> 映射的 UTF-8 编码文本映射文件。</td></tr></tbody></table><p>mapping char_filter 示例如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_analyze</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"tokenizer"</span>: <span class="string">"keyword"</span>,</span><br><span class="line">  <span class="string">"char_filter"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"type"</span>: <span class="string">"mapping"</span>,</span><br><span class="line">      <span class="string">"mappings"</span>: [</span><br><span class="line">        <span class="string">"٠ =&gt; 0"</span>,</span><br><span class="line">        <span class="string">"١ =&gt; 1"</span>,</span><br><span class="line">        <span class="string">"٢ =&gt; 2"</span>,</span><br><span class="line">        <span class="string">"٣ =&gt; 3"</span>,</span><br><span class="line">        <span class="string">"٤ =&gt; 4"</span>,</span><br><span class="line">        <span class="string">"٥ =&gt; 5"</span>,</span><br><span class="line">        <span class="string">"٦ =&gt; 6"</span>,</span><br><span class="line">        <span class="string">"٧ =&gt; 7"</span>,</span><br><span class="line">        <span class="string">"٨ =&gt; 8"</span>,</span><br><span class="line">        <span class="string">"٩ =&gt; 9"</span></span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  <span class="string">"text"</span>: <span class="string">"My license plate is ٢٥٠١٥"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>分析结果如下：</p><figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">[ My license plate <span class="keyword">is</span> <span class="number">25015</span> ]</span><br></pre></td></tr></table></figure><h3 id="13-pattern-replace-character-filter"><a class="markdownIt-Anchor" href="#13-pattern-replace-character-filter"></a> 1.3. Pattern Replace character filter</h3><p>Pattern Replace character filter 支持如下三个参数：</p><table><thead><tr><th style="text-align:left">参数名称</th><th style="text-align:left">参数说明</th></tr></thead><tbody><tr><td style="text-align:left"><strong><em><code>pattern</code></em></strong></td><td style="text-align:left">必填参数，一个 java 的正则表达式。</td></tr><tr><td style="text-align:left"><strong><em><code>replacement</code></em></strong></td><td style="text-align:left">替换字符串，可以使用 <strong><em><code>$1 ... $9</code></em></strong> 语法来引用捕获组。</td></tr><tr><td style="text-align:left"><strong><em><code>flags</code></em></strong></td><td style="text-align:left">Java 正则表达式的标志，具体参考 java 的 java.util.regex.Pattern 类的标志属性。</td></tr></tbody></table><p>如将输入的 text 中大于一个的空格都转变为一个空格，在 settings 时，配置示例如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="string">"char_filter"</span>: &#123;</span><br><span class="line">  <span class="string">"multi_space_2_one"</span>: &#123;</span><br><span class="line">    <span class="string">"pattern"</span>: <span class="string">"[ ]+"</span>,</span><br><span class="line">    <span class="string">"type"</span>: <span class="string">"pattern_replace"</span>,</span><br><span class="line">    <span class="string">"replacement"</span>: <span class="string">" "</span></span><br><span class="line">  &#125;,</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-分词器tokenizer"><a class="markdownIt-Anchor" href="#2-分词器tokenizer"></a> 2. 分词器（Tokenizer）</h2><p>tokenizer 即分词器，也是 analyzer 最重要的组件，它对文本进行分词；<strong>一个 analyzer 必需且只可包含一个 tokenizer</strong>。</p><p>ES 自带默认的分词器是 standard tokenizer，标准分词器提供基于语法的分词（基于 Unicode 文本分割算法），并且适用于大多数语言。</p><p>此外有很多第三方的分词插件，如中文分词界最经典的 ik 分词器，它对应的 tokenizer 分为 ik_smart 和 ik_max_word，一个是智能分词（针对搜索侧），一个是全切分词（针对索引侧）。</p><p>ES 默认提供的分词器 standard 对中文分词不优化，效果差，一般会安装第三方中文分词插件，通常首先 <a href="https://github.com/medcl/elasticsearch-analysis-ik" target="_blank" rel="noopener">elasticsearch-analysis-ik</a> 插件，它其实是 ik 针对的 ES 的定制版。</p><h3 id="21-elasticsearch-plugin-使用"><a class="markdownIt-Anchor" href="#21-elasticsearch-plugin-使用"></a> 2.1. elasticsearch-plugin 使用</h3><p>在安装 elasticsearch-analysis-ik 第三方之前，我们首先要了解 es 的插件管理工具 <strong><em><code>elasticsearch-plugin</code></em></strong> 的使用。</p><p>现在的 elasticsearch 安装完后，在安装目录的 bin 目录下会存在 elasticsearch-plugin 命令工具，用它来对 es 插件进行管理。</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">bin/elastic<span class="built_in">search-plugin</span></span><br></pre></td></tr></table></figure><p>其实该命令的是软连接，原始路径是：</p><figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">libexec<span class="regexp">/bin/</span>elasticsearch-plugin</span><br></pre></td></tr></table></figure><p>再进一步看脚本代码，你会发现，它是通过 <strong><em><code>elasticsearch-cli</code></em></strong> 执行 <code>libexec/lib/tools/plugin-cli/elasticsearch-plugin-cli-x.x.x.jar</code>。</p><p>但一般使用者了解 elasticsearch-plugin 命令使用就可：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#  安装指定的插件到当前 ES 节点中</span></span><br><span class="line">elasticsearch-plugin install &#123;plugin_url&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#  显示当前 ES 节点已经安装的插件列表</span></span><br><span class="line">elasticsearch-plugin list</span><br><span class="line"></span><br><span class="line"><span class="comment">#  删除已安装的插件</span></span><br><span class="line">elasticsearch-plugin remove &#123;plugin_name&#125;</span><br></pre></td></tr></table></figure><blockquote><p>在安装插件时，要保证安装的插件与 ES 版本一致。</p></blockquote><h3 id="22-elasticsearch-analysis-ik-安装"><a class="markdownIt-Anchor" href="#22-elasticsearch-analysis-ik-安装"></a> 2.2. elasticsearch-analysis-ik 安装</h3><p>在确定要安装的 ik 版本之后，执行如下命令：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v&#123;X.X.X&#125;/elasticsearch-analysis-ik-&#123;X.X.X&#125;.zip</span><br></pre></td></tr></table></figure><p>执行完安装命令后，我们会发现在 plugins 中多了 analysis-ik 目录，这里面主要存放的是源码 jar 包，此外，在 config 文件里也多了 analysis-ik 目录，里面主要是 ik 相关的配置，如 IKAnalyzer.cfg.xml 配置、词典文件等。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#  两个新增目录路径</span></span><br><span class="line">libexec/plugins/analysis-ik/</span><br><span class="line">libexec/config/analysis-ik/</span><br></pre></td></tr></table></figure><h3 id="23-elasticsearch-analysis-ik-使用"><a class="markdownIt-Anchor" href="#23-elasticsearch-analysis-ik-使用"></a> 2.3. elasticsearch-analysis-ik 使用</h3><p>ES 5.X 版本开始安装完的 elasticsearch-analysis-ik 提供了两个分词器，分别对应名称是 <strong><em>ik_max_word</em></strong> 和 <strong><em>ik_smart</em></strong>，ik_max_word 是索引侧的分词器，走全切模式，ik_smart 是搜索侧的分词器，走智能分词，属于搜索模式。</p><h4 id="索引-mapping-设置"><a class="markdownIt-Anchor" href="#索引-mapping-设置"></a> 索引 mapping 设置</h4><p>安装完 elasticsearch-analysis-ik 后，我们可以指定索引及指定字段设置可用的分析器（analyzer），示例如下：</p><figure class="highlight"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"qa"</span>: &#123;</span><br><span class="line">    <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">      <span class="attr">"qa"</span>: &#123;</span><br><span class="line">        <span class="attr">"_all"</span>: &#123;</span><br><span class="line">          <span class="attr">"enabled"</span>: <span class="literal">false</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"properties"</span>: &#123;</span><br><span class="line">          <span class="attr">"question"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">            <span class="attr">"store"</span>: <span class="literal">true</span>,</span><br><span class="line">            <span class="attr">"similarity"</span>: <span class="string">"BM25"</span>,</span><br><span class="line">            <span class="attr">"analyzer"</span>: <span class="string">"ik_max_word"</span>,</span><br><span class="line">            <span class="attr">"search_analyzer"</span>: <span class="string">"ik_smart"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"answer"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">            <span class="attr">"store"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"similarity"</span>: <span class="string">"BM25"</span>,</span><br><span class="line">            <span class="attr">"analyzer"</span>: <span class="string">"ik_max_word"</span>,</span><br><span class="line">            <span class="attr">"search_analyzer"</span>: <span class="string">"ik_smart"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          ...</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如上示例中，analyzer 指定 ik_max_word，即索引侧使用 ik 全切模式，search_analyzer 设置 ik_smart，即搜索侧使用 ik 智能分词模式。</p><h4 id="查看-ik-分词结果"><a class="markdownIt-Anchor" href="#查看-ik-分词结果"></a> 查看 ik 分词结果</h4><p>es 提供了查看分词结果的 api <strong><code>analyze</code></strong>，具体示例如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET &#123;index&#125;/_analyze</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"analyzer"</span> : <span class="string">"ik_smart"</span>,</span><br><span class="line">  <span class="string">"text"</span> : <span class="string">"es 中文分词器安装"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"tokens"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"token"</span>: <span class="string">"es"</span>,</span><br><span class="line">      <span class="attr">"start_offset"</span>: <span class="number">0</span>,</span><br><span class="line">      <span class="attr">"end_offset"</span>: <span class="number">2</span>,</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"CN_WORD"</span>,</span><br><span class="line">      <span class="attr">"position"</span>: <span class="number">0</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"token"</span>: <span class="string">"中文"</span>,</span><br><span class="line">      <span class="attr">"start_offset"</span>: <span class="number">3</span>,</span><br><span class="line">      <span class="attr">"end_offset"</span>: <span class="number">5</span>,</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"CN_WORD"</span>,</span><br><span class="line">      <span class="attr">"position"</span>: <span class="number">1</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"token"</span>: <span class="string">"分词器"</span>,</span><br><span class="line">      <span class="attr">"start_offset"</span>: <span class="number">5</span>,</span><br><span class="line">      <span class="attr">"end_offset"</span>: <span class="number">8</span>,</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"CN_WORD"</span>,</span><br><span class="line">      <span class="attr">"position"</span>: <span class="number">2</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"token"</span>: <span class="string">"安装"</span>,</span><br><span class="line">      <span class="attr">"start_offset"</span>: <span class="number">8</span>,</span><br><span class="line">      <span class="attr">"end_offset"</span>: <span class="number">10</span>,</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"CN_WORD"</span>,</span><br><span class="line">      <span class="attr">"position"</span>: <span class="number">3</span></span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="elasticsearch-analysis-ik-自定义词典"><a class="markdownIt-Anchor" href="#elasticsearch-analysis-ik-自定义词典"></a> elasticsearch-analysis-ik 自定义词典</h4><p>elasticsearch-analysis-ik 本质是 ik 分词器，使用者根据实际需求可以扩展自定义的词典，具体主要分为如下 2 大类，每类又分为本地配置和远程配置 2 种：</p><ol><li>自定义扩展词典；</li><li>自定义扩展停用词典；</li></ol><p>elasticsearch-analysis-ik 配置文件为 <code>IKAnalyzer.cfg.xml</code>，它位于 <code>libexec/config/analysis-ik</code> 目录下，具体配置结构如下：</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">properties</span> <span class="meta-keyword">SYSTEM</span> <span class="meta-string">"http://java.sun.com/dtd/properties.dtd"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">comment</span>&gt;</span>IK Analyzer 扩展配置<span class="tag">&lt;/<span class="name">comment</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--用户可以在这里配置自己的扩展字典 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">"ext_dict"</span>&gt;</span><span class="tag">&lt;/<span class="name">entry</span>&gt;</span></span><br><span class="line"> <span class="comment">&lt;!--用户可以在这里配置自己的扩展停止词字典--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">entry</span> <span class="attr">key</span>=<span class="string">"ext_stopwords"</span>&gt;</span><span class="tag">&lt;/<span class="name">entry</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--用户可以在这里配置远程扩展字典 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- &lt;entry key="remote_ext_dict"&gt;words_location&lt;/entry&gt; --&gt;</span></span><br><span class="line"><span class="comment">&lt;!--用户可以在这里配置远程扩展停止词字典--&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- &lt;entry key="remote_ext_stopwords"&gt;words_location&lt;/entry&gt; --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>当然，如果开发者认为 ik 默认的词表有问题，也可以进行调整，文件都在 <code>libexec/config/analysis-ik</code> 下，如 main.dic 为主词典，stopword.dic 为停用词表。</p></blockquote><h2 id="3-词元过滤器token-filters"><a class="markdownIt-Anchor" href="#3-词元过滤器token-filters"></a> 3. 词元过滤器（Token Filters）</h2><p>token filters 叫词元过滤器，或词项过滤器，对 tokenizer 分出的词进行过滤处理。常用的有转小写、停用词处理、同义词处理等等。<strong>一个 analyzer 可包含 0 个或多个词项过滤器，按配置顺序进行过滤</strong>。</p><p>以同义词过滤器的使用示例，具体如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PUT /test_index</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"settings"</span>: &#123;</span><br><span class="line">    <span class="string">"index"</span>: &#123;</span><br><span class="line">      <span class="string">"analysis"</span>: &#123;</span><br><span class="line">        <span class="string">"analyzer"</span>: &#123;</span><br><span class="line">          <span class="string">"synonym"</span>: &#123;</span><br><span class="line">            <span class="string">"tokenizer"</span>: <span class="string">"standard"</span>,</span><br><span class="line">            <span class="string">"filter"</span>: [ <span class="string">"my_stop"</span>, <span class="string">"synonym"</span> ]</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"filter"</span>: &#123;</span><br><span class="line">          <span class="string">"my_stop"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"stop"</span>,</span><br><span class="line">            <span class="string">"stopwords"</span>: [ <span class="string">"bar"</span> ]</span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="string">"synonym"</span>: &#123;</span><br><span class="line">            <span class="string">"type"</span>: <span class="string">"synonym"</span>,</span><br><span class="line">            <span class="string">"lenient"</span>: <span class="literal">true</span>,</span><br><span class="line">            <span class="string">"synonyms"</span>: [ <span class="string">"foo, bar =&gt; baz"</span> ]</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="31-同义词"><a class="markdownIt-Anchor" href="#31-同义词"></a> 3.1. 同义词</h3><p>Elasticsearch 同义词通过专有的同义词过滤器（synonym token filter）来进行工作，它允许在分析（analysis）过程中方便地处理同义词，一般是通过配置文件配置同义词。此外，同义词可以再建索引时（index-time synonyms）或者检索时（search-time synonyms）使用。</p><h4 id="同义词synonym配置语法"><a class="markdownIt-Anchor" href="#同义词synonym配置语法"></a> 同义词（synonym）配置语法</h4><p>如上例子所示，es 同义词配置的 filter 语法具体如下选项：</p><ul><li><p><strong><em><code>type</code></em></strong>：指定 synonym，表示同义词 filter；</p></li><li><p><strong><em><code>synonyms_path</code></em></strong>：指定同义词配置文件路径；</p></li><li><p><strong><code>expand</code></strong>：该参数决定映射行为的模式，默认为 true，表示扩展模式，具体示例如下：</p><ul><li><p>当 <strong><code>expand == true</code></strong> 时，</p><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">ipod, <span class="built_in">i</span>-pod, <span class="built_in">i</span> pod</span><br></pre></td></tr></table></figure><p>等价于：</p><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">ipod, <span class="built_in">i</span>-pod, <span class="built_in">i</span> pod =&gt; ipod, <span class="built_in">i</span>-pod, <span class="built_in">i</span> pod</span><br></pre></td></tr></table></figure><p>当 <strong><em><code>expand == false</code></em></strong> 时，</p><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">ipod, <span class="built_in">i</span>-pod, <span class="built_in">i</span> pod</span><br></pre></td></tr></table></figure><p>仅映射第一个单词，等价于：</p><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">ipod, <span class="built_in">i</span>-pod, <span class="built_in">i</span> pod =&gt; ipod</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong><em><code>lenient</code></em></strong>：如果值为 true 时，遇到那些无法解析的同义词规则时，忽略异常。默认为 false。</p></li></ul><h4 id="同义词文档格式"><a class="markdownIt-Anchor" href="#同义词文档格式"></a> 同义词文档格式</h4><p>elasticsearch 的同义词有如下两种形式：</p><ul><li><p>单向同义词：</p><figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">ipod, <span class="built_in">i</span>-pod, <span class="built_in">i</span> pod =&gt; ipod</span><br></pre></td></tr></table></figure></li><li><p>双向同义词：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">马铃薯, 土豆, potato</span><br></pre></td></tr></table></figure></li></ul><p>单向同义词不管索引还是检索时，箭头左侧的词都会映射成箭头右侧的词；</p><p>双向同义词是索引时，都建立同义词的倒排索引，检索时，同义词之间都会进行倒排索引的匹配。</p><blockquote><p>同义词的文档化时，需要注意的是，同一个词在不同的同义词关系中出现时，其它同义词之间不具有传递性，这点需要注意。</p></blockquote><p>假设如上示例中，如果“马铃薯”和其它两个同义词分成两行写：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">马铃薯,土豆</span><br><span class="line">马铃薯,potato</span><br></pre></td></tr></table></figure><p>此时，elasticsearch 中不会将“土豆”和“potato”视为同义词关系，所以多个同义词要写在一起，这往往是开发中经常容易疏忽的点。</p><h2 id="4-参考资料"><a class="markdownIt-Anchor" href="#4-参考资料"></a> 4. 参考资料</h2><ul><li><a href="https://www.knowledgedict.com/tutorial/elasticsearch-intro.html" target="_blank" rel="noopener">Elasticsearch 教程</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;elasticsearch-分析器&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#elasticsearch-分析器&quot;&gt;&lt;/a&gt; Elasticsearch 分析器&lt;/h1&gt;
&lt;p&gt;在 ES 中，不管是索引任务还是搜索工作，都需要使用 
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/Elasticsearch/"/>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/tags/Elasticsearch/"/>
    
      <category term="分析器" scheme="https://dunwu.github.io/blog/tags/%E5%88%86%E6%9E%90%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch 性能优化</title>
    <link href="https://dunwu.github.io/blog/2022/01/21/elasticsearch-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    <id>https://dunwu.github.io/blog/2022/01/21/elasticsearch-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</id>
    <published>2022-01-21T11:54:43.000Z</published>
    <updated>2022-04-14T08:45:53.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="elasticsearch-性能优化"><a class="markdownIt-Anchor" href="#elasticsearch-性能优化"></a> Elasticsearch 性能优化</h1><p>Elasticsearch 是当前流行的企业级搜索引擎，设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。作为一个开箱即用的产品，在生产环境上线之后，我们其实不一定能确保其的性能和稳定性。如何根据实际情况提高服务的性能，其实有很多技巧。这章我们分享从实战经验中总结出来的 elasticsearch 性能优化，主要从硬件配置优化、索引优化设置、查询方面优化、数据结构优化、集群架构优化等方面讲解。</p><h2 id="1-硬件配置优化"><a class="markdownIt-Anchor" href="#1-硬件配置优化"></a> 1. 硬件配置优化</h2><p>升级硬件设备配置一直都是提高服务能力最快速有效的手段，在系统层面能够影响应用性能的一般包括三个因素：CPU、内存和 IO，可以从这三方面进行 ES 的性能优化工作。</p><h3 id="11-cpu-配置"><a class="markdownIt-Anchor" href="#11-cpu-配置"></a> 1.1. CPU 配置</h3><p>一般说来，CPU 繁忙的原因有以下几个：</p><ol><li>线程中有无限空循环、无阻塞、正则匹配或者单纯的计算；</li><li>发生了频繁的 GC；</li><li>多线程的上下文切换；</li></ol><p>大多数 Elasticsearch 部署往往对 CPU 要求不高。因此，相对其它资源，具体配置多少个（CPU）不是那么关键。你应该选择具有多个内核的现代处理器，常见的集群使用 2 到 8 个核的机器。<strong>如果你要在更快的 CPUs 和更多的核数之间选择，选择更多的核数更好</strong>。多个内核提供的额外并发远胜过稍微快一点点的时钟频率。</p><h3 id="12-内存配置"><a class="markdownIt-Anchor" href="#12-内存配置"></a> 1.2. 内存配置</h3><p>如果有一种资源是最先被耗尽的，它可能是内存。排序和聚合都很耗内存，所以有足够的堆空间来应付它们是很重要的。即使堆空间是比较小的时候，也能为操作系统文件缓存提供额外的内存。因为 Lucene 使用的许多数据结构是基于磁盘的格式，Elasticsearch 利用操作系统缓存能产生很大效果。</p><p><strong>64 GB 内存的机器是非常理想的</strong>，但是 32 GB 和 16 GB 机器也是很常见的。少于 8 GB 会适得其反（你最终需要很多很多的小机器），大于 64 GB 的机器也会有问题。</p><p>由于 ES 构建基于 lucene，而 lucene 设计强大之处在于 lucene 能够很好的利用操作系统内存来缓存索引数据，以提供快速的查询性能。lucene 的索引文件 segements 是存储在单文件中的，并且不可变，对于 OS 来说，能够很友好地将索引文件保持在 cache 中，以便快速访问；因此，我们很有必要将一半的物理内存留给 lucene；另一半的物理内存留给 ES（JVM heap）。</p><h4 id="内存分配"><a class="markdownIt-Anchor" href="#内存分配"></a> 内存分配</h4><p>当机器内存小于 64G 时，遵循通用的原则，50% 给 ES，50% 留给 lucene。</p><p>当机器内存大于 64G 时，遵循以下原则：</p><ul><li>如果主要的使用场景是全文检索，那么建议给 ES Heap 分配 4~32G 的内存即可；其它内存留给操作系统，供 lucene 使用（segments cache），以提供更快的查询性能。</li><li>如果主要的使用场景是聚合或排序，并且大多数是 numerics，dates，geo_points 以及 not_analyzed 的字符类型，建议分配给 ES Heap 分配 4~32G 的内存即可，其它内存留给操作系统，供 lucene 使用，提供快速的基于文档的聚类、排序性能。</li><li>如果使用场景是聚合或排序，并且都是基于 analyzed 字符数据，这时需要更多的 heap size，建议机器上运行多 ES 实例，每个实例保持不超过 50% 的 ES heap 设置（但不超过 32 G，堆内存设置 32 G 以下时，JVM 使用对象指标压缩技巧节省空间），50% 以上留给 lucene。</li></ul><h4 id="禁止-swap"><a class="markdownIt-Anchor" href="#禁止-swap"></a> 禁止 swap</h4><p>禁止 swap，一旦允许内存与磁盘的交换，会引起致命的性能问题。可以通过在 elasticsearch.yml 中 <code>bootstrap.memory_lock: true</code>，以保持 JVM 锁定内存，保证 ES 的性能。</p><h4 id="gc-设置"><a class="markdownIt-Anchor" href="#gc-设置"></a> GC 设置</h4><p>保持 GC 的现有设置，默认设置为：Concurrent-Mark and Sweep（CMS），别换成 G1 GC，因为目前 G1 还有很多 BUG。</p><p>保持线程池的现有设置，目前 ES 的线程池较 1.X 有了较多优化设置，保持现状即可；默认线程池大小等于 CPU 核心数。如果一定要改，按公式 ( ( CPU 核心数 * 3 ) / 2 ) + 1 设置；不能超过 CPU 核心数的 2 倍；但是不建议修改默认配置，否则会对 CPU 造成硬伤。</p><h3 id="13-磁盘"><a class="markdownIt-Anchor" href="#13-磁盘"></a> 1.3. 磁盘</h3><p>硬盘对所有的集群都很重要，对大量写入的集群更是加倍重要（例如那些存储日志数据的）。硬盘是服务器上最慢的子系统，这意味着那些写入量很大的集群很容易让硬盘饱和，使得它成为集群的瓶颈。</p><p><strong>在经济压力能承受的范围下，尽量使用固态硬盘（SSD）</strong>。固态硬盘相比于任何旋转介质（机械硬盘，磁带等），无论随机写还是顺序写，都会对 IO 有较大的提升。</p><blockquote><p>如果你正在使用 SSDs，确保你的系统 I/O 调度程序是配置正确的。当你向硬盘写数据，I/O 调度程序决定何时把数据实际发送到硬盘。大多数默认 *nix 发行版下的调度程序都叫做 cfq（完全公平队列）。</p><p>调度程序分配时间片到每个进程。并且优化这些到硬盘的众多队列的传递。但它是为旋转介质优化的：机械硬盘的固有特性意味着它写入数据到基于物理布局的硬盘会更高效。</p><p>这对 SSD 来说是低效的，尽管这里没有涉及到机械硬盘。但是，deadline 或者 noop 应该被使用。deadline 调度程序基于写入等待时间进行优化，noop 只是一个简单的 FIFO 队列。</p><p>这个简单的更改可以带来显著的影响。仅仅是使用正确的调度程序，我们看到了 500 倍的写入能力提升。</p></blockquote><p><strong>如果你使用旋转介质（如机械硬盘），尝试获取尽可能快的硬盘（高性能服务器硬盘，15k RPM 驱动器）</strong>。</p><p><strong>使用 RAID0 是提高硬盘速度的有效途径，对机械硬盘和 SSD 来说都是如此</strong>。没有必要使用镜像或其它 RAID 变体，因为 Elasticsearch 在自身层面通过副本，已经提供了备份的功能，所以不需要利用磁盘的备份功能，同时如果使用磁盘备份功能的话，对写入速度有较大的影响。</p><p><strong>最后，避免使用网络附加存储（NAS）</strong>。人们常声称他们的 NAS 解决方案比本地驱动器更快更可靠。除却这些声称，我们从没看到 NAS 能配得上它的大肆宣传。NAS 常常很慢，显露出更大的延时和更宽的平均延时方差，而且它是单点故障的。</p><h2 id="2-索引优化设置"><a class="markdownIt-Anchor" href="#2-索引优化设置"></a> 2. 索引优化设置</h2><p>索引优化主要是在 Elasticsearch 的插入层面优化，Elasticsearch 本身索引速度其实还是蛮快的，具体数据，我们可以参考官方的 benchmark 数据。我们可以根据不同的需求，针对索引优化。</p><h3 id="21-批量提交"><a class="markdownIt-Anchor" href="#21-批量提交"></a> 2.1. 批量提交</h3><p>当有大量数据提交的时候，建议采用批量提交（Bulk 操作）；此外使用 bulk 请求时，每个请求不超过几十 M，因为太大会导致内存使用过大。</p><p>比如在做 ELK 过程中，Logstash indexer 提交数据到 Elasticsearch 中，batch size 就可以作为一个优化功能点。但是优化 size 大小需要根据文档大小和服务器性能而定。</p><p>像 Logstash 中提交文档大小超过 20MB，Logstash 会将一个批量请求切分为多个批量请求。</p><p>如果在提交过程中，遇到 EsRejectedExecutionException 异常的话，则说明集群的索引性能已经达到极限了。这种情况，要么提高服务器集群的资源，要么根据业务规则，减少数据收集速度，比如只收集 Warn、Error 级别以上的日志。</p><h3 id="22-增加-refresh-时间间隔"><a class="markdownIt-Anchor" href="#22-增加-refresh-时间间隔"></a> 2.2. 增加 Refresh 时间间隔</h3><p>为了提高索引性能，Elasticsearch 在写入数据的时候，采用延迟写入的策略，即数据先写到内存中，当超过默认 1 秒（index.refresh_interval）会进行一次写入操作，就是将内存中 segment 数据刷新到磁盘中，此时我们才能将数据搜索出来，所以这就是为什么 Elasticsearch 提供的是近实时搜索功能，而不是实时搜索功能。</p><p>如果我们的系统对数据延迟要求不高的话，我们<strong>可以通过延长 refresh 时间间隔，可以有效地减少 segment 合并压力，提高索引速度</strong>。比如在做全链路跟踪的过程中，我们就将 <code>index.refresh_interval</code> 设置为 30s，减少 refresh 次数。再如，在进行全量索引时，可以将 refresh 次数临时关闭，即 <code>index.refresh_interval</code> 设置为-1，数据导入成功后再打开到正常模式，比如 30s。</p><blockquote><p>在加载大量数据时候可以暂时不用 refresh 和 repliccas，index.refresh_interval 设置为-1，index.number_of_replicas 设置为 0。</p></blockquote><h3 id="23-修改-index_buffer_size-的设置"><a class="markdownIt-Anchor" href="#23-修改-index_buffer_size-的设置"></a> 2.3. 修改 index_buffer_size 的设置</h3><p>索引缓冲的设置可以控制多少内存分配给索引进程。这是一个全局配置，会应用于一个节点上所有不同的分片上。</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">indices.memory.index_buffer_size:</span> <span class="number">10</span><span class="string">%</span></span><br><span class="line"><span class="attr">indices.memory.min_index_buffer_size:</span> <span class="string">48mb</span></span><br></pre></td></tr></table></figure><p><code>indices.memory.index_buffer_size</code> 接受一个百分比或者一个表示字节大小的值。默认是 10%，意味着分配给节点的总内存的 10%用来做索引缓冲的大小。这个数值被分到不同的分片（shards）上。如果设置的是百分比，还可以设置 <code>min_index_buffer_size</code> （默认 48mb）和 <code>max_index_buffer_size</code>（默认没有上限）。</p><h3 id="24-修改-translog-相关的设置"><a class="markdownIt-Anchor" href="#24-修改-translog-相关的设置"></a> 2.4. 修改 translog 相关的设置</h3><p>一是控制数据从内存到硬盘的操作频率，以减少硬盘 IO。可将 sync_interval 的时间设置大一些。默认为 5s。</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">index.translog.sync_interval:</span> <span class="string">5s</span></span><br></pre></td></tr></table></figure><p>也可以控制 tranlog 数据块的大小，达到 threshold 大小时，才会 flush 到 lucene 索引文件。默认为 512m。</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">index.translog.flush_threshold_size:</span> <span class="string">512mb</span></span><br></pre></td></tr></table></figure><h3 id="25-注意-_id-字段的使用"><a class="markdownIt-Anchor" href="#25-注意-_id-字段的使用"></a> 2.5. 注意 _id 字段的使用</h3><p>_id 字段的使用，应尽可能避免自定义 _id，以避免针对 ID 的版本管理；建议使用 ES 的默认 ID 生成策略或使用数字类型 ID 做为主键。</p><h3 id="26-注意-_all-字段及-_source-字段的使用"><a class="markdownIt-Anchor" href="#26-注意-_all-字段及-_source-字段的使用"></a> 2.6. 注意 _all 字段及 _source 字段的使用</h3><p>**_**all 字段及 _source 字段的使用，应该注意场景和需要，_all 字段包含了所有的索引字段，方便做全文检索，如果无此需求，可以禁用；_source 存储了原始的 document 内容，如果没有获取原始文档数据的需求，可通过设置 includes、excludes 属性来定义放入 _source 的字段。</p><h3 id="27-合理的配置使用-index-属性"><a class="markdownIt-Anchor" href="#27-合理的配置使用-index-属性"></a> 2.7. 合理的配置使用 index 属性</h3><p>合理的配置使用 index 属性，analyzed 和 not_analyzed，根据业务需求来控制字段是否分词或不分词。只有 groupby 需求的字段，配置时就设置成 not_analyzed，以提高查询或聚类的效率。</p><h3 id="28-减少副本数量"><a class="markdownIt-Anchor" href="#28-减少副本数量"></a> 2.8. 减少副本数量</h3><p>Elasticsearch 默认副本数量为 3 个，虽然这样会提高集群的可用性，增加搜索的并发数，但是同时也会影响写入索引的效率。</p><p>在索引过程中，需要把更新的文档发到副本节点上，等副本节点生效后在进行返回结束。使用 Elasticsearch 做业务搜索的时候，建议副本数目还是设置为 3 个，但是像内部 ELK 日志系统、分布式跟踪系统中，完全可以将副本数目设置为 1 个。</p><h2 id="3-查询方面优化"><a class="markdownIt-Anchor" href="#3-查询方面优化"></a> 3. 查询方面优化</h2><p>Elasticsearch 作为业务搜索的近实时查询时，查询效率的优化显得尤为重要。</p><h3 id="31-路由优化"><a class="markdownIt-Anchor" href="#31-路由优化"></a> 3.1. 路由优化</h3><p>当我们查询文档的时候，Elasticsearch 如何知道一个文档应该存放到哪个分片中呢？它其实是通过下面这个公式来计算出来的。</p><figure class="highlight gcode"><table><tr><td class="code"><pre><span class="line">shard = hash<span class="comment">(routing)</span> <span class="meta">%</span> <span class="symbol">number_of_primary_shards</span></span><br></pre></td></tr></table></figure><p>routing 默认值是文档的 id，也可以采用自定义值，比如用户 ID。</p><h4 id="不带-routing-查询"><a class="markdownIt-Anchor" href="#不带-routing-查询"></a> 不带 routing 查询</h4><p>在查询的时候因为不知道要查询的数据具体在哪个分片上，所以整个过程分为 2 个步骤：</p><ol><li>分发：请求到达协调节点后，协调节点将查询请求分发到每个分片上。</li><li>聚合：协调节点搜集到每个分片上查询结果，再将查询的结果进行排序，之后给用户返回结果。</li></ol><h4 id="带-routing-查询"><a class="markdownIt-Anchor" href="#带-routing-查询"></a> 带 routing 查询</h4><p>查询的时候，可以直接根据 routing 信息定位到某个分配查询，不需要查询所有的分配，经过协调节点排序。</p><p>向上面自定义的用户查询，如果 routing 设置为 userid 的话，就可以直接查询出数据来，效率提升很多。</p><h3 id="32-filter-vs-query"><a class="markdownIt-Anchor" href="#32-filter-vs-query"></a> 3.2. Filter VS Query</h3><p>尽可能使用过滤器上下文（Filter）替代查询上下文（Query）</p><ul><li>Query：此文档与此查询子句的匹配程度如何？</li><li>Filter：此文档和查询子句匹配吗？</li></ul><p>Elasticsearch 针对 Filter 查询只需要回答「是」或者「否」，不需要像 Query 查询一样计算相关性分数，同时 Filter 结果可以缓存。</p><h3 id="33-深度翻页"><a class="markdownIt-Anchor" href="#33-深度翻页"></a> 3.3. 深度翻页</h3><p>在使用 Elasticsearch 过程中，应尽量避免大翻页的出现。</p><p>正常翻页查询都是从 from 开始 size 条数据，这样就需要在每个分片中查询打分排名在前面的 from+size 条数据。协同节点收集每个分配的前 from+size 条数据。协同节点一共会受到 N*(from+size) 条数据，然后进行排序，再将其中 from 到 from+size 条数据返回出去。如果 from 或者 size 很大的话，导致参加排序的数量会同步扩大很多，最终会导致 CPU 资源消耗增大。</p><p>可以通过使用 Elasticsearch scroll 和 scroll-scan 高效滚动的方式来解决这样的问题。</p><p>也可以结合实际业务特点，文档 id 大小如果和文档创建时间是一致有序的，可以以文档 id 作为分页的偏移量，并将其作为分页查询的一个条件。</p><h3 id="34-脚本script合理使用"><a class="markdownIt-Anchor" href="#34-脚本script合理使用"></a> 3.4. 脚本（script）合理使用</h3><p>我们知道脚本使用主要有 3 种形式，内联动态编译方式、_script 索引库中存储和文件脚本存储的形式；一般脚本的使用场景是粗排，尽量用第二种方式先将脚本存储在 _script 索引库中，起到提前编译，然后通过引用脚本 id，并结合 params 参数使用，即可以达到模型（逻辑）和数据进行了分离，同时又便于脚本模块的扩展与维护。具体 ES 脚本的深入内容请参考 <a href="https://www.knowledgedict.com/tutorial/elasticsearch-script.html" target="_blank" rel="noopener">Elasticsearch 脚本模块的详解</a>。</p><h2 id="4-数据结构优化"><a class="markdownIt-Anchor" href="#4-数据结构优化"></a> 4. 数据结构优化</h2><p>基于 Elasticsearch 的使用场景，文档数据结构尽量和使用场景进行结合，去掉没用及不合理的数据。</p><h3 id="41-尽量减少不需要的字段"><a class="markdownIt-Anchor" href="#41-尽量减少不需要的字段"></a> 4.1. 尽量减少不需要的字段</h3><p>如果 Elasticsearch 用于业务搜索服务，一些不需要用于搜索的字段最好不存到 ES 中，这样即节省空间，同时在相同的数据量下，也能提高搜索性能。</p><p>避免使用动态值作字段，动态递增的 mapping，会导致集群崩溃；同样，也需要控制字段的数量，业务中不使用的字段，就不要索引。控制索引的字段数量、mapping 深度、索引字段的类型，对于 ES 的性能优化是重中之重。</p><p>以下是 ES 关于字段数、mapping 深度的一些默认设置：</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">index.mapping.nested_objects.limit:</span> <span class="number">10000</span></span><br><span class="line"><span class="attr">index.mapping.total_fields.limit:</span> <span class="number">1000</span></span><br><span class="line"><span class="attr">index.mapping.depth.limit:</span> <span class="number">20</span></span><br></pre></td></tr></table></figure><h3 id="42-nested-object-vs-parentchild"><a class="markdownIt-Anchor" href="#42-nested-object-vs-parentchild"></a> 4.2. Nested Object vs Parent/Child</h3><p>尽量避免使用 nested 或 parent/child 的字段，能不用就不用；nested query 慢，parent/child query 更慢，比 nested query 慢上百倍；因此能在 mapping 设计阶段搞定的（大宽表设计或采用比较 smart 的数据结构），就不要用父子关系的 mapping。</p><p>如果一定要使用 nested fields，保证 nested fields 字段不能过多，目前 ES 默认限制是 50。因为针对 1 个 document，每一个 nested field，都会生成一个独立的 document，这将使 doc 数量剧增，影响查询效率，尤其是 JOIN 的效率。</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">index.mapping.nested_fields.limit:</span> <span class="number">50</span></span><br></pre></td></tr></table></figure><table><thead><tr><th style="text-align:left">对比</th><th style="text-align:left">Nested Object</th><th style="text-align:left">Parent/Child</th></tr></thead><tbody><tr><td style="text-align:left">优点</td><td style="text-align:left">文档存储在一起，因此读取性高</td><td style="text-align:left">父子文档可以独立更新，互不影响</td></tr><tr><td style="text-align:left">缺点</td><td style="text-align:left">更新父文档或子文档时需要更新整个文档</td><td style="text-align:left">为了维护 join 关系，需要占用部分内存，读取性能较差</td></tr><tr><td style="text-align:left">场景</td><td style="text-align:left">子文档偶尔更新，查询频繁</td><td style="text-align:left">子文档更新频繁</td></tr></tbody></table><h3 id="43-选择静态映射非必需时禁止动态映射"><a class="markdownIt-Anchor" href="#43-选择静态映射非必需时禁止动态映射"></a> 4.3. 选择静态映射，非必需时，禁止动态映射</h3><p>尽量避免使用动态映射，这样有可能会导致集群崩溃，此外，动态映射有可能会带来不可控制的数据类型，进而有可能导致在查询端出现相关异常，影响业务。</p><p>此外，Elasticsearch 作为搜索引擎时，主要承载 query 的匹配和排序的功能，那数据的存储类型基于这两种功能的用途分为两类，一是需要匹配的字段，用来建立倒排索引对 query 匹配用，另一类字段是用做粗排用到的特征字段，如 ctr、点击数、评论数等等。</p><h2 id="5-集群架构设计"><a class="markdownIt-Anchor" href="#5-集群架构设计"></a> 5. 集群架构设计</h2><p>合理的部署 Elasticsearch 有助于提高服务的整体可用性。</p><h3 id="51-主节点-数据节点和协调节点分离"><a class="markdownIt-Anchor" href="#51-主节点-数据节点和协调节点分离"></a> 5.1. 主节点、数据节点和协调节点分离</h3><p>Elasticsearch 集群在架构拓朴时，采用主节点、数据节点和负载均衡节点分离的架构，在 5.x 版本以后，又可将数据节点再细分为“Hot-Warm”的架构模式。</p><p>Elasticsearch 的配置文件中有 2 个参数，node.master 和 node.data。这两个参数搭配使用时，能够帮助提供服务器性能。</p><h4 id="主master节点"><a class="markdownIt-Anchor" href="#主master节点"></a> 主（master）节点</h4><p>配置 <code>node.master:true</code> 和 <code>node.data:false</code>，该 node 服务器只作为一个主节点，但不存储任何索引数据。我们推荐每个集群运行 3 个专用的 master 节点来提供最好的弹性。使用时，你还需要将 <code>discovery.zen.minimum_master_nodes setting</code> 参数设置为 2，以免出现脑裂（split-brain）的情况。用 3 个专用的 master 节点，专门负责处理集群的管理以及加强状态的整体稳定性。因为这 3 个 master 节点不包含数据也不会实际参与搜索以及索引操作，在 JVM 上它们不用做相同的事，例如繁重的索引或者耗时，资源耗费很大的搜索。因此不太可能会因为垃圾回收而导致停顿。因此，master 节点的 CPU，内存以及磁盘配置可以比 data 节点少很多的。</p><h4 id="数据data节点"><a class="markdownIt-Anchor" href="#数据data节点"></a> 数据（data）节点</h4><p>配置 <code>node.master:false</code> 和 <code>node.data:true</code>，该 node 服务器只作为一个数据节点，只用于存储索引数据，使该 node 服务器功能单一，只用于数据存储和数据查询，降低其资源消耗率。</p><p>在 Elasticsearch 5.x 版本之后，data 节点又可再细分为“Hot-Warm”架构，即分为热节点（hot node）和暖节点（warm node）。</p><p>hot 节点：</p><p>hot 节点主要是索引节点（写节点），同时会保存近期的一些频繁被查询的索引。由于进行索引非常耗费 CPU 和 IO，即属于 IO 和 CPU 密集型操作，建议使用 SSD 的磁盘类型，保持良好的写性能；我们推荐部署最小化的 3 个 hot 节点来保证高可用性。根据近期需要收集以及查询的数据量，可以增加服务器数量来获得想要的性能。</p><p>将节点设置为 hot 类型需要 elasticsearch.yml 如下配置：</p><figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line"><span class="keyword">node</span>.<span class="title">attr</span>.box_type: hot</span><br></pre></td></tr></table></figure><p>如果是针对指定的 index 操作，可以通过 settings 设置 <code>index.routing.allocation.require.box_type: hot</code> 将索引写入 hot 节点。</p><p>warm 节点：</p><p>这种类型的节点是为了处理大量的，而且不经常访问的只读索引而设计的。由于这些索引是只读的，warm 节点倾向于挂载大量磁盘（普通磁盘）来替代 SSD。内存、CPU 的配置跟 hot 节点保持一致即可；节点数量一般也是大于等于 3 个。</p><p>将节点设置为 warm 类型需要 elasticsearch.yml 如下配置：</p><figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line"><span class="keyword">node</span>.<span class="title">attr</span>.box_type: warm</span><br></pre></td></tr></table></figure><p>同时，也可以在 elasticsearch.yml 中设置 <code>index.codec:best_compression</code> 保证 warm 节点的压缩配置。</p><p>当索引不再被频繁查询时，可通过 <code>index.routing.allocation.require.box_type:warm</code>，将索引标记为 warm，从而保证索引不写入 hot 节点，以便将 SSD 磁盘资源用在刀刃上。一旦设置这个属性，ES 会自动将索引合并到 warm 节点。</p><h4 id="协调coordinating节点"><a class="markdownIt-Anchor" href="#协调coordinating节点"></a> 协调（coordinating）节点</h4><p>协调节点用于做分布式里的协调，将各分片或节点返回的数据整合后返回。该节点不会被选作主节点，也不会存储任何索引数据。该服务器主要用于查询负载均衡。在查询的时候，通常会涉及到从多个 node 服务器上查询数据，并将请求分发到多个指定的 node 服务器，并对各个 node 服务器返回的结果进行一个汇总处理，最终返回给客户端。在 ES 集群中，所有的节点都有可能是协调节点，但是，可以通过设置 <code>node.master</code>、<code>node.data</code>、<code>node.ingest</code> 都为 <code>false</code> 来设置专门的协调节点。需要较好的 CPU 和较高的内存。</p><ul><li>node.master:false 和 node.data:true，该 node 服务器只作为一个数据节点，只用于存储索引数据，使该 node 服务器功能单一，只用于数据存储和数据查询，降低其资源消耗率。</li><li>node.master:true 和 node.data:false，该 node 服务器只作为一个主节点，但不存储任何索引数据，该 node 服务器将使用自身空闲的资源，来协调各种创建索引请求或者查询请求，并将这些请求合理分发到相关的 node 服务器上。</li><li>node.master:false 和 node.data:false，该 node 服务器即不会被选作主节点，也不会存储任何索引数据。该服务器主要用于查询负载均衡。在查询的时候，通常会涉及到从多个 node 服务器上查询数据，并将请求分发到多个指定的 node 服务器，并对各个 node 服务器返回的结果进行一个汇总处理，最终返回给客户端。</li></ul><h3 id="52-关闭-data-节点服务器中的-http-功能"><a class="markdownIt-Anchor" href="#52-关闭-data-节点服务器中的-http-功能"></a> 5.2. 关闭 data 节点服务器中的 http 功能</h3><p>针对 Elasticsearch 集群中的所有数据节点，不用开启 http 服务。将其中的配置参数这样设置，<code>http.enabled:false</code>，同时也不要安装 head, bigdesk, marvel 等监控插件，这样保证 data 节点服务器只需处理创建/更新/删除/查询索引数据等操作。</p><p>http 功能可以在非数据节点服务器上开启，上述相关的监控插件也安装到这些服务器上，用于监控 Elasticsearch 集群状态等数据信息。这样做一来出于数据安全考虑，二来出于服务性能考虑。</p><h3 id="53-一台服务器上最好只部署一个-node"><a class="markdownIt-Anchor" href="#53-一台服务器上最好只部署一个-node"></a> 5.3. 一台服务器上最好只部署一个 node</h3><p>一台物理服务器上可以启动多个 node 服务器节点（通过设置不同的启动 port），但一台服务器上的 CPU、内存、硬盘等资源毕竟有限，从服务器性能考虑，不建议一台服务器上启动多个 node 节点。</p><h3 id="54-集群分片设置"><a class="markdownIt-Anchor" href="#54-集群分片设置"></a> 5.4. 集群分片设置</h3><p>ES 一旦创建好索引后，就无法调整分片的设置，而在 ES 中，一个分片实际上对应一个 lucene 索引，而 lucene 索引的读写会占用很多的系统资源，因此，分片数不能设置过大；所以，在创建索引时，合理配置分片数是非常重要的。一般来说，我们遵循一些原则：</p><ol><li>控制每个分片占用的硬盘容量不超过 ES 的最大 JVM 的堆空间设置（一般设置不超过 32 G，参考上面的 JVM 内存设置原则），因此，如果索引的总容量在 500 G 左右，那分片大小在 16 个左右即可；当然，最好同时考虑原则 2。</li><li>考虑一下 node 数量，一般一个节点有时候就是一台物理机，如果分片数过多，大大超过了节点数，很可能会导致一个节点上存在多个分片，一旦该节点故障，即使保持了 1 个以上的副本，同样有可能会导致数据丢失，集群无法恢复。所以，<strong>一般都设置分片数不超过节点数的 3 倍</strong>。</li></ol><h2 id="6-参考资料"><a class="markdownIt-Anchor" href="#6-参考资料"></a> 6. 参考资料</h2><ul><li><a href="https://www.knowledgedict.com/tutorial/elasticsearch-intro.html" target="_blank" rel="noopener">Elasticsearch 教程</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;elasticsearch-性能优化&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#elasticsearch-性能优化&quot;&gt;&lt;/a&gt; Elasticsearch 性能优化&lt;/h1&gt;
&lt;p&gt;Elasticsearch 是当前流行的企业级搜
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/Elasticsearch/"/>
    
    
      <category term="性能" scheme="https://dunwu.github.io/blog/tags/%E6%80%A7%E8%83%BD/"/>
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch 排序</title>
    <link href="https://dunwu.github.io/blog/2022/01/19/elasticsearch-%E6%8E%92%E5%BA%8F/"/>
    <id>https://dunwu.github.io/blog/2022/01/19/elasticsearch-%E6%8E%92%E5%BA%8F/</id>
    <published>2022-01-19T14:49:16.000Z</published>
    <updated>2022-04-14T08:45:53.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="elasticsearch-排序"><a class="markdownIt-Anchor" href="#elasticsearch-排序"></a> Elasticsearch 排序</h1><p>在 Elasticsearch 中，默认排序是<strong>按照相关性的评分（_score）<strong>进行降序排序，也可以按照</strong>字段的值排序</strong>、<strong>多级排序</strong>、<strong>多值字段排序、基于 geo（地理位置）排序以及自定义脚本排序</strong>，除此之外，对于相关性的评分也可以用 rescore 二次、三次打分，它可以限定重新打分的窗口大小（window size），并针对作用范围内的文档修改其得分，从而达到精细化控制结果相关性的目的。</p><h2 id="1-默认相关性排序"><a class="markdownIt-Anchor" href="#1-默认相关性排序"></a> 1. 默认相关性排序</h2><p>在 Elasticsearch 中，默认情况下，文档是按照相关性得分倒序排列的，其对应的相关性得分字段用 <code>_score</code> 来表示，它是浮点数类型，<code>_score</code> 评分越高，相关性越高。评分模型的选择可以通过 <code>similarity</code> 参数在映射中指定。</p><p>相似度算法可以按字段指定，只需在映射中为不同字段选定即可，如果要修改已有字段的相似度算法，只能通过为数据重新建立索引来达到目的。关于更多 es 相似度算法可以参考 <a href="https://www.knowledgedict.com/tutorial/elasticsearch-similarity.html" target="_blank" rel="noopener">深入理解 es 相似度算法（相关性得分计算）</a>。</p><h3 id="11-tf-idf-模型"><a class="markdownIt-Anchor" href="#11-tf-idf-模型"></a> 1.1. TF-IDF 模型</h3><p>Elasticsearch 在 5.4 版本以前，text 类型的字段，默认采用基于 tf-idf 的向量空间模型。</p><p>在开始计算得分之时，Elasticsearch 使用了被搜索词条的频率以及它有多常见来影响得分。一个简短的解释是，<strong>一个词条出现在某个文档中的次数越多，它就越相关；但是，如果该词条出现在不同的文档的次数越多，它就越不相关</strong>。这一点被称为 TF-IDF，TF 是<strong>词频</strong>（term frequency），IDF 是<strong>逆文档频率</strong>（inverse document frequency）。</p><p>考虑给一篇文档打分的首要方式，是统计一个词条在文本中出现的次数。举个例子，如果在用户的区域搜索关于 Elasticsearch 的 get-together，用户希望频繁提及 Elasticsearch 的分组被优先展示出来。</p><figure class="highlight smalltalk"><table><tr><td class="code"><pre><span class="line"><span class="comment">"We will discuss Elasticsearch at the next Big Data group."</span></span><br><span class="line"><span class="comment">"Tuesday the Elasticsearch team will gather to answer questions about Elasticsearch."</span></span><br></pre></td></tr></table></figure><p>第一个句子提到 Elasticsearch 一次，而第二个句子提到 Elasticsearch 两次，所以包含第二句话的文档应该比包含第一句话的文档拥有更高的得分。如果我们要按照数量来讨论，第一句话的词频（TF）是 1，而第二句话的词频将是 2。</p><p>逆文档频率比文档词频稍微复杂一点。这个听上去很酷炫的描述意味着，如果一个分词（通常是单词，但不一定是）在索引的不同文档中出现越多的次数，那么它就越不重要。使用如下例子更容易解释这一点。</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">"We <span class="keyword">use</span> Elasticsearch <span class="keyword">to</span> <span class="keyword">power</span> the <span class="keyword">search</span> <span class="keyword">for</span> our website.<span class="string">"</span></span><br><span class="line"><span class="string">"</span>The developers <span class="keyword">like</span> Elasticsearch so far.<span class="string">"</span></span><br><span class="line"><span class="string">"</span>The scoring <span class="keyword">of</span> documents <span class="keyword">is</span> calculated <span class="keyword">by</span> the scoring formula.<span class="string">"</span></span><br></pre></td></tr></table></figure><p>如上述例子，需要理解以下几点：</p><ul><li>词条 “Elasticsearch” 的文档频率是 2（因为它出现在两篇文档中）。文档频率的逆源自得分乘以 1/DF，这里 DF 是该词条的文档频率。这就意味着，由于词条拥有更高的文档频率，它的权重就会降低。</li><li>词条 “the” 的文档频率是 3，因为它出现在所有的三篇文档中。请注意，尽管 “the” 在最后一篇文档中出现了两次，它的文档频率还是 3。这是因为，逆文档频率只检查一个词条是否出现在某文档中，而不检查它出现多少次。那个应该是词频所关心的事情。</li></ul><p>逆文档频率是一个重要的因素，用于平衡词条的词频。举个例子，考虑有一个用户搜索词条 “the score”，单词 the 几乎出现在每个普通的英语文本中，如果它不被均衡一下，单词 the 的频率要完全淹没单词 score 的频率。逆文档频率 IDF 均衡了 the 这种常见词的相关性影响，所以实际的相关性得分将会对查询的词条有一个更准确的描述。</p><p>一旦词频 TF 和逆文档频率 IDF 计算完成，就可以使用 TF-IDF 公式来计算文档的得分。</p><h3 id="12-bm25-模型"><a class="markdownIt-Anchor" href="#12-bm25-模型"></a> 1.2. BM25 模型</h3><p>Elasticsearch 在 5.4 版本之后，针对 text 类型的字段，默认采用的是 BM25 评分模型，而不是基于 tf-idf 的向量空间模型，评分模型的选择可以通过 <code>similarity</code> 参数在映射中指定。</p><h2 id="2-字段的值排序"><a class="markdownIt-Anchor" href="#2-字段的值排序"></a> 2. 字段的值排序</h2><p>在 Elasticsearch 中按照字段的值排序，可以利用 <code>sort</code> 参数实现。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET books/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"sort"</span>: &#123;</span><br><span class="line">    <span class="string">"price"</span>: &#123;</span><br><span class="line">      <span class="string">"order"</span>: <span class="string">"desc"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>返回结果如下：</p><figure class="highlight"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"took"</span>: <span class="number">132</span>,</span><br><span class="line">  <span class="attr">"timed_out"</span>: <span class="literal">false</span>,</span><br><span class="line">  <span class="attr">"_shards"</span>: &#123;</span><br><span class="line">    <span class="attr">"total"</span>: <span class="number">10</span>,</span><br><span class="line">    <span class="attr">"successful"</span>: <span class="number">10</span>,</span><br><span class="line">    <span class="attr">"skipped"</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="attr">"failed"</span>: <span class="number">0</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"hits"</span>: &#123;</span><br><span class="line">    <span class="attr">"total"</span>: <span class="number">749244</span>,</span><br><span class="line">    <span class="attr">"max_score"</span>: <span class="literal">null</span>,</span><br><span class="line">    <span class="attr">"hits"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"_index"</span>: <span class="string">"books"</span>,</span><br><span class="line">        <span class="attr">"_type"</span>: <span class="string">"book"</span>,</span><br><span class="line">        <span class="attr">"_id"</span>: <span class="string">"8456479"</span>,</span><br><span class="line">        <span class="attr">"_score"</span>: <span class="literal">null</span>,</span><br><span class="line">        <span class="attr">"_source"</span>: &#123;</span><br><span class="line">          <span class="attr">"id"</span>: <span class="number">8456479</span>,</span><br><span class="line">          <span class="attr">"price"</span>: <span class="number">1580.00</span>,</span><br><span class="line">          ...</span><br><span class="line">        &#125;,</span><br><span class="line">        "sort": [</span><br><span class="line">          <span class="number">1580.00</span></span><br><span class="line">        ]</span><br><span class="line">      &#125;,</span><br><span class="line">      ...</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从如上返回结果，可以看出，<code>max_score</code> 和 <code>_score</code> 字段都返回 <code>null</code>，返回字段多出 <code>sort</code> 字段，包含排序字段的分值。计算 _<code>score</code> 的花销巨大，如果不根据相关性排序，记录 _<code>score</code> 是没有意义的。如果无论如何都要计算 _<code>score</code>，可以将 <code>track_scores</code> 参数设置为 <code>true</code>。</p><h2 id="3-多字段排序"><a class="markdownIt-Anchor" href="#3-多字段排序"></a> 3. 多字段排序</h2><p>如果我们想要结合使用 price、date 和 _score 进行查询，并且匹配的结果首先按照价格排序，然后按照日期排序，最后按照相关性排序，具体示例如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET books/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"bool"</span>: &#123;</span><br><span class="line"><span class="string">"must"</span>: &#123;</span><br><span class="line"><span class="string">"match"</span>: &#123; <span class="string">"content"</span>: <span class="string">"java"</span> &#125;</span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"filter"</span>: &#123;</span><br><span class="line"><span class="string">"term"</span>: &#123; <span class="string">"user_id"</span>: 4868438 &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"sort"</span>: [&#123;</span><br><span class="line"><span class="string">"price"</span>: &#123;</span><br><span class="line"><span class="string">"order"</span>: <span class="string">"desc"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;, &#123;</span><br><span class="line"><span class="string">"date"</span>: &#123;</span><br><span class="line"><span class="string">"order"</span>: <span class="string">"desc"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;, &#123;</span><br><span class="line"><span class="string">"_score"</span>: &#123;</span><br><span class="line"><span class="string">"order"</span>: <span class="string">"desc"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>排序条件的顺序是很重要的。结果首先按第一个条件排序，仅当结果集的第一个 <code>sort</code> 值完全相同时才会按照第二个条件进行排序，以此类推。</p><p>多级排序并不一定包含 <code>_score</code>。你可以根据一些不同的字段进行排序，如地理距离或是脚本计算的特定值。</p><h2 id="4-多值字段的排序"><a class="markdownIt-Anchor" href="#4-多值字段的排序"></a> 4. 多值字段的排序</h2><p>一种情形是字段有多个值的排序，需要记住这些值并没有固有的顺序；一个多值的字段仅仅是多个值的包装，这时应该选择哪个进行排序呢？</p><p>对于数字或日期，你可以将多值字段减为单值，这可以通过使用 <code>min</code>、<code>max</code>、<code>avg</code> 或是 <code>sum</code> 排序模式。例如你可以按照每个 date 字段中的最早日期进行排序，通过以下方法：</p><figure class="highlight"><table><tr><td class="code"><pre><span class="line">"sort": &#123;</span><br><span class="line">  "dates": &#123;</span><br><span class="line">    "order": "asc",</span><br><span class="line">    "mode":  "min"</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="5-地理位置上的距离排序"><a class="markdownIt-Anchor" href="#5-地理位置上的距离排序"></a> 5. 地理位置上的距离排序</h2><p>es 的地理位置排序使用 <strong><code>_geo_distance</code></strong> 来进行距离排序，如下示例：</p><figure class="highlight"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"sort"</span> : [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"_geo_distance"</span> : &#123;</span><br><span class="line">        <span class="attr">"es_location_field"</span> : [<span class="number">116.407526</span>, <span class="number">39.904030</span>],</span><br><span class="line">        <span class="attr">"order"</span> : <span class="string">"asc"</span>,</span><br><span class="line">        <span class="attr">"unit"</span> : <span class="string">"km"</span>,</span><br><span class="line">        <span class="attr">"mode"</span> : <span class="string">"min"</span>,</span><br><span class="line">        <span class="attr">"distance_type"</span> : <span class="string">"plane"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"query"</span> : &#123;</span><br><span class="line">    ......</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><em>_geo_distance</em> 的选项具体如下：</p><ul><li>如上的 <em>es_location_field</em> 指的是 es 存储经纬度数据的字段名。</li><li><strong><em><code>order</code></em></strong>：指定按距离升序或降序，分别对应 <strong><em><code>asc</code></em></strong> 和 <strong><em><code>desc</code></em></strong>。</li><li><strong><em><code>unit</code></em></strong>：计算距离值的单位，默认是 <strong><em><code>m</code></em></strong>，表示米（meters），其它可选项有 <strong><em><code>mi</code></em></strong>、<strong><em><code>cm</code></em></strong>、<strong><em><code>mm</code></em></strong>、<strong><em><code>NM</code></em></strong>、<strong><em><code>km</code></em></strong>、<strong><em><code>ft</code></em></strong>、<strong><em><code>yd</code></em></strong> 和 <strong><em><code>in</code></em></strong>。</li><li><strong><em><code>mode</code></em></strong>：针对数组数据（多个值）时，指定的取值模式，可选值有 <strong><em><code>min</code></em></strong>、<strong><em><code>max</code></em></strong>、<strong><em><code>sum</code></em></strong>、<strong><em><code>avg</code></em></strong> 和 <strong><em><code>median</code></em></strong>，当排序采用升序时，默认为 <em>min</em>；排序采用降序时，默认为 <em>max</em>。</li><li><strong><em><code>distance_type</code></em></strong>：用来设置如何计算距离，它的可选项有 <strong><em><code>sloppy_arc</code></em></strong>、<strong><em><code>arc</code></em></strong> 和 <strong><em><code>plane</code></em></strong>，默认为 <em>sloppy_arc</em>，<em>arc</em> 它相对更精确些，但速度会明显下降，<em>plane</em> 则是计算快，但是长距离计算相对不准确。</li><li><strong><em><code>ignore_unmapped</code></em></strong>：未映射字段时，是否忽略处理，可选项有 <strong><em><code>true</code></em></strong> 和 <strong><em><code>false</code></em></strong>；默认为 <em>false</em>，表示如果未映射字段，查询将引发异常；若设置 <em>true</em>，将忽略未映射的字段，并且不匹配此查询的任何文档。</li><li><strong><em><code>validation_method</code></em></strong>：指定检验经纬度数据的方式，可选项有 <strong><em><code>IGNORE_MALFORMED</code></em></strong>、<strong><em><code>COERCE</code></em></strong> 和 <strong><em><code>STRICT</code></em></strong>；<em>IGNORE_MALFORMED</em> 表示可接受纬度或经度无效的地理点，即忽略数据；<em>COERCE</em> 表示另外尝试并推断正确的地理坐标；<em>STRICT</em> 为默认值，表示遇到不正确的地理坐标直接抛出异常。</li></ul><h2 id="6-参考资料"><a class="markdownIt-Anchor" href="#6-参考资料"></a> 6. 参考资料</h2><ul><li><a href="https://www.knowledgedict.com/tutorial/elasticsearch-intro.html" target="_blank" rel="noopener">Elasticsearch 教程</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;elasticsearch-排序&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#elasticsearch-排序&quot;&gt;&lt;/a&gt; Elasticsearch 排序&lt;/h1&gt;
&lt;p&gt;在 Elasticsearch 中，默认排序是&lt;strong
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/Elasticsearch/"/>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/tags/Elasticsearch/"/>
    
      <category term="排序" scheme="https://dunwu.github.io/blog/tags/%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch 聚合</title>
    <link href="https://dunwu.github.io/blog/2022/01/19/elasticsearch-%E8%81%9A%E5%90%88/"/>
    <id>https://dunwu.github.io/blog/2022/01/19/elasticsearch-%E8%81%9A%E5%90%88/</id>
    <published>2022-01-19T14:49:16.000Z</published>
    <updated>2022-04-14T08:45:53.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="elasticsearch-聚合"><a class="markdownIt-Anchor" href="#elasticsearch-聚合"></a> Elasticsearch 聚合</h1><p>Elasticsearch 是一个分布式的全文搜索引擎，索引和搜索是 Elasticsearch 的基本功能。事实上，Elasticsearch 的聚合（Aggregations）功能也十分强大，允许在数据上做复杂的分析统计。Elasticsearch 提供的聚合分析功能主要有<strong>指标聚合(metrics aggregations)</strong>、<strong>桶聚合(bucket aggregations)</strong>、<strong>管道聚合(pipeline aggregations)</strong> 和 <strong>矩阵聚合(matrix aggregations)</strong> 四大类，管道聚合和矩阵聚合官方说明是在试验阶段，后期会完全更改或者移除，这里不再对管道聚合和矩阵聚合进行讲解。</p><!-- TOC depthFrom:2 depthTo:3 --><ul><li><a href="#1-%E8%81%9A%E5%90%88%E7%9A%84%E5%85%B7%E4%BD%93%E7%BB%93%E6%9E%84">1. 聚合的具体结构</a></li><li><a href="#2-%E6%8C%87%E6%A0%87%E8%81%9A%E5%90%88">2. 指标聚合</a><ul><li><a href="#21-max-aggregation">2.1. Max Aggregation</a></li><li><a href="#22-min-aggregation">2.2. Min Aggregation</a></li><li><a href="#23-avg-aggregation">2.3. Avg Aggregation</a></li><li><a href="#24-sum-aggregation">2.4. Sum Aggregation</a></li><li><a href="#25-value-count-aggregation">2.5. Value Count Aggregation</a></li><li><a href="#26-cardinality-aggregation">2.6. Cardinality Aggregation</a></li><li><a href="#27-stats-aggregation">2.7. Stats Aggregation</a></li><li><a href="#28-extended-stats-aggregation">2.8. Extended Stats Aggregation</a></li><li><a href="#29-percentiles-aggregation">2.9. Percentiles Aggregation</a></li><li><a href="#210-percentiles-ranks-aggregation">2.10. Percentiles Ranks Aggregation</a></li></ul></li><li><a href="#3-%E6%A1%B6%E8%81%9A%E5%90%88">3. 桶聚合</a><ul><li><a href="#31-terms-aggregation">3.1. Terms Aggregation</a></li><li><a href="#32-filter-aggregation">3.2. Filter Aggregation</a></li><li><a href="#33-filters-aggregation">3.3. Filters Aggregation</a></li><li><a href="#34-range-aggregation">3.4. Range Aggregation</a></li></ul></li><li><a href="#4-%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">4. 参考资料</a></li></ul><!-- /TOC --><h2 id="1-聚合的具体结构"><a class="markdownIt-Anchor" href="#1-聚合的具体结构"></a> 1. 聚合的具体结构</h2><p>所有的聚合，无论它们是什么类型，都遵从以下的规则。</p><ul><li>使用查询中同样的 JSON 请求来定义它们，而且你是使用键 aggregations 或者是 aggs 来进行标记。需要给每个聚合起一个名字，指定它的类型以及和该类型相关的选项。</li><li>它们运行在查询的结果之上。和查询不匹配的文档不会计算在内，除非你使用 global 聚集将不匹配的文档囊括其中。</li><li>可以进一步过滤查询的结果，而不影响聚集。</li></ul><p>以下是聚合的基本结构：</p><figure class="highlight"><table><tr><td class="code"><pre><span class="line">"aggregations" : &#123; &lt;!-- 最外层的聚合键，也可以缩写为 aggs --&gt;</span><br><span class="line">    "&lt;aggregation_name&gt;" : &#123; &lt;!-- 聚合的自定义名字 --&gt;</span><br><span class="line">        "&lt;aggregation_type&gt;" : &#123; &lt;!-- 聚合的类型，指标相关的，如 max、min、avg、sum，桶相关的 terms、filter 等 --&gt;</span><br><span class="line">            &lt;aggregation_body&gt; &lt;!-- 聚合体：对哪些字段进行聚合，可以取字段的值，也可以是脚本计算的结果 --&gt;</span><br><span class="line">        &#125;</span><br><span class="line">        [,"meta" : &#123;  [&lt;meta_data_body&gt;] &#125; ]? &lt;!-- 元 --&gt;</span><br><span class="line">        [,"aggregations" : &#123; [&lt;sub_aggregation&gt;]+ &#125; ]? &lt;!-- 在聚合里面在定义子聚合 --&gt;</span><br><span class="line">    &#125;</span><br><span class="line">    [,"&lt;aggregation_name_2&gt;" : &#123; ... &#125; ]* &lt;!-- 聚合的自定义名字 2 --&gt;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>在最上层有一个 aggregations 的键，可以缩写为 aggs</strong>。</li><li>在下面一层，需要为聚合指定一个名字。可以在请求的返回中看到这个名字。在同一个请求中使用多个聚合时，这一点非常有用，它让你可以很容易地理解每组结果的含义。</li><li>最后，必须要指定聚合的类型。</li></ul><blockquote><p>关于聚合分析的值来源，可以<strong>取字段的值</strong>，也可以是<strong>脚本计算的结果</strong>。</p><p>但是用脚本计算的结果时，需要注意脚本的性能和安全性；尽管多数聚集类型允许使用脚本，但是脚本使得聚集变得缓慢，因为脚本必须在每篇文档上运行。为了避免脚本的运行，可以在索引阶段进行计算。</p><p>此外，脚本也可以被人可能利用进行恶意代码攻击，尽量使用沙盒（sandbox）内的脚本语言。</p></blockquote><p>示例：查询所有球员的平均年龄是多少，并对球员的平均薪水加 188（也可以理解为每名球员加 188 后的平均薪水）。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST /player/_search?size=0</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"aggs"</span>: &#123;</span><br><span class="line">    <span class="string">"avg_age"</span>: &#123;</span><br><span class="line">      <span class="string">"avg"</span>: &#123;</span><br><span class="line">        <span class="string">"field"</span>: <span class="string">"age"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"avg_salary_188"</span>: &#123;</span><br><span class="line">      <span class="string">"avg"</span>: &#123;</span><br><span class="line">        <span class="string">"script"</span>: &#123;</span><br><span class="line">          <span class="string">"source"</span>: <span class="string">"doc.salary.value + 188"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-指标聚合"><a class="markdownIt-Anchor" href="#2-指标聚合"></a> 2. 指标聚合</h2><p>指标聚合（又称度量聚合）主要从不同文档的分组中提取统计数据，或者，从来自其他聚合的文档桶来提取统计数据。</p><p>这些统计数据通常来自数值型字段，如最小或者平均价格。用户可以单独获取每项统计数据，或者也可以使用 stats 聚合来同时获取它们。更高级的统计数据，如平方和或者是标准差，可以通过 extended stats 聚合来获取。</p><h3 id="21-max-aggregation"><a class="markdownIt-Anchor" href="#21-max-aggregation"></a> 2.1. Max Aggregation</h3><p>Max Aggregation 用于最大值统计。例如，统计 sales 索引中价格最高的是哪本书，并且计算出对应的价格的 2 倍值，查询语句如下：</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> /sales/_search?<span class="attribute">size</span>=0</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"aggs"</span> : &#123;</span><br><span class="line">    <span class="string">"max_price"</span> : &#123;</span><br><span class="line">      <span class="string">"max"</span> : &#123;</span><br><span class="line">        <span class="string">"field"</span> : <span class="string">"price"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"max_price_2"</span> : &#123;</span><br><span class="line">      <span class="string">"max"</span> : &#123;</span><br><span class="line">        <span class="string">"field"</span> : <span class="string">"price"</span>,</span><br><span class="line">        <span class="string">"script"</span>: &#123;</span><br><span class="line">          <span class="string">"source"</span>: <span class="string">"_value * 2.0"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>指定的 field，在脚本中可以用 _value 取字段的值</strong>。</p><p>聚合结果如下：</p><figure class="highlight clojure"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">"aggregations"</span>: &#123;</span><br><span class="line">    <span class="string">"max_price"</span>: &#123;</span><br><span class="line">      <span class="string">"value"</span>: <span class="number">188.0</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"max_price_2"</span>: &#123;</span><br><span class="line">      <span class="string">"value"</span>: <span class="number">376.0</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="22-min-aggregation"><a class="markdownIt-Anchor" href="#22-min-aggregation"></a> 2.2. Min Aggregation</h3><p>Min Aggregation 用于最小值统计。例如，统计 sales 索引中价格最低的是哪本书，查询语句如下：</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> /sales/_search?<span class="attribute">size</span>=0</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"aggs"</span> : &#123;</span><br><span class="line">    <span class="string">"min_price"</span> : &#123;</span><br><span class="line">      <span class="string">"min"</span> : &#123;</span><br><span class="line">        <span class="string">"field"</span> : <span class="string">"price"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>聚合结果如下：</p><figure class="highlight clojure"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">"aggregations"</span>: &#123;</span><br><span class="line">    <span class="string">"min_price"</span>: &#123;</span><br><span class="line">      <span class="string">"value"</span>: <span class="number">18.0</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="23-avg-aggregation"><a class="markdownIt-Anchor" href="#23-avg-aggregation"></a> 2.3. Avg Aggregation</h3><p>Avg Aggregation 用于计算平均值。例如，统计 exams 索引中考试的平均分数，如未存在分数，默认为 60 分，查询语句如下：</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> /exams/_search?<span class="attribute">size</span>=0</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"aggs"</span> : &#123;</span><br><span class="line">    <span class="string">"avg_grade"</span> : &#123;</span><br><span class="line">      <span class="string">"avg"</span> : &#123;</span><br><span class="line">        <span class="string">"field"</span> : <span class="string">"grade"</span>,</span><br><span class="line">        <span class="string">"missing"</span>: 60</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>如果指定字段没有值，可以通过 missing 指定默认值；若未指定默认值，缺失该字段值的文档将被忽略（计算）</strong>。</p><p>聚合结果如下：</p><figure class="highlight clojure"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">"aggregations"</span>: &#123;</span><br><span class="line">    <span class="string">"avg_grade"</span>: &#123;</span><br><span class="line">      <span class="string">"value"</span>: <span class="number">78.0</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>除了常规的平均值聚合计算外，elasticsearch 还提供了加权平均值的聚合计算，详情参见 <a href="https://www.knowledgedict.com/tutorial/elasticsearch-aggregations-metrics-weighted-avg-aggregation.html" target="_blank" rel="noopener">Elasticsearch 指标聚合之 Weighted Avg Aggregation</a>。</p><h3 id="24-sum-aggregation"><a class="markdownIt-Anchor" href="#24-sum-aggregation"></a> 2.4. Sum Aggregation</h3><p>Sum Aggregation 用于计算总和。例如，统计 sales 索引中 type 字段中匹配 hat 的价格总和，查询语句如下：</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> /exams/_search?<span class="attribute">size</span>=0</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span> : &#123;</span><br><span class="line">    <span class="string">"constant_score"</span> : &#123;</span><br><span class="line">      <span class="string">"filter"</span> : &#123;</span><br><span class="line">        <span class="string">"match"</span> : &#123; <span class="string">"type"</span> : <span class="string">"hat"</span> &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"aggs"</span> : &#123;</span><br><span class="line">    <span class="string">"hat_prices"</span> : &#123;</span><br><span class="line">      <span class="string">"sum"</span> : &#123; <span class="string">"field"</span> : <span class="string">"price"</span> &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>聚合结果如下：</p><figure class="highlight clojure"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">"aggregations"</span>: &#123;</span><br><span class="line">    <span class="string">"hat_prices"</span>: &#123;</span><br><span class="line">      <span class="string">"value"</span>: <span class="number">567.0</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="25-value-count-aggregation"><a class="markdownIt-Anchor" href="#25-value-count-aggregation"></a> 2.5. Value Count Aggregation</h3><p>Value Count Aggregation 可按字段统计文档数量。例如，统计 books 索引中包含 author 字段的文档数量，查询语句如下：</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> /books/_search?<span class="attribute">size</span>=0</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"aggs"</span> : &#123;</span><br><span class="line">    <span class="string">"doc_count"</span> : &#123;</span><br><span class="line">      <span class="string">"value_count"</span> : &#123; <span class="string">"field"</span> : <span class="string">"author"</span> &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>聚合结果如下：</p><figure class="highlight clojure"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">"aggregations"</span>: &#123;</span><br><span class="line">    <span class="string">"doc_count"</span>: &#123;</span><br><span class="line">      <span class="string">"value"</span>: <span class="number">5</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="26-cardinality-aggregation"><a class="markdownIt-Anchor" href="#26-cardinality-aggregation"></a> 2.6. Cardinality Aggregation</h3><p>Cardinality Aggregation 用于基数统计，其作用是先执行类似 SQL 中的 distinct 操作，去掉集合中的重复项，然后统计去重后的集合长度。例如，在 books 索引中对 language 字段进行 cardinality 操作可以统计出编程语言的种类数，查询语句如下：</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> /books/_search?<span class="attribute">size</span>=0</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"aggs"</span> : &#123;</span><br><span class="line">    <span class="string">"all_lan"</span> : &#123;</span><br><span class="line">      <span class="string">"cardinality"</span> : &#123; <span class="string">"field"</span> : <span class="string">"language"</span> &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"title_cnt"</span> : &#123;</span><br><span class="line">      <span class="string">"cardinality"</span> : &#123; <span class="string">"field"</span> : <span class="string">"title.keyword"</span> &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>假设 title 字段为文本类型（text），去重时需要指定 keyword，表示把 title 作为整体去重，即不分词统计</strong>。</p><p>聚合结果如下：</p><figure class="highlight clojure"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">"aggregations"</span>: &#123;</span><br><span class="line">    <span class="string">"all_lan"</span>: &#123;</span><br><span class="line">      <span class="string">"value"</span>: <span class="number">8</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"title_cnt"</span>: &#123;</span><br><span class="line">      <span class="string">"value"</span>: <span class="number">18</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="27-stats-aggregation"><a class="markdownIt-Anchor" href="#27-stats-aggregation"></a> 2.7. Stats Aggregation</h3><p>Stats Aggregation 用于基本统计，会一次返回 count、max、min、avg 和 sum 这 5 个指标。例如，在 exams 索引中对 grade 字段进行分数相关的基本统计，查询语句如下：</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> /exams/_search?<span class="attribute">size</span>=0</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"aggs"</span> : &#123;</span><br><span class="line">    <span class="string">"grades_stats"</span> : &#123;</span><br><span class="line">      <span class="string">"stats"</span> : &#123; <span class="string">"field"</span> : <span class="string">"grade"</span> &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>聚合结果如下：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&#123;</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line">  <span class="attr">"aggregations":</span> <span class="string">&#123;</span></span><br><span class="line">    <span class="attr">"grades_stats":</span> <span class="string">&#123;</span></span><br><span class="line">      <span class="attr">"count":</span> <span class="number">2</span><span class="string">,</span></span><br><span class="line">      <span class="attr">"min":</span> <span class="number">50.0</span><span class="string">,</span></span><br><span class="line">      <span class="attr">"max":</span> <span class="number">100.0</span><span class="string">,</span></span><br><span class="line">      <span class="attr">"avg":</span> <span class="number">75.0</span><span class="string">,</span></span><br><span class="line">      <span class="attr">"sum":</span> <span class="number">150.0</span></span><br><span class="line">    <span class="string">&#125;</span></span><br><span class="line">  <span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="28-extended-stats-aggregation"><a class="markdownIt-Anchor" href="#28-extended-stats-aggregation"></a> 2.8. Extended Stats Aggregation</h3><p>Extended Stats Aggregation 用于高级统计，和基本统计功能类似，但是会比基本统计多出以下几个统计结果，sum_of_squares（平方和）、variance（方差）、std_deviation（标准差）、std_deviation_bounds（平均值加/减两个标准差的区间）。在 exams 索引中对 grade 字段进行分数相关的高级统计，查询语句如下：</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> /exams/_search?<span class="attribute">size</span>=0</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"aggs"</span> : &#123;</span><br><span class="line">    <span class="string">"grades_stats"</span> : &#123;</span><br><span class="line">      <span class="string">"extended_stats"</span> : &#123; <span class="string">"field"</span> : <span class="string">"grade"</span> &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>聚合结果如下：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&#123;</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line">  <span class="attr">"aggregations":</span> <span class="string">&#123;</span></span><br><span class="line">    <span class="attr">"grades_stats":</span> <span class="string">&#123;</span></span><br><span class="line">      <span class="attr">"count":</span> <span class="number">2</span><span class="string">,</span></span><br><span class="line">      <span class="attr">"min":</span> <span class="number">50.0</span><span class="string">,</span></span><br><span class="line">      <span class="attr">"max":</span> <span class="number">100.0</span><span class="string">,</span></span><br><span class="line">      <span class="attr">"avg":</span> <span class="number">75.0</span><span class="string">,</span></span><br><span class="line">      <span class="attr">"sum":</span> <span class="number">150.0</span><span class="string">,</span></span><br><span class="line">      <span class="attr">"sum_of_squares":</span> <span class="number">12500.0</span><span class="string">,</span></span><br><span class="line">      <span class="attr">"variance":</span> <span class="number">625.0</span><span class="string">,</span></span><br><span class="line">      <span class="attr">"std_deviation":</span> <span class="number">25.0</span><span class="string">,</span></span><br><span class="line">      <span class="attr">"std_deviation_bounds":</span> <span class="string">&#123;</span></span><br><span class="line">        <span class="attr">"upper":</span> <span class="number">125.0</span><span class="string">,</span></span><br><span class="line">        <span class="attr">"lower":</span> <span class="number">25.0</span></span><br><span class="line">      <span class="string">&#125;</span></span><br><span class="line">    <span class="string">&#125;</span></span><br><span class="line">  <span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="29-percentiles-aggregation"><a class="markdownIt-Anchor" href="#29-percentiles-aggregation"></a> 2.9. Percentiles Aggregation</h3><p>Percentiles Aggregation 用于百分位统计。百分位数是一个统计学术语，如果将一组数据从大到小排序，并计算相应的累计百分位，某一百分位所对应数据的值就称为这一百分位的百分位数。默认情况下，累计百分位为 [ 1, 5, 25, 50, 75, 95, 99 ]。以下例子给出了在 latency 索引中对 load_time 字段进行加载时间的百分位统计，查询语句如下：</p><figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">GET latency/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="string">"aggs"</span> : &#123;</span><br><span class="line">    <span class="string">"load_time_outlier"</span> : &#123;</span><br><span class="line">      <span class="string">"percentiles"</span> : &#123;</span><br><span class="line">        <span class="string">"field"</span> : "<span class="type">load_time</span><span class="string">"</span></span><br><span class="line"><span class="string">      &#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><p><strong>需要注意的是，如上的 <code>load_time</code> 字段必须是数字类型</strong>。</p><p>聚合结果如下：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&#123;</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line">  <span class="attr">"aggregations":</span> <span class="string">&#123;</span></span><br><span class="line">    <span class="attr">"load_time_outlier":</span> <span class="string">&#123;</span></span><br><span class="line">      <span class="string">"values"</span> <span class="string">:</span> <span class="string">&#123;</span></span><br><span class="line">        <span class="attr">"1.0":</span> <span class="number">5.0</span><span class="string">,</span></span><br><span class="line">        <span class="attr">"5.0":</span> <span class="number">25.0</span><span class="string">,</span></span><br><span class="line">        <span class="attr">"25.0":</span> <span class="number">165.0</span><span class="string">,</span></span><br><span class="line">        <span class="attr">"50.0":</span> <span class="number">445.0</span><span class="string">,</span></span><br><span class="line">        <span class="attr">"75.0":</span> <span class="number">725.0</span><span class="string">,</span></span><br><span class="line">        <span class="attr">"95.0":</span> <span class="number">945.0</span><span class="string">,</span></span><br><span class="line">        <span class="attr">"99.0":</span> <span class="number">985.0</span></span><br><span class="line">      <span class="string">&#125;</span></span><br><span class="line">    <span class="string">&#125;</span></span><br><span class="line">  <span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><p>百分位的统计也可以指定 percents 参数指定百分位，如下：</p><figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">GET latency/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="string">"aggs"</span> : &#123;</span><br><span class="line">    <span class="string">"load_time_outlier"</span> : &#123;</span><br><span class="line">      <span class="string">"percentiles"</span> : &#123;</span><br><span class="line">        <span class="string">"field"</span> : "<span class="type">load_time</span><span class="string">",</span></span><br><span class="line"><span class="string">        "</span>percents<span class="string">": [60, 80, 95]</span></span><br><span class="line"><span class="string">      &#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="210-percentiles-ranks-aggregation"><a class="markdownIt-Anchor" href="#210-percentiles-ranks-aggregation"></a> 2.10. Percentiles Ranks Aggregation</h3><p>Percentiles Ranks Aggregation 与 Percentiles Aggregation 统计恰恰相反，就是想看当前数值处在什么范围内（百分位）， 假如你查一下当前值 500 和 600 所处的百分位，发现是 90.01 和 100，那么说明有 90.01 % 的数值都在 500 以内，100 % 的数值在 600 以内。</p><figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">GET latency/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"size"</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="string">"aggs"</span> : &#123;</span><br><span class="line">      <span class="string">"load_time_ranks"</span> : &#123;</span><br><span class="line">        <span class="string">"percentile_ranks"</span> : &#123;</span><br><span class="line">          <span class="string">"field"</span> : "<span class="type">load_time</span><span class="string">",</span></span><br><span class="line"><span class="string">          "</span>values<span class="string">" : [500, 600]</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">      &#125;</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><p><strong><code>同样 load_time</code> 字段必须是数字类型</strong>。</p><p>返回结果大概类似如下：</p><figure class="highlight clojure"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">"aggregations"</span>: &#123;</span><br><span class="line">    <span class="string">"load_time_ranks"</span>: &#123;</span><br><span class="line">      <span class="string">"values"</span> : &#123;</span><br><span class="line">        <span class="string">"500.0"</span>: <span class="number">90.01</span>,</span><br><span class="line">        <span class="string">"600.0"</span>: <span class="number">100.0</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以设置 <code>keyed</code> 参数为 <code>true</code>，将对应的 values 作为桶 key 一起返回，默认是 <code>false</code>。</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> latency/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"size"</span>: 0,</span><br><span class="line">  <span class="string">"aggs"</span>: &#123;</span><br><span class="line">    <span class="string">"load_time_ranks"</span>: &#123;</span><br><span class="line">      <span class="string">"percentile_ranks"</span>: &#123;</span><br><span class="line">        <span class="string">"field"</span>: <span class="string">"load_time"</span>,</span><br><span class="line">        <span class="string">"values"</span>: [500, 600],</span><br><span class="line">        <span class="string">"keyed"</span>: <span class="literal">true</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>返回结果如下：</p><figure class="highlight clojure"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">"aggregations"</span>: &#123;</span><br><span class="line">    <span class="string">"load_time_ranks"</span>: &#123;</span><br><span class="line">      <span class="string">"values"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="string">"key"</span>: <span class="number">500.0</span>,</span><br><span class="line">          <span class="string">"value"</span>: <span class="number">90.01</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="string">"key"</span>: <span class="number">600.0</span>,</span><br><span class="line">          <span class="string">"value"</span>: <span class="number">100.0</span></span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-桶聚合"><a class="markdownIt-Anchor" href="#3-桶聚合"></a> 3. 桶聚合</h2><p>bucket 可以理解为一个桶，它会遍历文档中的内容，凡是符合某一要求的就放入一个桶中，分桶相当于 SQL 中的 group by。从另外一个角度，可以将指标聚合看成单桶聚合，即把所有文档放到一个桶中，而桶聚合是多桶型聚合，它根据相应的条件进行分组。</p><table><thead><tr><th style="text-align:left">种类</th><th style="text-align:left">描述/场景</th></tr></thead><tbody><tr><td style="text-align:left">词项聚合（Terms Aggregation）</td><td style="text-align:left">用于分组聚合，让用户得知文档中每个词项的频率，它返回每个词项出现的次数。</td></tr><tr><td style="text-align:left">差异词项聚合（Significant Terms Aggregation）</td><td style="text-align:left">它会返回某个词项在整个索引中和在查询结果中的词频差异，这有助于我们发现搜索场景中有意义的词。</td></tr><tr><td style="text-align:left">过滤器聚合（Filter Aggregation）</td><td style="text-align:left">指定过滤器匹配的所有文档到单个桶（bucket），通常这将用于将当前聚合上下文缩小到一组特定的文档。</td></tr><tr><td style="text-align:left">多过滤器聚合（Filters Aggregation）</td><td style="text-align:left">指定多个过滤器匹配所有文档到多个桶（bucket）。</td></tr><tr><td style="text-align:left">范围聚合（Range Aggregation）</td><td style="text-align:left">范围聚合，用于反映数据的分布情况。</td></tr><tr><td style="text-align:left">日期范围聚合（Date Range Aggregation）</td><td style="text-align:left">专门用于日期类型的范围聚合。</td></tr><tr><td style="text-align:left">IP 范围聚合（IP Range Aggregation）</td><td style="text-align:left">用于对 IP 类型数据范围聚合。</td></tr><tr><td style="text-align:left">直方图聚合（Histogram Aggregation）</td><td style="text-align:left">可能是数值，或者日期型，和范围聚集类似。</td></tr><tr><td style="text-align:left">时间直方图聚合（Date Histogram Aggregation）</td><td style="text-align:left">时间直方图聚合，常用于按照日期对文档进行统计并绘制条形图。</td></tr><tr><td style="text-align:left">空值聚合（Missing Aggregation）</td><td style="text-align:left">空值聚合，可以把文档集中所有缺失字段的文档分到一个桶中。</td></tr><tr><td style="text-align:left">地理点范围聚合（Geo Distance Aggregation）</td><td style="text-align:left">用于对地理点（geo point）做范围统计。</td></tr></tbody></table><h3 id="31-terms-aggregation"><a class="markdownIt-Anchor" href="#31-terms-aggregation"></a> 3.1. Terms Aggregation</h3><p>Terms Aggregation 用于词项的分组聚合。最为经典的用例是获取 X 中最频繁（top frequent）的项目，其中 X 是文档中的某个字段，如用户的名称、标签或分类。由于 terms 聚集统计的是每个词条，而不是整个字段值，因此通常需要在一个非分析型的字段上运行这种聚集。原因是, 你期望“big data”作为词组统计，而不是“big”单独统计一次，“data”再单独统计一次。</p><p>用户可以使用 terms 聚集，从分析型字段（如内容）中抽取最为频繁的词条。还可以使用这种信息来生成一个单词云。</p><figure class="highlight clojure"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"aggs"</span>: &#123;</span><br><span class="line">    <span class="string">"profit_terms"</span>: &#123;</span><br><span class="line">      <span class="string">"terms"</span>: &#123; // terms 聚合 关键字</span><br><span class="line">        <span class="string">"field"</span>: <span class="string">"profit"</span>,</span><br><span class="line">        ......</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在 terms 分桶的基础上，还可以对每个桶进行指标统计，也可以基于一些指标或字段值进行排序。示例如下：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"item_terms"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"item_id"</span>,</span><br><span class="line">        <span class="attr">"size"</span>: <span class="number">1000</span>,</span><br><span class="line">        <span class="attr">"order"</span>:[&#123;</span><br><span class="line">          <span class="attr">"gmv_stat"</span>: <span class="string">"desc"</span></span><br><span class="line">        &#125;,&#123;</span><br><span class="line">          <span class="attr">"gmv_180d"</span>: <span class="string">"desc"</span></span><br><span class="line">        &#125;]</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">        <span class="attr">"gmv_stat"</span>: &#123;</span><br><span class="line">          <span class="attr">"sum"</span>: &#123;</span><br><span class="line">            <span class="attr">"field"</span>: <span class="string">"gmv"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"gmv_180d"</span>: &#123;</span><br><span class="line">          <span class="attr">"sum"</span>: &#123;</span><br><span class="line">            <span class="attr">"script"</span>: <span class="string">"doc['gmv_90d'].value*2"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>返回的结果如下：</p><figure class="highlight clojure"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">"aggregations"</span>: &#123;</span><br><span class="line">    <span class="string">"hospital_id_agg"</span>: &#123;</span><br><span class="line">      <span class="string">"doc_count_error_upper_bound"</span>: <span class="number">0</span>,</span><br><span class="line">      <span class="string">"sum_other_doc_count"</span>: <span class="number">260</span>,</span><br><span class="line">      <span class="string">"buckets"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="string">"key"</span>: <span class="number">23388</span>,</span><br><span class="line">          <span class="string">"doc_count"</span>: <span class="number">18</span>,</span><br><span class="line">          <span class="string">"gmv_stat"</span>: &#123;</span><br><span class="line">            <span class="string">"value"</span>: <span class="number">176220</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="string">"gmv_180d"</span>: &#123;</span><br><span class="line">            <span class="string">"value"</span>: <span class="number">89732</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="string">"key"</span>: <span class="number">96117</span>,</span><br><span class="line">          <span class="string">"doc_count"</span>: <span class="number">16</span>,</span><br><span class="line">          <span class="string">"gmv_stat"</span>: &#123;</span><br><span class="line">            <span class="string">"value"</span>: <span class="number">129306</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="string">"gmv_180d"</span>: &#123;</span><br><span class="line">            <span class="string">"value"</span>: <span class="number">56988</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        ...</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>默认情况下返回按文档计数从高到低的前 10 个分组，可以通过 size 参数指定返回的分组数。</p><h3 id="32-filter-aggregation"><a class="markdownIt-Anchor" href="#32-filter-aggregation"></a> 3.2. Filter Aggregation</h3><p>Filter Aggregation 是过滤器聚合，可以把符合过滤器中的条件的文档分到一个桶中，即是单分组聚合。</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"age_terms"</span>: &#123;</span><br><span class="line">      <span class="attr">"filter"</span>: &#123;<span class="attr">"match"</span>:&#123;<span class="attr">"gender"</span>:<span class="string">"F"</span>&#125;&#125;,</span><br><span class="line">      <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">        <span class="attr">"avg_age"</span>: &#123;</span><br><span class="line">          <span class="attr">"avg"</span>: &#123;</span><br><span class="line">            <span class="attr">"field"</span>: <span class="string">"age"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="33-filters-aggregation"><a class="markdownIt-Anchor" href="#33-filters-aggregation"></a> 3.3. Filters Aggregation</h3><p>Filters Aggregation 是多过滤器聚合，可以把符合多个过滤条件的文档分到不同的桶中，即每个分组关联一个过滤条件，并收集所有满足自身过滤条件的文档。</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"messages"</span>: &#123;</span><br><span class="line">      <span class="attr">"filters"</span>: &#123;</span><br><span class="line">        <span class="attr">"filters"</span>: &#123;</span><br><span class="line">          <span class="attr">"errors"</span>: &#123; <span class="attr">"match"</span>: &#123; <span class="attr">"body"</span>: <span class="string">"error"</span> &#125; &#125;,</span><br><span class="line">          <span class="attr">"warnings"</span>: &#123; <span class="attr">"match"</span>: &#123; <span class="attr">"body"</span>: <span class="string">"warning"</span> &#125; &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个例子里，我们分析日志信息。聚合会创建两个关于日志数据的分组，一个收集包含错误信息的文档，另一个收集包含告警信息的文档。而且每个分组会按月份划分。</p><figure class="highlight clojure"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">"aggregations"</span>: &#123;</span><br><span class="line">    <span class="string">"messages"</span>: &#123;</span><br><span class="line">      <span class="string">"buckets"</span>: &#123;</span><br><span class="line">        <span class="string">"errors"</span>: &#123;</span><br><span class="line">          <span class="string">"doc_count"</span>: <span class="number">1</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"warnings"</span>: &#123;</span><br><span class="line">          <span class="string">"doc_count"</span>: <span class="number">2</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="34-range-aggregation"><a class="markdownIt-Anchor" href="#34-range-aggregation"></a> 3.4. Range Aggregation</h3><p>Range Aggregation 范围聚合是一个基于多组值来源的聚合，可以让用户定义一系列范围，每个范围代表一个分组。在聚合执行的过程中，从每个文档提取出来的值都会检查每个分组的范围，并且使相关的文档落入分组中。注意，范围聚合的每个范围内包含 from 值但是排除 to 值。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&#123;</span></span><br><span class="line">  <span class="attr">"aggs":</span> <span class="string">&#123;</span></span><br><span class="line">    <span class="attr">"age_range":</span> <span class="string">&#123;</span></span><br><span class="line">      <span class="attr">"range":</span> <span class="string">&#123;</span></span><br><span class="line">        <span class="attr">"field":</span> <span class="string">"age"</span><span class="string">,</span></span><br><span class="line">          <span class="attr">"ranges":</span> <span class="string">[&#123;</span></span><br><span class="line">            <span class="attr">"to":</span> <span class="number">25</span></span><br><span class="line">          <span class="string">&#125;,</span></span><br><span class="line">          <span class="string">&#123;</span></span><br><span class="line">            <span class="attr">"from":</span> <span class="number">25</span><span class="string">,</span></span><br><span class="line">            <span class="attr">"to":</span> <span class="number">35</span></span><br><span class="line">          <span class="string">&#125;,</span></span><br><span class="line">          <span class="string">&#123;</span></span><br><span class="line">            <span class="attr">"from":</span> <span class="number">35</span></span><br><span class="line">          <span class="string">&#125;]</span></span><br><span class="line">        <span class="string">&#125;,</span></span><br><span class="line">        <span class="attr">"aggs":</span> <span class="string">&#123;</span></span><br><span class="line">          <span class="attr">"bmax":</span> <span class="string">&#123;</span></span><br><span class="line">            <span class="attr">"max":</span> <span class="string">&#123;</span></span><br><span class="line">              <span class="attr">"field":</span> <span class="string">"balance"</span></span><br><span class="line">            <span class="string">&#125;</span></span><br><span class="line">          <span class="string">&#125;</span></span><br><span class="line">        <span class="string">&#125;</span></span><br><span class="line">      <span class="string">&#125;</span></span><br><span class="line">    <span class="string">&#125;</span></span><br><span class="line">  <span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><p>返回结果如下：</p><figure class="highlight clojure"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="string">"aggregations"</span>: &#123;</span><br><span class="line">    <span class="string">"age_range"</span>: &#123;</span><br><span class="line">      <span class="string">"buckets"</span>: [&#123;</span><br><span class="line">        <span class="string">"key"</span>: <span class="string">"*-25.0"</span>,</span><br><span class="line">        <span class="string">"to"</span>: <span class="number">25</span>,</span><br><span class="line">        <span class="string">"doc_count"</span>: <span class="number">225</span>,</span><br><span class="line">        <span class="string">"bmax"</span>: &#123;</span><br><span class="line">          <span class="string">"value"</span>: <span class="number">49587</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="string">"key"</span>: <span class="string">"25.0-35.0"</span>,</span><br><span class="line">        <span class="string">"from"</span>: <span class="number">25</span>,</span><br><span class="line">        <span class="string">"to"</span>: <span class="number">35</span>,</span><br><span class="line">        <span class="string">"doc_count"</span>: <span class="number">485</span>,</span><br><span class="line">        <span class="string">"bmax"</span>: &#123;</span><br><span class="line">          <span class="string">"value"</span>: <span class="number">49795</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="string">"key"</span>: <span class="string">"35.0-*"</span>,</span><br><span class="line">        <span class="string">"from"</span>: <span class="number">35</span>,</span><br><span class="line">        <span class="string">"doc_count"</span>: <span class="number">290</span>,</span><br><span class="line">        <span class="string">"bmax"</span>: &#123;</span><br><span class="line">          <span class="string">"value"</span>: <span class="number">49989</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4-参考资料"><a class="markdownIt-Anchor" href="#4-参考资料"></a> 4. 参考资料</h2><ul><li><a href="https://www.knowledgedict.com/tutorial/elasticsearch-intro.html" target="_blank" rel="noopener">Elasticsearch 教程</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;elasticsearch-聚合&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#elasticsearch-聚合&quot;&gt;&lt;/a&gt; Elasticsearch 聚合&lt;/h1&gt;
&lt;p&gt;Elasticsearch 是一个分布式的全文搜索引擎，索引
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/Elasticsearch/"/>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="聚合" scheme="https://dunwu.github.io/blog/tags/%E8%81%9A%E5%90%88/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch 查询</title>
    <link href="https://dunwu.github.io/blog/2022/01/18/elasticsearch-%E6%9F%A5%E8%AF%A2/"/>
    <id>https://dunwu.github.io/blog/2022/01/18/elasticsearch-%E6%9F%A5%E8%AF%A2/</id>
    <published>2022-01-18T00:01:08.000Z</published>
    <updated>2022-04-14T08:45:53.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="elasticsearch-查询"><a class="markdownIt-Anchor" href="#elasticsearch-查询"></a> Elasticsearch 查询</h1><p>Elasticsearch 查询语句采用基于 RESTful 风格的接口封装成 JSON 格式的对象，称之为 Query DSL。Elasticsearch 查询分类大致分为<strong>全文查询</strong>、<strong>词项查询</strong>、<strong>复合查询</strong>、<strong>嵌套查询</strong>、<strong>位置查询</strong>、<strong>特殊查询</strong>。Elasticsearch 查询从机制分为两种，一种是根据用户输入的查询词，通过排序模型计算文档与查询词之间的<strong>相关度</strong>，并根据评分高低排序返回；另一种是<strong>过滤机制</strong>，只根据过滤条件对文档进行过滤，不计算评分，速度相对较快。</p><h2 id="1-全文查询"><a class="markdownIt-Anchor" href="#1-全文查询"></a> 1. 全文查询</h2><p>ES 全文查询主要用于在全文字段上，主要考虑查询词与文档的相关性（Relevance）。</p><h3 id="11-intervals-query"><a class="markdownIt-Anchor" href="#11-intervals-query"></a> 1.1. intervals query</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-intervals-query.html" target="_blank" rel="noopener"><strong><code>intervals query</code></strong></a> 根据匹配词的顺序和近似度返回文档。</p><p>intervals query 使用<strong>匹配规则</strong>，这些规则应用于指定字段中的 term。</p><p>示例：下面示例搜索 <code>query</code> 字段，搜索值是 <code>my favorite food</code>，没有任何间隙；然后是 <code>my_text</code> 字段搜索匹配 <code>hot water</code>、<code>cold porridge</code> 的 term。</p><p>当 my_text 中的值为 <code>my favorite food is cold porridge</code> 时，会匹配成功，但是 <code>when it's cold my favorite food is porridge</code> 则匹配失败</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POST _search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"intervals"</span> : &#123;</span><br><span class="line">      <span class="string">"my_text"</span> : &#123;</span><br><span class="line">        <span class="string">"all_of"</span> : &#123;</span><br><span class="line">          <span class="string">"ordered"</span> : <span class="literal">true</span>,</span><br><span class="line">          <span class="string">"intervals"</span> : [</span><br><span class="line">            &#123;</span><br><span class="line">              <span class="string">"match"</span> : &#123;</span><br><span class="line">                <span class="string">"query"</span> : <span class="string">"my favorite food"</span>,</span><br><span class="line">                <span class="string">"max_gaps"</span> : 0,</span><br><span class="line">                <span class="string">"ordered"</span> : <span class="literal">true</span></span><br><span class="line">              &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">              <span class="string">"any_of"</span> : &#123;</span><br><span class="line">                <span class="string">"intervals"</span> : [</span><br><span class="line">                  &#123; <span class="string">"match"</span> : &#123; <span class="string">"query"</span> : <span class="string">"hot water"</span> &#125; &#125;,</span><br><span class="line">                  &#123; <span class="string">"match"</span> : &#123; <span class="string">"query"</span> : <span class="string">"cold porridge"</span> &#125; &#125;</span><br><span class="line">                ]</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="12-match-query"><a class="markdownIt-Anchor" href="#12-match-query"></a> 1.2. match query</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query.html" target="_blank" rel="noopener"><strong><code>match query</code></strong></a> <strong>用于搜索单个字段</strong>，首先会针对查询语句进行解析（经过 analyzer），主要是对查询语句进行分词，分词后查询语句的任何一个词项被匹配，文档就会被搜到，默认情况下相当于对分词后词项进行 or 匹配操作。</p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query.html" target="_blank" rel="noopener"><strong><code>match query</code></strong></a> 是执行全文搜索的标准查询，包括模糊匹配选项。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET kibana_sample_data_ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"match"</span>: &#123;</span><br><span class="line">      <span class="string">"customer_full_name"</span>: &#123;</span><br><span class="line">        <span class="string">"query"</span>: <span class="string">"George Hubbard"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>等同于 <code>or</code> 匹配操作，如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET kibana_sample_data_ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"match"</span>: &#123;</span><br><span class="line">      <span class="string">"customer_full_name"</span>: &#123;</span><br><span class="line">        <span class="string">"query"</span>: <span class="string">"George Hubbard"</span>,</span><br><span class="line">        <span class="string">"operator"</span>: <span class="string">"or"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="match-query-简写"><a class="markdownIt-Anchor" href="#match-query-简写"></a> match query 简写</h4><p>可以通过组合 <code>&lt;field&gt;</code> 和 <code>query</code> 参数来简化匹配查询语法。</p><p>示例：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"match"</span>: &#123;</span><br><span class="line">      <span class="string">"message"</span>: <span class="string">"this is a test"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="match-query-如何工作"><a class="markdownIt-Anchor" href="#match-query-如何工作"></a> match query 如何工作</h4><p>匹配查询是布尔类型。这意味着会对提供的文本进行分析，分析过程从提供的文本构造一个布尔查询。 <code>operator</code> 参数可以设置为 <code>or</code> 或 <code>and</code> 来控制布尔子句（默认为 <code>or</code>）。可以使用 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-minimum-should-match.html" target="_blank" rel="noopener"><code>minimum_should_match</code></a> 参数设置要匹配的可选 <code>should</code> 子句的最小数量。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET kibana_sample_data_ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"match"</span>: &#123;</span><br><span class="line">      <span class="string">"customer_full_name"</span>: &#123;</span><br><span class="line">        <span class="string">"query"</span>: <span class="string">"George Hubbard"</span>,</span><br><span class="line">        <span class="string">"operator"</span>: <span class="string">"and"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以设置 <code>analyzer</code> 来控制哪个分析器将对文本执行分析过程。它默认为字段显式映射定义或默认搜索分析器。</p><p><code>lenient</code> 参数可以设置为 <code>true</code> 以忽略由数据类型不匹配导致的异常，例如尝试使用文本查询字符串查询数字字段。默认为 <code>false</code>。</p><h4 id="match-query-的模糊查询"><a class="markdownIt-Anchor" href="#match-query-的模糊查询"></a> match query 的模糊查询</h4><p><code>fuzziness</code> 允许基于被查询字段的类型进行模糊匹配。请参阅 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/common-options.html#fuzziness" target="_blank" rel="noopener">Fuzziness</a> 的配置。</p><p>在这种情况下可以设置 <code>prefix_length</code> 和 <code>max_expansions</code> 来控制模糊匹配。如果设置了模糊选项，查询将使用 <code>top_terms_blended_freqs_${max_expansions}</code> 作为其重写方法，<code>fuzzy_rewrite</code> 参数允许控制查询将如何被重写。</p><p>默认情况下允许模糊倒转 (<code>ab</code> → <code>ba</code>)，但可以通过将 <code>fuzzy_transpositions</code> 设置为 <code>false</code> 来禁用。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"match"</span>: &#123;</span><br><span class="line">      <span class="string">"message"</span>: &#123;</span><br><span class="line">        <span class="string">"query"</span>: <span class="string">"this is a testt"</span>,</span><br><span class="line">        <span class="string">"fuzziness"</span>: <span class="string">"AUTO"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="zero-terms-查询"><a class="markdownIt-Anchor" href="#zero-terms-查询"></a> zero terms 查询</h4><p>如果使用的分析器像 stop 过滤器一样删除查询中的所有标记，则默认行为是不匹配任何文档。可以使用 <code>zero_terms_query</code> 选项来改变默认行为，它接受 <code>none</code>（默认）和 <code>all</code> （相当于 <code>match_all</code> 查询）。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"match"</span>: &#123;</span><br><span class="line">      <span class="string">"message"</span>: &#123;</span><br><span class="line">        <span class="string">"query"</span>: <span class="string">"to be or not to be"</span>,</span><br><span class="line">        <span class="string">"operator"</span>: <span class="string">"and"</span>,</span><br><span class="line">        <span class="string">"zero_terms_query"</span>: <span class="string">"all"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="13-match_bool_prefix-query"><a class="markdownIt-Anchor" href="#13-match_bool_prefix-query"></a> 1.3. match_bool_prefix query</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-bool-prefix-query.html" target="_blank" rel="noopener"><strong><code>match_bool_prefix query</code></strong></a> 分析其输入并根据这些词构造一个布尔查询。除了最后一个术语之外的每个术语都用于术语查询。最后一个词用于 <code>prefix query</code>。</p><p>示例：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"match_bool_prefix"</span> : &#123;</span><br><span class="line">      <span class="string">"message"</span> : <span class="string">"quick brown f"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>等价于</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"bool"</span> : &#123;</span><br><span class="line">      <span class="string">"should"</span>: [</span><br><span class="line">        &#123; <span class="string">"term"</span>: &#123; <span class="string">"message"</span>: <span class="string">"quick"</span> &#125;&#125;,</span><br><span class="line">        &#123; <span class="string">"term"</span>: &#123; <span class="string">"message"</span>: <span class="string">"brown"</span> &#125;&#125;,</span><br><span class="line">        &#123; <span class="string">"prefix"</span>: &#123; <span class="string">"message"</span>: <span class="string">"f"</span>&#125;&#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>match_bool_prefix query</code> 和 <code>match_phrase_prefix query</code> 之间的一个重要区别是：<code>match_phrase_prefix query</code> 将其 term 匹配为短语，但 <code>match_bool_prefix query</code> 可以在任何位置匹配其 term。</p><p>上面的示例 <code>match_bool_prefix query</code> 查询可以匹配包含 <code>quick brown fox</code> 的字段，但它也可以快速匹配 <code>brown fox</code>。它还可以匹配包含 <code>quick</code>、<code>brown</code> 和以 <code>f</code> 开头的字段，出现在任何位置。</p><h3 id="14-match_phrase-query"><a class="markdownIt-Anchor" href="#14-match_phrase-query"></a> 1.4. match_phrase query</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query-phrase.html" target="_blank" rel="noopener"><strong><code>match_phrase query</code></strong></a> 即短语匹配，首先会把 query 内容分词，分词器可以自定义，同时文档还要满足以下两个条件才会被搜索到：</p><ol><li><strong>分词后所有词项都要出现在该字段中（相当于 and 操作）</strong>。</li><li><strong>字段中的词项顺序要一致</strong>。</li></ol><p>例如，有以下 3 个文档，使用 <strong><code>match_phrase</code></strong> 查询 “How are you”，只有前两个文档会被匹配：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PUT demo/_create/1</span><br><span class="line">&#123; <span class="string">"desc"</span>: <span class="string">"How are you"</span> &#125;</span><br><span class="line"></span><br><span class="line">PUT demo/_create/2</span><br><span class="line">&#123; <span class="string">"desc"</span>: <span class="string">"How are you, Jack?"</span>&#125;</span><br><span class="line"></span><br><span class="line">PUT demo/_create/3</span><br><span class="line">&#123; <span class="string">"desc"</span>: <span class="string">"are you"</span>&#125;</span><br><span class="line"></span><br><span class="line">GET demo/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"match_phrase"</span>: &#123;</span><br><span class="line">      <span class="string">"desc"</span>: <span class="string">"How are you"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>说明：</p><p>一个被认定为和短语 How are you 匹配的文档，必须满足以下这些要求：</p><ul><li>How、 are 和 you 需要全部出现在域中。</li><li>are 的位置应该比 How 的位置大 1 。</li><li>you 的位置应该比 How 的位置大 2 。</li></ul></blockquote><h3 id="15-match_phrase_prefix-query"><a class="markdownIt-Anchor" href="#15-match_phrase_prefix-query"></a> 1.5. match_phrase_prefix query</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query-phrase-prefix.html" target="_blank" rel="noopener"><strong><code>match_phrase_prefix query</code></strong></a> 和 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query-phrase.html" target="_blank" rel="noopener"><strong><code>match_phrase query</code></strong></a> 类似，只不过 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query-phrase-prefix.html" target="_blank" rel="noopener"><strong><code>match_phrase_prefix query</code></strong></a> 最后一个 term 会被作为前缀匹配。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET demo/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"match_phrase_prefix"</span>: &#123;</span><br><span class="line">      <span class="string">"desc"</span>: <span class="string">"are yo"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="16-multi_match-query"><a class="markdownIt-Anchor" href="#16-multi_match-query"></a> 1.6. multi_match query</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-multi-match-query.html" target="_blank" rel="noopener"><strong><code>multi_match query</code></strong></a> 是 <strong><code>match query</code></strong> 的升级，<strong>用于搜索多个字段</strong>。</p><p>示例：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET kibana_sample_data_ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"multi_match"</span>: &#123;</span><br><span class="line">      <span class="string">"query"</span>: 34.98,</span><br><span class="line">      <span class="string">"fields"</span>: [</span><br><span class="line">        <span class="string">"taxful_total_price"</span>,</span><br><span class="line">        <span class="string">"taxless_total_price"</span></span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong><code>multi_match query</code></strong> 的搜索字段可以使用通配符指定，示例如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET kibana_sample_data_ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"multi_match"</span>: &#123;</span><br><span class="line">      <span class="string">"query"</span>: 34.98,</span><br><span class="line">      <span class="string">"fields"</span>: [</span><br><span class="line">        <span class="string">"taxful_*"</span>,</span><br><span class="line">        <span class="string">"taxless_total_price"</span></span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同时，也可以用<strong>指数符指定搜索字段的权重</strong>。</p><p>示例：指定 taxful_total_price 字段的权重是 taxless_total_price 字段的 3 倍，命令如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET kibana_sample_data_ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"multi_match"</span>: &#123;</span><br><span class="line">      <span class="string">"query"</span>: 34.98,</span><br><span class="line">      <span class="string">"fields"</span>: [</span><br><span class="line">        <span class="string">"taxful_total_price^3"</span>,</span><br><span class="line">        <span class="string">"taxless_total_price"</span></span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="17-combined_fields-query"><a class="markdownIt-Anchor" href="#17-combined_fields-query"></a> 1.7. combined_fields query</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-combined-fields-query.html" target="_blank" rel="noopener"><strong><code>combined_fields query</code></strong></a> 支持搜索多个文本字段，就好像它们的内容已被索引到一个组合字段中一样。该查询会生成以 term 为中心的输入字符串视图：首先它将查询字符串解析为独立的 term，然后在所有字段中查找每个 term。当匹配结果可能跨越多个文本字段时，此查询特别有用，例如文章的标题、摘要和正文：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"combined_fields"</span> : &#123;</span><br><span class="line">      <span class="string">"query"</span>:      <span class="string">"database systems"</span>,</span><br><span class="line">      <span class="string">"fields"</span>:     [ <span class="string">"title"</span>, <span class="string">"abstract"</span>, <span class="string">"body"</span>],</span><br><span class="line">      <span class="string">"operator"</span>:   <span class="string">"and"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="字段前缀权重"><a class="markdownIt-Anchor" href="#字段前缀权重"></a> 字段前缀权重</h4><p>字段前缀权重根据组合字段模型进行计算。例如，如果 title 字段的权重为 2，则匹配度打分时会将 title 中的每个 term 形成的组合字段，按出现两次进行打分。</p><h3 id="18-common_terms-query"><a class="markdownIt-Anchor" href="#18-common_terms-query"></a> 1.8. common_terms query</h3><blockquote><p>7.3.0 废弃</p></blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-common-terms-query.html" target="_blank" rel="noopener"><strong><code>common_terms query</code></strong></a> 是一种在不牺牲性能的情况下替代停用词提高搜索准确率和召回率的方案。</p><p>查询中的每个词项都有一定的代价，以搜索“The brown fox”为例，query 会被解析成三个词项“the”“brown”和“fox”，每个词项都会到索引中执行一次查询。很显然包含“the”的文档非常多，相比其他词项，“the”的重要性会低很多。传统的解决方案是把“the”当作停用词处理，去除停用词之后可以减少索引大小，同时在搜索时减少对停用词的收缩。</p><p>虽然停用词对文档评分影响不大，但是当停用词仍然有重要意义的时候，去除停用词就不是完美的解决方案了。如果去除停用词，就无法区分“happy”和“not happy”, “The”“To be or not to be”就不会在索引中存在，搜索的准确率和召回率就会降低。</p><p>common_terms query 提供了一种解决方案，它把 query 分词后的词项分成重要词项（低频词项）和不重要的词项（高频词，也就是之前的停用词）。在搜索的时候，首先搜索和重要词项匹配的文档，这些文档是词项出现较少并且词项对其评分影响较大的文档。然后执行第二次查询，搜索对评分影响较小的高频词项，但是不计算所有文档的评分，而是只计算第一次查询已经匹配的文档得分。如果一个查询中只包含高频词，那么会通过 and 连接符执行一个单独的查询，换言之，会搜索所有的词项。</p><p>词项是高频词还是低频词是通过 cutoff frequency 来设置阀值的，取值可以是绝对频率（频率大于 1）或者相对频率（0 ～ 1）。common_terms query 最有趣之处在于它能自适应特定领域的停用词，例如，在视频托管网站上，诸如“clip”或“video”之类的高频词项将自动表现为停用词，无须保留手动列表。</p><p>例如，文档频率高于 0.1% 的词项将会被当作高频词项，词频之间可以用 low_freq_operator、high_freq_operator 参数连接。设置低频词操作符为“and”使所有的低频词都是必须搜索的，示例代码如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET books/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"common"</span>: &#123;</span><br><span class="line"><span class="string">"body"</span>: &#123;</span><br><span class="line"><span class="string">"query"</span>: <span class="string">"nelly the elephant as a cartoon"</span>,</span><br><span class="line"><span class="string">"cutoff_frequency"</span>: 0.001,</span><br><span class="line"><span class="string">"low_freq_operator"</span>: <span class="string">"and"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述操作等价于：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET books/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"bool"</span>: &#123;</span><br><span class="line"><span class="string">"must"</span>: [</span><br><span class="line">  &#123; <span class="string">"term"</span>: &#123; <span class="string">"body"</span>: <span class="string">"nelly"</span> &#125; &#125;,</span><br><span class="line">  &#123; <span class="string">"term"</span>: &#123; <span class="string">"body"</span>: <span class="string">"elephant"</span> &#125; &#125;,</span><br><span class="line">  &#123; <span class="string">"term"</span>: &#123; <span class="string">"body"</span>: <span class="string">"cartoon"</span> &#125; &#125;</span><br><span class="line">],</span><br><span class="line"><span class="string">"should"</span>: [</span><br><span class="line">  &#123; <span class="string">"term"</span>: &#123; <span class="string">"body"</span>: <span class="string">"the"</span> &#125; &#125;,</span><br><span class="line">  &#123; <span class="string">"term"</span>: &#123; <span class="string">"body"</span>: <span class="string">"as"</span> &#125; &#125;,</span><br><span class="line">  &#123; <span class="string">"term"</span>: &#123; <span class="string">"body"</span>: <span class="string">"a"</span> &#125; &#125;</span><br><span class="line">]</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="19-query_string-query"><a class="markdownIt-Anchor" href="#19-query_string-query"></a> 1.9. query_string query</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html" target="_blank" rel="noopener"><strong><code>query_string query</code></strong></a> 是与 Lucene 查询语句的语法结合非常紧密的一种查询，允许在一个查询语句中使用多个特殊条件关键字（如：AND | OR | NOT）对多个字段进行查询，建议熟悉 Lucene 查询语法的用户去使用。</p><p>用户可以使用 query_string query 来创建包含通配符、跨多个字段的搜索等复杂搜索。虽然通用，但查询是严格的，如果查询字符串包含任何无效语法，则会返回错误。</p><p>示例：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"query_string"</span>: &#123;</span><br><span class="line">      <span class="string">"query"</span>: <span class="string">"(new york city) OR (big apple)"</span>,</span><br><span class="line">      <span class="string">"default_field"</span>: <span class="string">"content"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="110-simple_query_string-query"><a class="markdownIt-Anchor" href="#110-simple_query_string-query"></a> 1.10. simple_query_string query</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-simple-query-string-query.html" target="_blank" rel="noopener"><strong><code>simple_query_string query</code></strong></a> 是一种适合直接暴露给用户，并且具有非常完善的查询语法的查询语句，接受 Lucene 查询语法，解析过程中发生错误不会抛出异常。</p><p>虽然语法比 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html" target="_blank" rel="noopener"><strong><code>query_string query</code></strong></a> 更严格，但 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-simple-query-string-query.html" target="_blank" rel="noopener"><strong><code>simple_query_string query</code></strong></a> 不会返回无效语法的错误。相反，它会忽略查询字符串的任何无效部分。</p><p>示例：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"simple_query_string"</span> : &#123;</span><br><span class="line">        <span class="string">"query"</span>: <span class="string">"\"fried eggs\" +(eggplant | potato) -frittata"</span>,</span><br><span class="line">        <span class="string">"fields"</span>: [<span class="string">"title^5"</span>, <span class="string">"body"</span>],</span><br><span class="line">        <span class="string">"default_operator"</span>: <span class="string">"and"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="simple_query_string-语义"><a class="markdownIt-Anchor" href="#simple_query_string-语义"></a> simple_query_string 语义</h4><ul><li><code>+</code>：等价于 AND 操作</li><li><code>|</code>：等价于 OR 操作</li><li><code>-</code>：相当于 NOT 操作</li><li><code>&quot;</code>：包装一些标记以表示用于搜索的短语</li><li><code>*</code>：词尾表示前缀查询</li><li><code>(</code> and <code>)</code>：表示优先级</li><li><code>~N</code>：词尾表示表示编辑距离（模糊性）</li><li><code>~N</code>：在一个短语之后表示溢出量</li></ul><p>注意：要使用上面的字符，请使用反斜杠 <code>/</code> 对其进行转义。</p><h3 id="111-全文查询完整示例"><a class="markdownIt-Anchor" href="#111-全文查询完整示例"></a> 1.11. 全文查询完整示例</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#设置 position_increment_gap</span></span><br><span class="line">DELETE groups</span><br><span class="line">PUT groups</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"mappings"</span>: &#123;</span><br><span class="line">    <span class="string">"properties"</span>: &#123;</span><br><span class="line">      <span class="string">"names"</span>:&#123;</span><br><span class="line">        <span class="string">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">        <span class="string">"position_increment_gap"</span>: 0</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET groups/_mapping</span><br><span class="line"></span><br><span class="line">POST groups/_doc</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"names"</span>: [ <span class="string">"John Water"</span>, <span class="string">"Water Smith"</span>]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST groups/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"match_phrase"</span>: &#123;</span><br><span class="line">      <span class="string">"names"</span>: &#123;</span><br><span class="line">        <span class="string">"query"</span>: <span class="string">"Water Water"</span>,</span><br><span class="line">        <span class="string">"slop"</span>: 100</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST groups/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"match_phrase"</span>: &#123;</span><br><span class="line">      <span class="string">"names"</span>: <span class="string">"Water Smith"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DELETE groups</span><br></pre></td></tr></table></figure><h2 id="2-词项查询"><a class="markdownIt-Anchor" href="#2-词项查询"></a> 2. 词项查询</h2><p><strong><code>Term</code>（词项）是表达语意的最小单位</strong>。搜索和利用统计语言模型进行自然语言处理都需要处理 Term。</p><p>全文查询在执行查询之前会分析查询字符串。</p><p>与全文查询不同，词项查询不会分词，而是将输入作为一个整体，在倒排索引中查找准确的词项。并且使用相关度计算公式为每个包含该词项的文档进行相关度计算。一言以概之：<strong>词项查询是对词项进行精确匹配</strong>。词项查询通常用于结构化数据，如数字、日期和枚举类型。</p><p>词项查询有以下类型：</p><ul><li><strong><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-exists-query.html" target="_blank" rel="noopener"><code>exists</code> query</a></strong></li><li><strong><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-fuzzy-query.html" target="_blank" rel="noopener"><code>fuzzy</code> query</a></strong></li><li><strong><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-ids-query.html" target="_blank" rel="noopener"><code>ids</code> query</a></strong></li><li><strong><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-prefix-query.html" target="_blank" rel="noopener"><code>prefix</code> query</a></strong></li><li><strong><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-range-query.html" target="_blank" rel="noopener"><code>range</code> query</a></strong></li><li><strong><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-regexp-query.html" target="_blank" rel="noopener"><code>regexp</code> query</a></strong></li><li><strong><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-term-query.html" target="_blank" rel="noopener"><code>term</code> query</a></strong></li><li><strong><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-terms-query.html" target="_blank" rel="noopener"><code>terms</code> query</a></strong></li><li><strong><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-type-query.html" target="_blank" rel="noopener"><code>type</code> query</a></strong></li><li><strong><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-wildcard-query.html" target="_blank" rel="noopener"><code>wildcard</code> query</a></strong></li></ul><h3 id="21-exists-query"><a class="markdownIt-Anchor" href="#21-exists-query"></a> 2.1. exists query</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-exists-query.html" target="_blank" rel="noopener"><strong><code>exists query</code></strong></a> 会返回字段中至少有一个非空值的文档。</p><p>由于多种原因，文档字段可能不存在索引值：</p><ul><li>JSON 中的字段为 <code>null</code> 或 <code>[]</code></li><li>该字段在 mapping 中配置了 <code>&quot;index&quot; : false</code></li><li>字段值的长度超过了 mapping 中的 <code>ignore_above</code> 设置</li><li>字段值格式错误，并且在 mapping 中定义了 <code>ignore_malformed</code></li></ul><p>示例：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET kibana_sample_data_ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"exists"</span>: &#123;</span><br><span class="line">      <span class="string">"field"</span>: <span class="string">"email"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以下文档会匹配上面的查询：</p><ul><li><code>{ &quot;user&quot; : &quot;jane&quot; }</code> 有 user 字段，且不为空。</li><li><code>{ &quot;user&quot; : &quot;&quot; }</code> 有 user 字段，值为空字符串。</li><li><code>{ &quot;user&quot; : &quot;-&quot; }</code> 有 user 字段，值不为空。</li><li><code>{ &quot;user&quot; : [ &quot;jane&quot; ] }</code> 有 user 字段，值不为空。</li><li><code>{ &quot;user&quot; : [ &quot;jane&quot;, null ] }</code> 有 user 字段，至少一个值不为空即可。</li></ul><p>下面的文档都不会被匹配：</p><ul><li><code>{ &quot;user&quot; : null }</code> 虽然有 user 字段，但是值为空。</li><li><code>{ &quot;user&quot; : [] }</code> 虽然有 user 字段，但是值为空。</li><li><code>{ &quot;user&quot; : [null] }</code> 虽然有 user 字段，但是值为空。</li><li><code>{ &quot;foo&quot; : &quot;bar&quot; }</code> 没有 user 字段。</li></ul><h3 id="22-fuzzy-query"><a class="markdownIt-Anchor" href="#22-fuzzy-query"></a> 2.2. fuzzy query</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-fuzzy-query.html" target="_blank" rel="noopener"><strong><code>fuzzy query</code></strong>（模糊查询）</a>返回包含与搜索词相似的词的文档。ES 使用 <a href="https://en.wikipedia.org/wiki/Levenshtein_distance" target="_blank" rel="noopener">Levenshtein edit distance（Levenshtein 编辑距离）</a>测量相似度或模糊度。</p><p>编辑距离是将一个术语转换为另一个术语所需的单个字符更改的数量。这些变化可能包括：</p><ul><li>改变一个字符：（<strong>b</strong>ox -&gt; <strong>f</strong>ox）</li><li>删除一个字符：（<strong>b</strong>lack -&gt; lack）</li><li>插入一个字符：（sic -&gt; sic<strong>k</strong>）</li><li>反转两个相邻字符：（<strong>ac</strong>t → <strong>ca</strong>t）</li></ul><p>为了找到相似的词条，fuzzy query 会在指定的编辑距离内创建搜索词条的所有可能变体或扩展集。然后返回完全匹配任意扩展的文档。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET books/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"fuzzy"</span>: &#123;</span><br><span class="line">      <span class="string">"user.id"</span>: &#123;</span><br><span class="line">        <span class="string">"value"</span>: <span class="string">"ki"</span>,</span><br><span class="line">        <span class="string">"fuzziness"</span>: <span class="string">"AUTO"</span>,</span><br><span class="line">        <span class="string">"max_expansions"</span>: 50,</span><br><span class="line">        <span class="string">"prefix_length"</span>: 0,</span><br><span class="line">        <span class="string">"transpositions"</span>: <span class="literal">true</span>,</span><br><span class="line">        <span class="string">"rewrite"</span>: <span class="string">"constant_score"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：如果配置了 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html#query-dsl-allow-expensive-queries" target="_blank" rel="noopener"><code>search.allow_expensive_queries</code></a> ，则 fuzzy query 不能执行。</p><h3 id="23-ids-query"><a class="markdownIt-Anchor" href="#23-ids-query"></a> 2.3. ids query</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-ids-query.html" target="_blank" rel="noopener"><strong><code>ids query</code></strong></a> 根据 ID 返回文档。 此查询使用存储在 <code>_id</code> 字段中的文档 ID。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"ids"</span> : &#123;</span><br><span class="line">      <span class="string">"values"</span> : [<span class="string">"1"</span>, <span class="string">"4"</span>, <span class="string">"100"</span>]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="24-prefix-query"><a class="markdownIt-Anchor" href="#24-prefix-query"></a> 2.4. prefix query</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-prefix-query.html#prefix-query-ex-request" target="_blank" rel="noopener"><strong><code>prefix query</code></strong></a> 用于查询某个字段中包含指定前缀的文档。</p><p>比如查询 <code>user.id</code> 中含有以 <code>ki</code> 为前缀的关键词的文档，那么含有 <code>kind</code>、<code>kid</code> 等所有以 <code>ki</code> 开头关键词的文档都会被匹配。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"prefix"</span>: &#123;</span><br><span class="line">      <span class="string">"user.id"</span>: &#123;</span><br><span class="line">        <span class="string">"value"</span>: <span class="string">"ki"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="25-range-query"><a class="markdownIt-Anchor" href="#25-range-query"></a> 2.5. range query</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-range-query.html" target="_blank" rel="noopener"><strong><code>range query</code></strong></a> 即范围查询，用于匹配在某一范围内的数值型、日期类型或者字符串型字段的文档。比如搜索哪些书籍的价格在 50 到 100 之间、哪些书籍的出版时间在 2015 年到 2019 年之间。<strong>使用 range 查询只能查询一个字段，不能作用在多个字段上</strong>。</p><p>range 查询支持的参数有以下几种：</p><ul><li><p><strong><code>gt</code></strong>：大于</p></li><li><p><strong><code>gte</code></strong>：大于等于</p></li><li><p><strong><code>lt</code></strong>：小于</p></li><li><p><strong><code>lte</code></strong>：小于等于</p></li><li><p><strong><code>format</code></strong>：如果字段是 Date 类型，可以设置日期格式化</p></li><li><p><strong><code>time_zone</code></strong>：时区</p></li><li><p><strong><code>relation</code></strong>：指示范围查询如何匹配范围字段的值。</p><ul><li><strong><code>INTERSECTS</code> (Default)</strong>：匹配与查询字段值范围相交的文档。</li><li><strong><code>CONTAINS</code></strong>：匹配完全包含查询字段值的文档。</li><li><strong><code>WITHIN</code></strong>：匹配具有完全在查询范围内的范围字段值的文档。</li></ul></li></ul><p>示例：数值范围查询</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET kibana_sample_data_ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"range"</span>: &#123;</span><br><span class="line">      <span class="string">"taxful_total_price"</span>: &#123;</span><br><span class="line">        <span class="string">"gt"</span>: 10,</span><br><span class="line">        <span class="string">"lte"</span>: 50</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>示例：日期范围查询</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET kibana_sample_data_ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"range"</span>: &#123;</span><br><span class="line">      <span class="string">"order_date"</span>: &#123;</span><br><span class="line">        <span class="string">"time_zone"</span>: <span class="string">"+00:00"</span>,</span><br><span class="line">        <span class="string">"gte"</span>: <span class="string">"2018-01-01T00:00:00"</span>,</span><br><span class="line">        <span class="string">"lte"</span>: <span class="string">"now"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="26-regexp-query"><a class="markdownIt-Anchor" href="#26-regexp-query"></a> 2.6. regexp query</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-regexp-query.html" target="_blank" rel="noopener"><strong><code>regexp query</code></strong></a> 返回与正则表达式相匹配的 term 所属的文档。</p><p><a href="https://zh.wikipedia.org/zh-hans/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F" target="_blank" rel="noopener">正则表达式</a>是一种使用占位符字符匹配数据模式的方法，称为运算符。</p><p>示例：以下搜索返回 <code>user.id</code> 字段包含任何以 <code>k</code> 开头并以 <code>y</code> 结尾的文档。 <code>.*</code> 运算符匹配任何长度的任何字符，包括无字符。匹配项可以包括 <code>ky</code>、<code>kay</code> 和 <code>kimchy</code>。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"regexp"</span>: &#123;</span><br><span class="line">      <span class="string">"user.id"</span>: &#123;</span><br><span class="line">        <span class="string">"value"</span>: <span class="string">"k.*y"</span>,</span><br><span class="line">        <span class="string">"flags"</span>: <span class="string">"ALL"</span>,</span><br><span class="line">        <span class="string">"case_insensitive"</span>: <span class="literal">true</span>,</span><br><span class="line">        <span class="string">"max_determinized_states"</span>: 10000,</span><br><span class="line">        <span class="string">"rewrite"</span>: <span class="string">"constant_score"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>注意：如果配置了<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html#query-dsl-allow-expensive-queries" target="_blank" rel="noopener"><code>search.allow_expensive_queries</code></a> ，则 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-regexp-query.html" target="_blank" rel="noopener"><strong><code>regexp query</code></strong></a> 会被禁用。</p></blockquote><h3 id="27-term-query"><a class="markdownIt-Anchor" href="#27-term-query"></a> 2.7. term query</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-term-query.html" target="_blank" rel="noopener"><strong><code>term query</code></strong></a> 用来查找指定字段中包含给定单词的文档，term 查询不被解析，只有查询词和文档中的词精确匹配才会被搜索到，应用场景为查询人名、地名等需要精准匹配的需求。</p><p>示例：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1. 创建一个索引</span></span><br><span class="line">DELETE my-index-000001</span><br><span class="line">PUT my-index-000001</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"mappings"</span>: &#123;</span><br><span class="line">    <span class="string">"properties"</span>: &#123;</span><br><span class="line">      <span class="string">"full_text"</span>: &#123; <span class="string">"type"</span>: <span class="string">"text"</span> &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 使用 "Quick Brown Foxes!" 关键字查 "full_text" 字段</span></span><br><span class="line">PUT my-index-000001/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"full_text"</span>: <span class="string">"Quick Brown Foxes!"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 使用 term 查询</span></span><br><span class="line">GET my-index-000001/_search?pretty</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"term"</span>: &#123;</span><br><span class="line">      <span class="string">"full_text"</span>: <span class="string">"Quick Brown Foxes!"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 因为 full_text 字段不再包含确切的 Term —— "Quick Brown Foxes!"，所以 term query 搜索不到任何结果</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 使用 match 查询</span></span><br><span class="line">GET my-index-000001/_search?pretty</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"match"</span>: &#123;</span><br><span class="line">      <span class="string">"full_text"</span>: <span class="string">"Quick Brown Foxes!"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DELETE my-index-000001</span><br></pre></td></tr></table></figure><blockquote><p>⚠️ 注意：应避免 term 查询对 text 字段使用查询。</p><p>默认情况下，Elasticsearch 针对 text 字段的值进行解析分词，这会使查找 text 字段值的精确匹配变得困难。</p><p>要搜索 text 字段值，需改用 match 查询。</p></blockquote><h3 id="28-terms-query"><a class="markdownIt-Anchor" href="#28-terms-query"></a> 2.8. terms query</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-terms-query.html" target="_blank" rel="noopener"><strong><code>terms query</code></strong></a> 与 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-term-query.html" target="_blank" rel="noopener"><strong><code>term query</code></strong></a> 相同，但可以搜索多个值。</p><p>terms query 查询参数：</p><ul><li><strong><code>index</code></strong>：索引名</li><li><strong><code>id</code></strong>：文档 ID</li><li><strong><code>path</code></strong>：要从中获取字段值的字段的名称，即搜索关键字</li><li><strong><code>routing</code></strong>（选填）：要从中获取 term 值的文档的自定义路由值。如果在索引文档时提供了自定义路由值，则此参数是必需的。</li></ul><p>示例：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1. 创建一个索引</span></span><br><span class="line">DELETE my-index-000001</span><br><span class="line">PUT my-index-000001</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"mappings"</span>: &#123;</span><br><span class="line">    <span class="string">"properties"</span>: &#123;</span><br><span class="line">      <span class="string">"color"</span>: &#123; <span class="string">"type"</span>: <span class="string">"keyword"</span> &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 写入一个文档</span></span><br><span class="line">PUT my-index-000001/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"color"</span>: [</span><br><span class="line">    <span class="string">"blue"</span>,</span><br><span class="line">    <span class="string">"green"</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 写入另一个文档</span></span><br><span class="line">PUT my-index-000001/_doc/2</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"color"</span>: <span class="string">"blue"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 使用 terms query</span></span><br><span class="line">GET my-index-000001/_search?pretty</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"terms"</span>: &#123;</span><br><span class="line">      <span class="string">"color"</span>: &#123;</span><br><span class="line">        <span class="string">"index"</span>: <span class="string">"my-index-000001"</span>,</span><br><span class="line">        <span class="string">"id"</span>: <span class="string">"2"</span>,</span><br><span class="line">        <span class="string">"path"</span>: <span class="string">"color"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DELETE my-index-000001</span><br></pre></td></tr></table></figure><h3 id="29-type-query"><a class="markdownIt-Anchor" href="#29-type-query"></a> 2.9. type query</h3><blockquote><p>7.0.0 后废弃</p></blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-type-query.html" target="_blank" rel="noopener"><strong><code>type query</code></strong></a> 用于查询具有指定类型的文档。</p><p>示例：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"type"</span>: &#123;</span><br><span class="line">      <span class="string">"value"</span>: <span class="string">"_doc"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="210-wildcard-query"><a class="markdownIt-Anchor" href="#210-wildcard-query"></a> 2.10. wildcard query</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-wildcard-query.html" target="_blank" rel="noopener"><strong><code>wildcard query</code></strong></a> 即通配符查询，返回与通配符模式匹配的文档。</p><p><code>?</code> 用来匹配一个任意字符，<code>*</code> 用来匹配零个或者多个字符。</p><p>示例：以下搜索返回 <code>user.id</code> 字段包含以 <code>ki</code> 开头并以 <code>y</code> 结尾的术语的文档。这些匹配项可以包括 <code>kiy</code>、<code>kity</code> 或 <code>kimchy</code>。</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"wildcard"</span>: &#123;</span><br><span class="line">      <span class="string">"user.id"</span>: &#123;</span><br><span class="line">        <span class="string">"value"</span>: <span class="string">"ki*y"</span>,</span><br><span class="line">        <span class="string">"boost"</span>: 1.0,</span><br><span class="line">        <span class="string">"rewrite"</span>: <span class="string">"constant_score"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>注意：如果配置了<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html#query-dsl-allow-expensive-queries" target="_blank" rel="noopener"><code>search.allow_expensive_queries</code></a> ，则<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-wildcard-query.html" target="_blank" rel="noopener"><strong><code>wildcard query</code></strong></a> 会被禁用。</p></blockquote><h3 id="211-词项查询完整示例"><a class="markdownIt-Anchor" href="#211-词项查询完整示例"></a> 2.11. 词项查询完整示例</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">DELETE products</span><br><span class="line">PUT products</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"settings"</span>: &#123;</span><br><span class="line">    <span class="string">"number_of_shards"</span>: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST /products/_bulk</span><br><span class="line">&#123; <span class="string">"index"</span>: &#123; <span class="string">"_id"</span>: 1 &#125;&#125;</span><br><span class="line">&#123; <span class="string">"productID"</span> : <span class="string">"XHDK-A-1293-#fJ3"</span>,<span class="string">"desc"</span>:<span class="string">"iPhone"</span> &#125;</span><br><span class="line">&#123; <span class="string">"index"</span>: &#123; <span class="string">"_id"</span>: 2 &#125;&#125;</span><br><span class="line">&#123; <span class="string">"productID"</span> : <span class="string">"KDKE-B-9947-#kL5"</span>,<span class="string">"desc"</span>:<span class="string">"iPad"</span> &#125;</span><br><span class="line">&#123; <span class="string">"index"</span>: &#123; <span class="string">"_id"</span>: 3 &#125;&#125;</span><br><span class="line">&#123; <span class="string">"productID"</span> : <span class="string">"JODL-X-1937-#pV7"</span>,<span class="string">"desc"</span>:<span class="string">"MBP"</span> &#125;</span><br><span class="line"></span><br><span class="line">GET /products</span><br><span class="line"></span><br><span class="line">POST /products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"term"</span>: &#123;</span><br><span class="line">      <span class="string">"desc"</span>: &#123;</span><br><span class="line">        //<span class="string">"value"</span>: <span class="string">"iPhone"</span></span><br><span class="line">        <span class="string">"value"</span>:<span class="string">"iphone"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST /products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"term"</span>: &#123;</span><br><span class="line">      <span class="string">"desc.keyword"</span>: &#123;</span><br><span class="line">        //<span class="string">"value"</span>: <span class="string">"iPhone"</span></span><br><span class="line">        //<span class="string">"value"</span>:<span class="string">"iphone"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST /products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"term"</span>: &#123;</span><br><span class="line">      <span class="string">"productID"</span>: &#123;</span><br><span class="line">        <span class="string">"value"</span>: <span class="string">"XHDK-A-1293-#fJ3"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST /products/_search</span><br><span class="line">&#123;</span><br><span class="line">  //<span class="string">"explain"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"term"</span>: &#123;</span><br><span class="line">      <span class="string">"productID.keyword"</span>: &#123;</span><br><span class="line">        <span class="string">"value"</span>: <span class="string">"XHDK-A-1293-#fJ3"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST /products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"explain"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"constant_score"</span>: &#123;</span><br><span class="line">      <span class="string">"filter"</span>: &#123;</span><br><span class="line">        <span class="string">"term"</span>: &#123;</span><br><span class="line">          <span class="string">"productID.keyword"</span>: <span class="string">"XHDK-A-1293-#fJ3"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-复合查询"><a class="markdownIt-Anchor" href="#3-复合查询"></a> 3. 复合查询</h2><p>复合查询就是把一些简单查询组合在一起实现更复杂的查询需求，除此之外，复合查询还可以控制另外一个查询的行为。</p><h3 id="31-bool-query"><a class="markdownIt-Anchor" href="#31-bool-query"></a> 3.1. bool query</h3><p>bool 查询可以把任意多个简单查询组合在一起，使用 must、should、must_not、filter 选项来表示简单查询之间的逻辑，每个选项都可以出现 0 次到多次，它们的含义如下：</p><ul><li>must 文档必须匹配 must 选项下的查询条件，相当于逻辑运算的 AND，且参与文档相关度的评分。</li><li>should 文档可以匹配 should 选项下的查询条件也可以不匹配，相当于逻辑运算的 OR，且参与文档相关度的评分。</li><li>must_not 与 must 相反，匹配该选项下的查询条件的文档不会被返回；需要注意的是，<strong>must_not 语句不会影响评分，它的作用只是将不相关的文档排除</strong>。</li><li>filter 和 must 一样，匹配 filter 选项下的查询条件的文档才会被返回，<strong>但是 filter 不评分，只起到过滤功能，与 must_not 相反</strong>。</li></ul><p>假设要查询 title 中包含关键词 java，并且 price 不能高于 70，description 可以包含也可以不包含虚拟机的书籍，构造 bool 查询语句如下：</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> books/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"bool"</span>: &#123;</span><br><span class="line">      <span class="string">"filter"</span>: &#123;</span><br><span class="line">        <span class="string">"term"</span>: &#123;</span><br><span class="line">          <span class="string">"status"</span>: 1</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="string">"must_not"</span>: &#123;</span><br><span class="line">        <span class="string">"range"</span>: &#123;</span><br><span class="line">          <span class="string">"price"</span>: &#123;</span><br><span class="line">            <span class="string">"gte"</span>: 70</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="string">"must"</span>: &#123;</span><br><span class="line">        <span class="string">"match"</span>: &#123;</span><br><span class="line">          <span class="string">"title"</span>: <span class="string">"java"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="string">"should"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="string">"match"</span>: &#123;</span><br><span class="line">            <span class="string">"description"</span>: <span class="string">"虚拟机"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      <span class="string">"minimum_should_match"</span>: 1</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有关布尔查询更详细的信息参考 <a href="https://www.knowledgedict.com/tutorial/elasticsearch-query-bool.html" target="_blank" rel="noopener">bool query（组合查询）详解</a>。</p><h3 id="32-boosting-query"><a class="markdownIt-Anchor" href="#32-boosting-query"></a> 3.2. boosting query</h3><p>boosting 查询用于需要对两个查询的评分进行调整的场景，boosting 查询会把两个查询封装在一起并降低其中一个查询的评分。</p><p>boosting 查询包括 positive、negative 和 negative_boost 三个部分，positive 中的查询评分保持不变，negative 中的查询会降低文档评分，negative_boost 指明 negative 中降低的权值。如果我们想对 2015 年之前出版的书降低评分，可以构造一个 boosting 查询，查询语句如下：</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> books/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"boosting"</span>: &#123;</span><br><span class="line"><span class="string">"positive"</span>: &#123;</span><br><span class="line"><span class="string">"match"</span>: &#123;</span><br><span class="line"><span class="string">"title"</span>: <span class="string">"python"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"negative"</span>: &#123;</span><br><span class="line"><span class="string">"range"</span>: &#123;</span><br><span class="line"><span class="string">"publish_time"</span>: &#123;</span><br><span class="line"><span class="string">"lte"</span>: <span class="string">"2015-01-01"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"negative_boost"</span>: 0.2</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>boosting 查询中指定了抑制因子为 0.2，publish_time 的值在 2015-01-01 之后的文档得分不变，publish_time 的值在 2015-01-01 之前的文档得分为原得分的 0.2 倍。</p><h3 id="33-constant_score-query"><a class="markdownIt-Anchor" href="#33-constant_score-query"></a> 3.3. constant_score query</h3><p>constant<em>score query 包装一个 filter query，并返回匹配过滤器查询条件的文档，且它们的相关性评分都等于 _boost</em> 参数值（可以理解为原有的基于 tf-idf 或 bm25 的相关分固定为 1.0，所以最终评分为 <em>1.0 * boost</em>，即等于 <em>boost</em> 参数值）。下面的查询语句会返回 title 字段中含有关键词 <em>elasticsearch</em> 的文档，所有文档的评分都是 1.8：</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> books/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"constant_score"</span>: &#123;</span><br><span class="line">      <span class="string">"filter"</span>: &#123;</span><br><span class="line">        <span class="string">"term"</span>: &#123;</span><br><span class="line">          <span class="string">"title"</span>: <span class="string">"elasticsearch"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="string">"boost"</span>: 1.8</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="34-dis_max-query"><a class="markdownIt-Anchor" href="#34-dis_max-query"></a> 3.4. dis_max query</h3><p>dis_max query 与 bool query 有一定联系也有一定区别，dis_max query 支持多并发查询，可返回与任意查询条件子句匹配的任何文档类型。与 bool 查询可以将所有匹配查询的分数相结合使用的方式不同，dis_max 查询只使用最佳匹配查询条件的分数。请看下面的例子：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">GET</span> <span class="string">books/_search</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="attr">"query":</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"dis_max":</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"tie_breaker":</span> <span class="number">0.7</span><span class="string">,</span></span><br><span class="line"><span class="attr">"boost":</span> <span class="number">1.2</span><span class="string">,</span></span><br><span class="line"><span class="attr">"queries":</span> <span class="string">[&#123;</span></span><br><span class="line"><span class="attr">"term":</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"age":</span> <span class="number">34</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;,</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="attr">"term":</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"age":</span> <span class="number">35</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="35-function_score-query"><a class="markdownIt-Anchor" href="#35-function_score-query"></a> 3.5. function_score query</h3><p>function_score query 可以修改查询的文档得分，这个查询在有些情况下非常有用，比如通过评分函数计算文档得分代价较高，可以改用过滤器加自定义评分函数的方式来取代传统的评分方式。</p><p>使用 function_score query，用户需要定义一个查询和一至多个评分函数，评分函数会对查询到的每个文档分别计算得分。</p><p>下面这条查询语句会返回 books 索引中的所有文档，文档的最大得分为 5，每个文档的得分随机生成，权重的计算模式为相乘模式。</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> books/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"function_score"</span>: &#123;</span><br><span class="line">      <span class="string">"query"</span>: &#123;</span><br><span class="line">        <span class="string">"match all"</span>: &#123;&#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="string">"boost"</span>: <span class="string">"5"</span>,</span><br><span class="line">      <span class="string">"random_score"</span>: &#123;&#125;,</span><br><span class="line">      <span class="string">"boost_mode"</span>: <span class="string">"multiply"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用脚本自定义评分公式，这里把 price 值的十分之一开方作为每个文档的得分，查询语句如下：</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> books/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"function_score"</span>: &#123;</span><br><span class="line">      <span class="string">"query"</span>: &#123;</span><br><span class="line">        <span class="string">"match"</span>: &#123;</span><br><span class="line">          <span class="string">"title"</span>: <span class="string">"java"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="string">"script_score"</span>: &#123;</span><br><span class="line">        <span class="string">"inline"</span>: <span class="string">"Math.sqrt(doc['price'].value/10)"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>关于 function_score 的更多详细内容请查看 <a href="https://www.knowledgedict.com/tutorial/elasticsearch-function_score.html" target="_blank" rel="noopener">Elasticsearch function_score 查询最强详解</a>。</p><h3 id="36-indices-query"><a class="markdownIt-Anchor" href="#36-indices-query"></a> 3.6. indices query</h3><p>indices query 适用于需要在多个索引之间进行查询的场景，它允许指定一个索引名字列表和内部查询。indices query 中有 query 和 no_match_query 两部分，query 中用于搜索指定索引列表中的文档，no_match_query 中的查询条件用于搜索指定索引列表之外的文档。下面的查询语句实现了搜索索引 books、books2 中 title 字段包含关键字 javascript，其他索引中 title 字段包含 basketball 的文档，查询语句如下：</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> books/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"indices"</span>: &#123;</span><br><span class="line"><span class="string">"indices"</span>: [<span class="string">"books"</span>, <span class="string">"books2"</span>],</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"match"</span>: &#123;</span><br><span class="line"><span class="string">"title"</span>: <span class="string">"javascript"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"no_match_query"</span>: &#123;</span><br><span class="line"><span class="string">"term"</span>: &#123;</span><br><span class="line"><span class="string">"title"</span>: <span class="string">"basketball"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4-嵌套查询"><a class="markdownIt-Anchor" href="#4-嵌套查询"></a> 4. 嵌套查询</h2><p>在 Elasticsearch 这样的分布式系统中执行全 SQL 风格的连接查询代价昂贵，是不可行的。相应地，为了实现水平规模地扩展，Elasticsearch 提供了以下两种形式的 join：</p><ul><li><p>nested query（嵌套查询）</p><p>文档中可能包含嵌套类型的字段，这些字段用来索引一些数组对象，每个对象都可以作为一条独立的文档被查询出来。</p></li><li><p>has_child query（有子查询）和 has_parent query（有父查询）</p><p>父子关系可以存在单个的索引的两个类型的文档之间。has_child 查询将返回其子文档能满足特定查询的父文档，而 has_parent 则返回其父文档能满足特定查询的子文档。</p></li></ul><h3 id="41-nested-query"><a class="markdownIt-Anchor" href="#41-nested-query"></a> 4.1. nested query</h3><p>文档中可能包含嵌套类型的字段，这些字段用来索引一些数组对象，每个对象都可以作为一条独立的文档被查询出来（用嵌套查询）。</p><figure class="highlight dts"><table><tr><td class="code"><pre><span class="line">PUT /my_index</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"mappings"</span>: &#123;</span><br><span class="line"><span class="string">"type1"</span>: &#123;</span><br><span class="line"><span class="string">"properties"</span>: &#123;</span><br><span class="line"><span class="string">"obj1"</span>: &#123;</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"nested"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="42-has_child-query"><a class="markdownIt-Anchor" href="#42-has_child-query"></a> 4.2. has_child query</h3><p>文档的父子关系创建索引时在映射中声明，这里以员工（employee）和工作城市（branch）为例，它们属于不同的类型，相当于数据库中的两张表，如果想把员工和他们工作的城市关联起来，需要告诉 Elasticsearch 文档之间的父子关系，这里 employee 是 child type，branch 是 parent type，在映射中声明，执行命令：</p><figure class="highlight dts"><table><tr><td class="code"><pre><span class="line">PUT /company</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"mappings"</span>: &#123;</span><br><span class="line"><span class="string">"branch"</span>: &#123;&#125;,</span><br><span class="line"><span class="string">"employee"</span>: &#123;</span><br><span class="line"><span class="string">"parent"</span>: &#123; <span class="string">"type"</span>: <span class="string">"branch"</span> &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用 bulk api 索引 branch 类型下的文档，命令如下：</p><figure class="highlight dts"><table><tr><td class="code"><pre><span class="line">POST company<span class="meta-keyword">/branch/</span>_bulk</span><br><span class="line">&#123; <span class="string">"index"</span>: &#123; <span class="string">"_id"</span>: <span class="string">"london"</span> &#125;&#125;</span><br><span class="line">&#123; <span class="string">"name"</span>: <span class="string">"London Westminster"</span>,<span class="string">"city"</span>: <span class="string">"London"</span>,<span class="string">"country"</span>: <span class="string">"UK"</span> &#125;</span><br><span class="line">&#123; <span class="string">"index"</span>: &#123; <span class="string">"_id"</span>: <span class="string">"liverpool"</span> &#125;&#125;</span><br><span class="line">&#123; <span class="string">"name"</span>: <span class="string">"Liverpool Central"</span>,<span class="string">"city"</span>: <span class="string">"Liverpool"</span>,<span class="string">"country"</span>: <span class="string">"UK"</span> &#125;</span><br><span class="line">&#123; <span class="string">"index"</span>: &#123; <span class="string">"_id"</span>: <span class="string">"paris"</span> &#125;&#125;</span><br><span class="line">&#123; <span class="string">"name"</span>: <span class="string">"Champs Elysees"</span>,<span class="string">"city"</span>: <span class="string">"Paris"</span>,<span class="string">"country"</span>: <span class="string">"France"</span> &#125;</span><br></pre></td></tr></table></figure><p>添加员工数据：</p><figure class="highlight dts"><table><tr><td class="code"><pre><span class="line">POST company<span class="meta-keyword">/employee/</span>_bulk</span><br><span class="line">&#123; <span class="string">"index"</span>: &#123; <span class="string">"_id"</span>: <span class="number">1</span>,<span class="string">"parent"</span>:<span class="string">"london"</span> &#125;&#125;</span><br><span class="line">&#123; <span class="string">"name"</span>: <span class="string">"Alice Smith"</span>,<span class="string">"dob"</span>: <span class="string">"1970-10-24"</span>,<span class="string">"hobby"</span>: <span class="string">"hiking"</span> &#125;</span><br><span class="line">&#123; <span class="string">"index"</span>: &#123; <span class="string">"_id"</span>: <span class="number">2</span>,<span class="string">"parent"</span>:<span class="string">"london"</span> &#125;&#125;</span><br><span class="line">&#123; <span class="string">"name"</span>: <span class="string">"Mark Tomas"</span>,<span class="string">"dob"</span>: <span class="string">"1982-05-16"</span>,<span class="string">"hobby"</span>: <span class="string">"diving"</span> &#125;</span><br><span class="line">&#123; <span class="string">"index"</span>: &#123; <span class="string">"_id"</span>: <span class="number">3</span>,<span class="string">"parent"</span>:<span class="string">"liverpool"</span> &#125;&#125;</span><br><span class="line">&#123; <span class="string">"name"</span>: <span class="string">"Barry Smith"</span>,<span class="string">"dob"</span>: <span class="string">"1979-04-01"</span>,<span class="string">"hobby"</span>: <span class="string">"hiking"</span> &#125;</span><br><span class="line">&#123; <span class="string">"index"</span>: &#123; <span class="string">"_id"</span>: <span class="number">4</span>,<span class="string">"parent"</span>:<span class="string">"paris"</span> &#125;&#125;</span><br><span class="line">&#123; <span class="string">"name"</span>: <span class="string">"Adrien Grand"</span>,<span class="string">"dob"</span>: <span class="string">"1987-05-11"</span>,<span class="string">"hobby"</span>: <span class="string">"horses"</span> &#125;</span><br></pre></td></tr></table></figure><p>通过子文档查询父文档要使用 has_child 查询。例如，搜索 1980 年以后出生的员工所在的分支机构，employee 中 1980 年以后出生的有 Mark Thomas 和 Adrien Grand，他们分别在 london 和 paris，执行以下查询命令进行验证：</p><figure class="highlight dts"><table><tr><td class="code"><pre><span class="line">GET company<span class="meta-keyword">/branch/</span>_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"has_child"</span>: &#123;</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"employee"</span>,</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"range"</span>: &#123; <span class="string">"dob"</span>: &#123; <span class="string">"gte"</span>: <span class="string">"1980-01-01"</span> &#125; &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>搜索哪些机构中有名为 “Alice Smith” 的员工，因为使用 match 查询，会解析为 “Alice” 和 “Smith”，所以 Alice Smith 和 Barry Smith 所在的机构会被匹配，执行以下查询命令进行验证：</p><figure class="highlight dts"><table><tr><td class="code"><pre><span class="line">GET company<span class="meta-keyword">/branch/</span>_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"has_child"</span>: &#123;</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"employee"</span>,</span><br><span class="line"><span class="string">"score_mode"</span>: <span class="string">"max"</span>,</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"match"</span>: &#123; <span class="string">"name"</span>: <span class="string">"Alice Smith"</span> &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以使用 min_children 指定子文档的最小个数。例如，搜索最少含有两个 employee 的机构，查询命令如下：</p><figure class="highlight dts"><table><tr><td class="code"><pre><span class="line">GET company<span class="meta-keyword">/branch/</span>_search?pretty</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"has_child"</span>: &#123;</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"employee"</span>,</span><br><span class="line"><span class="string">"min_children"</span>: <span class="number">2</span>,</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"match_all"</span>: &#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="43-has_parent-query"><a class="markdownIt-Anchor" href="#43-has_parent-query"></a> 4.3. has_parent query</h3><p>通过父文档查询子文档使用 has_parent 查询。比如，搜索哪些 employee 工作在 UK，查询命令如下：</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> company/employee/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"has_parent"</span>: &#123;</span><br><span class="line"><span class="string">"parent_type"</span>: <span class="string">"branch"</span>,</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"match"</span>: &#123; <span class="string">"country"</span>: <span class="string">"UK &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><h2 id="5-位置查询"><a class="markdownIt-Anchor" href="#5-位置查询"></a> 5. 位置查询</h2><p>Elasticsearch 可以对地理位置点 geo_point 类型和地理位置形状 geo_shape 类型的数据进行搜索。为了学习方便，这里准备一些城市的地理坐标作为测试数据，每一条文档都包含城市名称和地理坐标这两个字段，这里的坐标点取的是各个城市中心的一个位置。首先把下面的内容保存到 geo.json 文件中：</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;<span class="attr">"index"</span>:&#123; <span class="attr">"_index"</span>:<span class="string">"geo"</span>,<span class="attr">"_type"</span>:<span class="string">"city"</span>,<span class="attr">"_id"</span>:<span class="string">"1"</span> &#125;&#125;</span><br><span class="line">&#123;<span class="attr">"name"</span>:<span class="string">"北京"</span>,<span class="attr">"location"</span>:<span class="string">"39.9088145109,116.3973999023"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123; <span class="attr">"_index"</span>:<span class="string">"geo"</span>,<span class="attr">"_type"</span>:<span class="string">"city"</span>,<span class="attr">"_id"</span>: <span class="string">"2"</span> &#125;&#125;</span><br><span class="line">&#123;<span class="attr">"name"</span>:<span class="string">"乌鲁木齐"</span>,<span class="attr">"location"</span>:<span class="string">"43.8266300000,87.6168800000"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123; <span class="attr">"_index"</span>:<span class="string">"geo"</span>,<span class="attr">"_type"</span>:<span class="string">"city"</span>,<span class="attr">"_id"</span>:<span class="string">"3"</span> &#125;&#125;</span><br><span class="line">&#123;<span class="attr">"name"</span>:<span class="string">"西安"</span>,<span class="attr">"location"</span>:<span class="string">"34.3412700000,108.9398400000"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123; <span class="attr">"_index"</span>:<span class="string">"geo"</span>,<span class="attr">"_type"</span>:<span class="string">"city"</span>,<span class="attr">"_id"</span>:<span class="string">"4"</span> &#125;&#125;</span><br><span class="line">&#123;<span class="attr">"name"</span>:<span class="string">"郑州"</span>,<span class="attr">"location"</span>:<span class="string">"34.7447157466,113.6587142944"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123; <span class="attr">"_index"</span>:<span class="string">"geo"</span>,<span class="attr">"_type"</span>:<span class="string">"city"</span>,<span class="attr">"_id"</span>:<span class="string">"5"</span> &#125;&#125;</span><br><span class="line">&#123;<span class="attr">"name"</span>:<span class="string">"杭州"</span>,<span class="attr">"location"</span>:<span class="string">"30.2294080260,120.1492309570"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123; <span class="attr">"_index"</span>:<span class="string">"geo"</span>,<span class="attr">"_type"</span>:<span class="string">"city"</span>,<span class="attr">"_id"</span>:<span class="string">"6"</span> &#125;&#125;</span><br><span class="line">&#123;<span class="attr">"name"</span>:<span class="string">"济南"</span>,<span class="attr">"location"</span>:<span class="string">"36.6518400000,117.1200900000"</span>&#125;</span><br></pre></td></tr></table></figure><p>创建一个索引并设置映射：</p><figure class="highlight dts"><table><tr><td class="code"><pre><span class="line">PUT geo</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"mappings"</span>: &#123;</span><br><span class="line"><span class="string">"city"</span>: &#123;</span><br><span class="line"><span class="string">"properties"</span>: &#123;</span><br><span class="line"><span class="string">"name"</span>: &#123;</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"keyword"</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"location"</span>: &#123;</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"geo_point"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后执行批量导入命令：</p><figure class="highlight armasm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">curl</span> -XPOST <span class="string">"http://localhost:9200/_bulk?pretty"</span> --<span class="meta">data</span>-<span class="keyword">binary </span><span class="comment">@geo.json</span></span><br></pre></td></tr></table></figure><h3 id="51-geo_distance-query"><a class="markdownIt-Anchor" href="#51-geo_distance-query"></a> 5.1. geo_distance query</h3><p>geo_distance query 可以查找在一个中心点指定范围内的地理点文档。例如，查找距离天津 200km 以内的城市，搜索结果中会返回北京，命令如下：</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> geo/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"bool"</span>: &#123;</span><br><span class="line"><span class="string">"must"</span>: &#123;</span><br><span class="line"><span class="string">"match_all"</span>: &#123;&#125;</span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"filter"</span>: &#123;</span><br><span class="line"><span class="string">"geo_distance"</span>: &#123;</span><br><span class="line"><span class="string">"distance"</span>: <span class="string">"200km"</span>,</span><br><span class="line"><span class="string">"location"</span>: &#123;</span><br><span class="line"><span class="string">"lat"</span>: 39.0851000000,</span><br><span class="line"><span class="string">"lon"</span>: 117.1993700000</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>按各城市离北京的距离排序：</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> geo/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"match_all"</span>: &#123;&#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"sort"</span>: [&#123;</span><br><span class="line">    <span class="string">"_geo_distance"</span>: &#123;</span><br><span class="line">      <span class="string">"location"</span>: <span class="string">"39.9088145109,116.3973999023"</span>,</span><br><span class="line">      <span class="string">"unit"</span>: <span class="string">"km"</span>,</span><br><span class="line">      <span class="string">"order"</span>: <span class="string">"asc"</span>,</span><br><span class="line">      <span class="string">"distance_type"</span>: <span class="string">"plane"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中 location 对应的经纬度字段；unit 为 <code>km</code> 表示将距离以 <code>km</code> 为单位写入到每个返回结果的 sort 键中；distance_type 为 <code>plane</code> 表示使用快速但精度略差的 <code>plane</code> 计算方式。</p><h3 id="52-geo_bounding_box-query"><a class="markdownIt-Anchor" href="#52-geo_bounding_box-query"></a> 5.2. geo_bounding_box query</h3><p>geo_bounding_box query 用于查找落入指定的矩形内的地理坐标。查询中由两个点确定一个矩形，然后在矩形区域内查询匹配的文档。</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">GET</span> <span class="string">geo/_search</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="attr">"query":</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"bool":</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"must":</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"match_all":</span> <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="string">&#125;,</span></span><br><span class="line"><span class="attr">"filter":</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"geo_bounding_box":</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"location":</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"top_left":</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"lat":</span> <span class="number">38.4864400000</span><span class="string">,</span></span><br><span class="line"><span class="attr">"lon":</span> <span class="number">106.2324800000</span></span><br><span class="line"><span class="string">&#125;,</span></span><br><span class="line"><span class="attr">"bottom_right":</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"lat":</span> <span class="number">28.6820200000</span><span class="string">,</span></span><br><span class="line"><span class="attr">"lon":</span> <span class="number">115.8579400000</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="53-geo_polygon-query"><a class="markdownIt-Anchor" href="#53-geo_polygon-query"></a> 5.3. geo_polygon query</h3><p>geo_polygon query 用于查找在指定<strong>多边形</strong>内的地理点。例如，呼和浩特、重庆、上海三地组成一个三角形，查询位置在该三角形区域内的城市，命令如下：</p><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">GET</span> <span class="string">geo/_search</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="attr">"query":</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"bool":</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"must":</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"match_all":</span> <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;,</span></span><br><span class="line"><span class="attr">"filter":</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"geo_polygon":</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"location":</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"points":</span> <span class="string">[&#123;</span></span><br><span class="line"><span class="attr">"lat":</span> <span class="number">40.8414900000</span><span class="string">,</span></span><br><span class="line"><span class="attr">"lon":</span> <span class="number">111.7519900000</span></span><br><span class="line"><span class="string">&#125;,</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"lat":</span> <span class="number">29.5647100000</span><span class="string">,</span></span><br><span class="line"><span class="attr">"lon":</span> <span class="number">106.5507300000</span></span><br><span class="line"><span class="string">&#125;,</span> <span class="string">&#123;</span></span><br><span class="line"><span class="attr">"lat":</span> <span class="number">31.2303700000</span><span class="string">,</span></span><br><span class="line"><span class="attr">"lon":</span> <span class="number">121.4737000000</span></span><br><span class="line"><span class="string">&#125;]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="54-geo_shape-query"><a class="markdownIt-Anchor" href="#54-geo_shape-query"></a> 5.4. geo_shape query</h3><p>geo_shape query 用于查询 geo_shape 类型的地理数据，地理形状之间的关系有相交、包含、不相交三种。创建一个新的索引用于测试，其中 location 字段的类型设为 geo_shape 类型。</p><figure class="highlight dts"><table><tr><td class="code"><pre><span class="line">PUT geoshape</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"mappings"</span>: &#123;</span><br><span class="line"><span class="string">"city"</span>: &#123;</span><br><span class="line"><span class="string">"properties"</span>: &#123;</span><br><span class="line"><span class="string">"name"</span>: &#123;</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"keyword"</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"location"</span>: &#123;</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"geo_shape"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>关于经纬度的顺序这里做一个说明，geo_point 类型的字段纬度在前经度在后，但是对于 geo_shape 类型中的点，是经度在前纬度在后，这一点需要特别注意。</p><p>把西安和郑州连成的线写入索引：</p><figure class="highlight prolog"><table><tr><td class="code"><pre><span class="line"><span class="symbol">POST</span> geoshape/city/<span class="number">1</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"name"</span>: <span class="string">"西安-郑州"</span>,</span><br><span class="line"><span class="string">"location"</span>: &#123;</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"linestring"</span>,</span><br><span class="line"><span class="string">"coordinates"</span>: [</span><br><span class="line">[<span class="number">108.9398400000</span>, <span class="number">34.3412700000</span>],</span><br><span class="line">[<span class="number">113.6587142944</span>, <span class="number">34.7447157466</span>]</span><br><span class="line">]</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查询包含在由银川和南昌作为对角线上的点组成的矩形的地理形状，由于西安和郑州组成的直线落在该矩形区域内，因此可以被查询到。命令如下：</p><figure class="highlight prolog"><table><tr><td class="code"><pre><span class="line"><span class="symbol">GET</span> geoshape/<span class="symbol">_search</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"bool"</span>: &#123;</span><br><span class="line"><span class="string">"must"</span>: &#123;</span><br><span class="line"><span class="string">"match_all"</span>: &#123;&#125;</span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"filter"</span>: &#123;</span><br><span class="line"><span class="string">"geo_shape"</span>: &#123;</span><br><span class="line"><span class="string">"location"</span>: &#123;</span><br><span class="line"><span class="string">"shape"</span>: &#123;</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"envelope"</span>,</span><br><span class="line"><span class="string">"coordinates"</span>: [</span><br><span class="line">[<span class="number">106.23248</span>, <span class="number">38.48644</span>],</span><br><span class="line">[<span class="number">115.85794</span>, <span class="number">28.68202</span>]</span><br><span class="line">]</span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"relation"</span>: <span class="string">"within"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="6-特殊查询"><a class="markdownIt-Anchor" href="#6-特殊查询"></a> 6. 特殊查询</h2><h3 id="61-more_like_this-query"><a class="markdownIt-Anchor" href="#61-more_like_this-query"></a> 6.1. more_like_this query</h3><p>more_like_this query 可以查询和提供文本类似的文档，通常用于近似文本的推荐等场景。查询命令如下：</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> books/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"more_like_ this"</span>: &#123;</span><br><span class="line"><span class="string">"fields"</span>: [<span class="string">"title"</span>, <span class="string">"description"</span>],</span><br><span class="line"><span class="string">"like"</span>: <span class="string">"java virtual machine"</span>,</span><br><span class="line"><span class="string">"min_term_freq"</span>: 1,</span><br><span class="line"><span class="string">"max_query_terms"</span>: 12</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可选的参数及取值说明如下：</p><ul><li>fields 要匹配的字段，默认是 _all 字段。</li><li>like 要匹配的文本。</li><li>min_term_freq 文档中词项的最低频率，默认是 2，低于此频率的文档会被忽略。</li><li>max_query_terms query 中能包含的最大词项数目，默认为 25。</li><li>min_doc_freq 最小的文档频率，默认为 5。</li><li>max_doc_freq 最大文档频率。</li><li>min_word length 单词的最小长度。</li><li>max_word length 单词的最大长度。</li><li>stop_words 停用词列表。</li><li>analyzer 分词器。</li><li>minimum_should_match 文档应匹配的最小词项数，默认为 query 分词后词项数的 30%。</li><li>boost terms 词项的权重。</li><li>include 是否把输入文档作为结果返回。</li><li>boost 整个 query 的权重，默认为 1.0。</li></ul><h3 id="62-script-query"><a class="markdownIt-Anchor" href="#62-script-query"></a> 6.2. script query</h3><p>Elasticsearch 支持使用脚本进行查询。例如，查询价格大于 180 的文档，命令如下：</p><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">GET</span> books/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"query"</span>: &#123;</span><br><span class="line">    <span class="string">"script"</span>: &#123;</span><br><span class="line">      <span class="string">"script"</span>: &#123;</span><br><span class="line">        <span class="string">"inline"</span>: <span class="string">"doc['price'].value &gt; 180"</span>,</span><br><span class="line">        <span class="string">"lang"</span>: <span class="string">"painless"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="63-percolate-query"><a class="markdownIt-Anchor" href="#63-percolate-query"></a> 6.3. percolate query</h3><p>一般情况下，我们是先把文档写入到 Elasticsearch 中，通过查询语句对文档进行搜索。percolate query 则是反其道而行之的做法，它会先注册查询条件，根据文档来查询 query。例如，在 my-index 索引中有一个 laptop 类型，文档有 price 和 name 两个字段，在映射中声明一个 percolator 类型的 query，命令如下：</p><figure class="highlight perl"><table><tr><td class="code"><pre><span class="line">PUT <span class="keyword">my</span>-<span class="keyword">index</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"mappings"</span>: &#123;</span><br><span class="line"><span class="string">"laptop"</span>: &#123;</span><br><span class="line"><span class="string">"properties"</span>: &#123;</span><br><span class="line"><span class="string">"price"</span>: &#123; <span class="string">"type"</span>: <span class="string">"long"</span> &#125;,</span><br><span class="line"><span class="string">"name"</span>: &#123; <span class="string">"type"</span>: <span class="string">"text"</span> &#125;</span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"queries"</span>: &#123;</span><br><span class="line"><span class="string">"properties"</span>: &#123;</span><br><span class="line"><span class="string">"query"</span>: &#123; <span class="string">"type"</span>: <span class="string">"percolator"</span> &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注册一个 bool query，bool query 中包含一个 range query，要求 price 字段的取值小于等于 10000，并且 name 字段中含有关键词 macbook：</p><figure class="highlight dts"><table><tr><td class="code"><pre><span class="line">PUT <span class="meta-keyword">/my-index/</span>queries/<span class="number">1</span>?refresh</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"bool"</span>: &#123;</span><br><span class="line"><span class="string">"must"</span>: [&#123;</span><br><span class="line"><span class="string">"range"</span>: &#123; <span class="string">"price"</span>: &#123; <span class="string">"lte"</span>: <span class="number">10000</span> &#125; &#125;</span><br><span class="line">&#125;, &#123;</span><br><span class="line"><span class="string">"match"</span>: &#123; <span class="string">"name"</span>: <span class="string">"macbook"</span> &#125;</span><br><span class="line">&#125;]</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过文档查询 query：</p><figure class="highlight dts"><table><tr><td class="code"><pre><span class="line">GET <span class="meta-keyword">/my-index/</span>_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"query"</span>: &#123;</span><br><span class="line"><span class="string">"percolate"</span>: &#123;</span><br><span class="line"><span class="string">"field"</span>: <span class="string">"query"</span>,</span><br><span class="line"><span class="string">"document_type"</span>: <span class="string">"laptop"</span>,</span><br><span class="line"><span class="string">"document"</span>: &#123;</span><br><span class="line"><span class="string">"price"</span>: <span class="number">9999</span>,</span><br><span class="line"><span class="string">"name"</span>: <span class="string">"macbook pro on sale"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>文档符合 query 中的条件，返回结果中可以查到上文中注册的 bool query。percolate query 的这种特性适用于数据分类、数据路由、事件监控和预警等场景。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;elasticsearch-查询&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#elasticsearch-查询&quot;&gt;&lt;/a&gt; Elasticsearch 查询&lt;/h1&gt;
&lt;p&gt;Elasticsearch 查询语句采用基于 RESTful
      
    
    </summary>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/Elasticsearch/"/>
    
    
      <category term="数据库" scheme="https://dunwu.github.io/blog/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="搜索引擎数据库" scheme="https://dunwu.github.io/blog/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://dunwu.github.io/blog/tags/Elasticsearch/"/>
    
      <category term="查询" scheme="https://dunwu.github.io/blog/tags/%E6%9F%A5%E8%AF%A2/"/>
    
  </entry>
  
</feed>
